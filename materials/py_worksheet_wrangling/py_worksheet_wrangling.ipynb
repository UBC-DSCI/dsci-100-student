{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "96ae171e34460d2aebf8e5283adb65c3",
     "grade": false,
     "grade_id": "cell-a3e4ac7f29e7ee20",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# Worksheet 3: Cleaning and Wrangling Data\n",
    "\n",
    "\n",
    "### Lecture and Tutorial Learning Goals:\n",
    "\n",
    "After completing this week's lecture and tutorial work, you will be able to:\n",
    "\n",
    "* define the term \"tidy data\"\n",
    "* Explain when chaining is appropriate and demonstrate chaining over multiple lines and verbs.\n",
    "* discuss the advantages and disadvantages of storing data in a tidy data format\n",
    "* recall and use the following functions and methods for their intended data wrangling tasks:\n",
    "    - Use `loc[]` to select rows or columns.\n",
    "    - Use `[]` to filter rows of a data frame.\n",
    "    - Create new or columns in a data frame using `assign` method.\n",
    "    - Use `groupby` to calculate summary statistics on grouped objects \n",
    "    - Use `melt` and `pivot` to reshape data frames, specifically to make tidy data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "7ba3b46cb18d152984c681d9d935f1cc",
     "grade": false,
     "grade_id": "cell-9ad6a603a70e118a",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "### Run this cell before continuing.\n",
    "import altair as alt\n",
    "import pandas as pd\n",
    "\n",
    "alt.data_transformers.disable_max_rows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "c4216c380079fd788b19c5542921ee63",
     "grade": false,
     "grade_id": "cell-0d59d96414adc1b8",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**Question 0.0** Multiple Choice: \n",
    "<br> {points: 1}\n",
    "\n",
    "Which of the following characterize a tidy dataset? note - there may be more than 1 correct answers to this question\n",
    "\n",
    "A) Each row is a single variable\n",
    "\n",
    "B) There are no missing or erroneous values\n",
    "\n",
    "C) Each value is a single cell\n",
    "\n",
    "D) Each variable is a single column\n",
    "\n",
    "*Assign your answer to an object called `answer0_0` in the code chunk below. Make sure your answer contains uppercase letters and surround it with quotation marks and square brackets. If there are more than one answers to this question, separate each letter with a comma within the square brackets. For example if you believe the answer is A, B and C your answer would like this:\n",
    "`answer0_0 = ['A', 'B', 'C']`*\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "aee20ce053bfd831dbf772b4cf3071fb",
     "grade": false,
     "grade_id": "cell-cffd5df5830ecafd",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# your code here\n",
    "raise NotImplementedError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "max_height": 100,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "fcb353824f99099f68fb5d2be2b1b39e",
     "grade": true,
     "grade_id": "cell-0bea903e0f37148c",
     "locked": true,
     "points": 3,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "from hashlib import sha1\n",
    "assert sha1(str(type(answer0_0)).encode(\"utf-8\")+b\"7be0e8a85c75a396\").hexdigest() == \"dc09246f4be541cca786232824a36faa799aa330\", \"type of answer0_0 is not list. answer0_0 should be a list\"\n",
    "assert sha1(str(len(answer0_0)).encode(\"utf-8\")+b\"7be0e8a85c75a396\").hexdigest() == \"aad80b0af1a7906054bce40e57051efc100f22ef\", \"length of answer0_0 is not correct\"\n",
    "assert sha1(str(sorted(map(str, answer0_0))).encode(\"utf-8\")+b\"7be0e8a85c75a396\").hexdigest() == \"7bcce9cb148e633a5b613b20d4e05dbfcfd5ccb1\", \"values of answer0_0 are not correct\"\n",
    "assert sha1(str(answer0_0).encode(\"utf-8\")+b\"7be0e8a85c75a396\").hexdigest() == \"7bcce9cb148e633a5b613b20d4e05dbfcfd5ccb1\", \"order of elements of answer0_0 is not correct\"\n",
    "\n",
    "print('Success!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "5986685c6a02b07eeb16d1d5bfb2be14",
     "grade": false,
     "grade_id": "cell-77d758b913b7fb7d",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "**Question 0.1** Multiple Choice: \n",
    "<br> {points: 1}\n",
    "\n",
    "The data below is wine ratings given for 3 wines by 5 different wine tasters. We are interested in seeing if Taster or Wine type influences the rating.  Given that motivation, which arrangement of the data set show below is \"tidy\"?,\n",
    "\n",
    "##### Data set 1:\n",
    "\n",
    "|     Taster       | Chardonnay | Pinot Grigio | Pinot Blanc |\n",
    "|------------|------------|--------------|-----------------|\n",
    "| 001 | 75         | 89           | 92              |\n",
    "| 002 | 89         | 88           | 89              |\n",
    "| 003 | 72         | 90           | 95              |\n",
    "| 004 | 85         | 81           | 90              |\n",
    "| 005 | 83         | 89           | 88              |\n",
    "\n",
    "##### Data set 2:\n",
    "\n",
    "|   Wine | Taster 001 | Taster 002 | Taster 003 | Taster 004 | Taster 005 |\n",
    "|------------|------------|--------------|-----------------|-------|---------|\n",
    "| Chardonnay | 75         | 89           | 72              | 85 | 83|\n",
    "| Pinot Grigio | 89         | 88           | 90             | 81 | 89 |\n",
    "| Pinot Blanc | 92         | 89           | 95              | 90 | 88 |\n",
    "\n",
    "##### Data set 3:\n",
    "\n",
    "| Taster           | Wine | Rating | \n",
    "|------------|------------|----|\n",
    "| 001 |  Chardonnay |  75         |\n",
    "| 002 |  Chardonnay | 89         | \n",
    "| 003 |  Chardonnay |72         | \n",
    "| 004 |  Chardonnay |85         | \n",
    "| 005 | Chardonnay | 83         | \n",
    "| 001 |  Pinot Grigio | 89         |\n",
    "| 002 |  Pinot Grigio | 88         | \n",
    "| 003 |  Pinot Grigio | 90         | \n",
    "| 004 |  Pinot Grigio | 81         |\n",
    "| 005 |  Pinot Grigio | 90         |\n",
    "| 001 |  Pinot Blanc | 92         |\n",
    "| 002 | Pinot Blanc | 89         |\n",
    "| 003 | Pinot Blanc | 95         | \n",
    "| 004 | Pinot Blanc | 90         |\n",
    "| 005 | Pinot Blanc | 88         | \n",
    "\n",
    "##### Data set 4:\n",
    "| Taster    | Chardonnay Rating | \n",
    "|------------|------------|\n",
    "| 001 |  75         | \n",
    "| 002 |   89         | \n",
    "| 003 |  72         |\n",
    "| 004 | 85         | \n",
    "| 005 | 83         |\n",
    "\n",
    "| Taster           | Pinot Grigio Rating | \n",
    "|------------|------------|\n",
    "| 001 |   89         |\n",
    "| 002 |  88         |\n",
    "| 003 |  90         | \n",
    "| 004 | 81         | \n",
    "| 005 |  90         | \n",
    "\n",
    "| Taster           | Pinot Blanc Rating | \n",
    "|------------|------------|\n",
    "| 001 |   92         | \n",
    "| 002 |  89         |\n",
    "| 003 |  95         | \n",
    "| 004 |  90         | \n",
    "| 005 |  88         | \n",
    "\n",
    "\n",
    "*Assign your answer to an object called `answer0_1`. Make sure your answer is surrounded by square brackets. If there are more than one answers to this question, separate each number with a comma in the square brackets. For example if you believe the answer is 1, 2 and 3 your answer would like this: `answer0_1` = [1, 2, 3]*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "cd8b3c0528decd8dba06d4ea554f9712",
     "grade": false,
     "grade_id": "cell-875bec2db6814c4e",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# your code here\n",
    "raise NotImplementedError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "max_height": 100,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "ac2d79703bb971e0b5124f3328a2d831",
     "grade": true,
     "grade_id": "cell-7bc5804c8cd5900d",
     "locked": true,
     "points": 3,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "from hashlib import sha1\n",
    "assert sha1(str(type(answer0_1)).encode(\"utf-8\")+b\"98afd7cd907a2083\").hexdigest() == \"a93149278702ac10672055f3dda9c11547685082\", \"type of answer0_1 is not list. answer0_1 should be a list\"\n",
    "assert sha1(str(len(answer0_1)).encode(\"utf-8\")+b\"98afd7cd907a2083\").hexdigest() == \"6f435e1d02987aaf244a14475e0499d22d6a1617\", \"length of answer0_1 is not correct\"\n",
    "assert sha1(str(sorted(map(str, answer0_1))).encode(\"utf-8\")+b\"98afd7cd907a2083\").hexdigest() == \"a42dd6ad0a28fa4282d6063ed7daa4a638a31cdd\", \"values of answer0_1 are not correct\"\n",
    "assert sha1(str(answer0_1).encode(\"utf-8\")+b\"98afd7cd907a2083\").hexdigest() == \"0e12bb5fb46e0043e31f984bb9a6430b70cb629c\", \"order of elements of answer0_1 is not correct\"\n",
    "\n",
    "print('Success!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "d2ed92379f556830ac1525c090b35d10",
     "grade": false,
     "grade_id": "cell-216b6088d404c4fc",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**Question 0.2** Multiple Choice: \n",
    "<br> {points: 1}\n",
    "\n",
    "To answer the question, assign the letter associated with the correct answer to a variable in the code cell below:\n",
    "\n",
    "Why is the primary goal of data wrangling getting dataframes into the tidy data format?\n",
    "\n",
    "A) Having data expressed in such a way, allows for easier readability and is more aesthetically pleasing.\n",
    "\n",
    "B) Tidy format uses less storage space on your computer.\n",
    "\n",
    "C) Many or most modern Data Science tools accept the tidy data format directly (or very close to that) and we need to get the data in a state ready for analysis.\n",
    "\n",
    "*Answer in the cell below using the uppercase letter associated with your answer. Place your answer between `\"\"`, assign the correct answer to an object called `answer0_2`.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "810e78626bf0c8657d0f2fad682fb553",
     "grade": false,
     "grade_id": "cell-fc224cb5d19b5cc1",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# your code here\n",
    "raise NotImplementedError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "max_height": 100,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "91d2a1f8f10e484a0ee5dcbec33e1f10",
     "grade": true,
     "grade_id": "cell-385b06349b0b7c8f",
     "locked": true,
     "points": 3,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "from hashlib import sha1\n",
    "assert sha1(str(type(answer0_2)).encode(\"utf-8\")+b\"7997af0bedd9ee7b\").hexdigest() == \"e7e6f83fb6f7cc71681786e5ba8a86ac18d529e2\", \"type of answer0_2 is not str. answer0_2 should be an str\"\n",
    "assert sha1(str(len(answer0_2)).encode(\"utf-8\")+b\"7997af0bedd9ee7b\").hexdigest() == \"b44318636caad2997bc3a6679ba888ca755c3403\", \"length of answer0_2 is not correct\"\n",
    "assert sha1(str(answer0_2.lower()).encode(\"utf-8\")+b\"7997af0bedd9ee7b\").hexdigest() == \"9fe820f638b4bf0a16581ff1d48062b2bf950ecf\", \"value of answer0_2 is not correct\"\n",
    "assert sha1(str(answer0_2).encode(\"utf-8\")+b\"7997af0bedd9ee7b\").hexdigest() == \"9eb904f0a92efb15f860aac0fcb946bf4594eb93\", \"correct string value of answer0_2 but incorrect case of letters\"\n",
    "\n",
    "print('Success!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "317f20c17f2d4d8d5827409d56a65384",
     "grade": false,
     "grade_id": "cell-122d814c0cfa7294",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "**Question 0.3** Multiple Choice: \n",
    "<br> {points: 1}\n",
    "\n",
    "For which scenario would using one of the `groupby` + `mean` be appropriate?\n",
    "\n",
    "A. To apply the same function to every row. \n",
    "\n",
    "B. To apply the same function to every column.\n",
    "\n",
    "C. To apply the same function to groups of rows. \n",
    "\n",
    "D. To apply the same function to groups of columns.\n",
    "\n",
    "*Assign your answer to an object called `answer0_3`.  Make sure your answer is an uppercase letter and is surrounded by quotation marks (e.g. `\"F\"`).*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "e966f4ad309952a5427ec79107785f91",
     "grade": false,
     "grade_id": "cell-85fb659000512dcd",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# your code here\n",
    "raise NotImplementedError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "max_height": 100,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "56580388043618e6ea0047b7faddfcd8",
     "grade": true,
     "grade_id": "cell-386ada4b41ae9cae",
     "locked": true,
     "points": 3,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "from hashlib import sha1\n",
    "assert sha1(str(type(answer0_3)).encode(\"utf-8\")+b\"94e9cafdb751f408\").hexdigest() == \"a67cf1bddc9d68278bdd0dcb0652b7d2fa3f9bca\", \"type of answer0_3 is not str. answer0_3 should be an str\"\n",
    "assert sha1(str(len(answer0_3)).encode(\"utf-8\")+b\"94e9cafdb751f408\").hexdigest() == \"dfccc8cf0d0985312be7c15a9dbc4eb3edcbd286\", \"length of answer0_3 is not correct\"\n",
    "assert sha1(str(answer0_3.lower()).encode(\"utf-8\")+b\"94e9cafdb751f408\").hexdigest() == \"3bf82a1c9785cc50c171e450e412321e2c5c904d\", \"value of answer0_3 is not correct\"\n",
    "assert sha1(str(answer0_3).encode(\"utf-8\")+b\"94e9cafdb751f408\").hexdigest() == \"99744e1871b5de86e44a835cafd8ebc618b7ba9b\", \"correct string value of answer0_3 but incorrect case of letters\"\n",
    "\n",
    "print('Success!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "8ce794daf58240c87dc3816f2d6868f2",
     "grade": false,
     "grade_id": "cell-fa871a669adbf899",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## 1. Assessing avocado prices to inform restaurant menu planning\n",
    "\n",
    "It is a well known that millennials LOVE avocado toast (joking...well mostly 😉), and so many restaurants will offer menu items that centre around this delicious food! Like many food items, avocado prices fluctuate. So a restaurant who wants to maximize profits on avocado-containing dishes might ask if there are times when the price of avocados are less expensive to purchase? If such times exist, this is when the restaurant should put avocado-containing dishes on the menu to maximize their profits for those dishes. \n",
    "\n",
    "<img align=\"left\" src=\"https://www.averiecooks.com/wp-content/uploads/2017/07/egghole-2.jpg\" width=\"150\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "6f879185b3739704219c1e2c00a8c06c",
     "grade": false,
     "grade_id": "cell-f911d0be7d9dc7f7",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "*Source: https://www.averiecooks.com/egg-hole-avocado-toast/*\n",
    "\n",
    "To answer this question we will analyze a data set of avocado sales from multiple US markets. This data was downloaded from the [Hass Avocado Board website](http://www.hassavocadoboard.com/) in May of 2018 & compiled into a single CSV. Each row in the data set contains weekly sales data for a region. The data set spans the year 2015-2018.\n",
    "\n",
    "Some relevant columns in the dataset:\n",
    "\n",
    "- `Date` - The date in year-month-day format\n",
    "- `average_price` - The average price of a single avocado\n",
    "- `type` - conventional or organic\n",
    "- `yr` - The year\n",
    "- `region` - The city or region of the observation\n",
    "- `small_hass_volume` in pounds (lbs)\t\n",
    "- `large_hass_volume` in pounds (lbs)\t\t\n",
    "- `extra_l_hass_volume`\tin pounds (lbs)\t\n",
    "- `wk` - integer number for the calendar week in the year (e.g., first week of January is 1, and last week of December is 52).\n",
    "\n",
    "To answer our question of whether there are times in the year when avocados are typically less expensive (and thus we can make more profitable menu items with them at a restaurant) we will want to create a scatter plot of `average_price` (y-axis) versus `Date` (x-axis)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "8a026996f8a6e53e7a7369de878a4100",
     "grade": false,
     "grade_id": "cell-acb1e485a76f043b",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "**Question 1.1** Multiple Choice:\n",
    "<br> {points: 1}\n",
    "\n",
    "Which of the following is not included in the `csv` file?\n",
    "\n",
    "A. Average price of a single avocado.\n",
    "\n",
    "B. The farming practice (production with/without the use of chemicals). \n",
    "\n",
    "C. Average price of a bag of avocados.\n",
    "\n",
    "D. All options are included in the data set.\n",
    "\n",
    "*Assign your answer to an object called `answer1_1`. Make sure your answer is an uppercase letter and is surrounded by quotation marks (e.g. `\"F\"`).* "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "d236b41c7081f0845aba209e0a822347",
     "grade": false,
     "grade_id": "cell-39161480e71d9b43",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# your code here\n",
    "raise NotImplementedError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "max_height": 100,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "47dcd16a63f85d2ad9947e82e2dddf0f",
     "grade": true,
     "grade_id": "cell-1c278f180e20468f",
     "locked": true,
     "points": 3,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "from hashlib import sha1\n",
    "assert sha1(str(type(answer1_1)).encode(\"utf-8\")+b\"58555bac63b4a151\").hexdigest() == \"648b96e05fb00778b4c16ff3a967982c98d44b31\", \"type of answer1_1 is not str. answer1_1 should be an str\"\n",
    "assert sha1(str(len(answer1_1)).encode(\"utf-8\")+b\"58555bac63b4a151\").hexdigest() == \"dd84b8c65f906b287603819a38c89a56eef17e34\", \"length of answer1_1 is not correct\"\n",
    "assert sha1(str(answer1_1.lower()).encode(\"utf-8\")+b\"58555bac63b4a151\").hexdigest() == \"6ee8e8fc127c415013f697f3b445195de2685553\", \"value of answer1_1 is not correct\"\n",
    "assert sha1(str(answer1_1).encode(\"utf-8\")+b\"58555bac63b4a151\").hexdigest() == \"b948197cabd178d3f0b3c84b907c0ba286360899\", \"correct string value of answer1_1 but incorrect case of letters\"\n",
    "\n",
    "print('Success!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "1fa28c377d50527d3a5230311f1c684e",
     "grade": false,
     "grade_id": "cell-56154f20b1c3af0b",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "**Question 1.2** Multiple Choice:\n",
    "<br> {points: 1}\n",
    "\n",
    "The rows in the data frame represent:\n",
    "\n",
    "A. daily avocado sales data for a region\n",
    "\n",
    "B. weekly avocado sales data for a region\n",
    "\n",
    "C. bi-weekly avocado sales data for a region\n",
    "\n",
    "D. yearly avocado sales data for a region\n",
    "\n",
    "*Assign your answer to an object called `answer1_2`. Make sure your answer is an uppercase letter and is surrounded by quotation marks (e.g. `\"F\"`).*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "dbe4d74869841a52e2bc947887d5afb2",
     "grade": false,
     "grade_id": "cell-1d614695a9d4a4f9",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# your code here\n",
    "raise NotImplementedError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "max_height": 100,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "f665b64088426e1312bc6d1826880002",
     "grade": true,
     "grade_id": "cell-6adfe52857aa9333",
     "locked": true,
     "points": 3,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "from hashlib import sha1\n",
    "assert sha1(str(type(answer1_2)).encode(\"utf-8\")+b\"5cdd7d99b2df7da0\").hexdigest() == \"2a10d841502b26fe90eb6b0cb4b4a37b788ccf56\", \"type of answer1_2 is not str. answer1_2 should be an str\"\n",
    "assert sha1(str(len(answer1_2)).encode(\"utf-8\")+b\"5cdd7d99b2df7da0\").hexdigest() == \"584d38a8e39e0c3e611133c86b133e669db1857d\", \"length of answer1_2 is not correct\"\n",
    "assert sha1(str(answer1_2.lower()).encode(\"utf-8\")+b\"5cdd7d99b2df7da0\").hexdigest() == \"36eb4e8dfc9590d13e83b4976c04e6eeacfdd302\", \"value of answer1_2 is not correct\"\n",
    "assert sha1(str(answer1_2).encode(\"utf-8\")+b\"5cdd7d99b2df7da0\").hexdigest() == \"f5218225939a23c2da2f256ffe478959c16026b2\", \"correct string value of answer1_2 but incorrect case of letters\"\n",
    "\n",
    "print('Success!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "90a4dee0b159c2090552aacf6083e1ea",
     "grade": false,
     "grade_id": "cell-7e263f37387da63d",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "**Question 1.3** \n",
    "<br> {points: 1}\n",
    "\n",
    "The first step to plotting total volume against average price is to read the file `avocado_prices.csv` using the shortest relative path. The data file was given to you along with this worksheet, but you will have to look to see where it is in the `data` directory to correctly load it. When you do this, you should also preview the file to help you choose an appropriate `.read_*` function to read the data.\n",
    "\n",
    "*Assign your answer to an object called `avocado`.* "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "08aaa424342cce98facbc1424c23dfbe",
     "grade": false,
     "grade_id": "cell-434656ab0b99d8bd",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# ___ = ___(\"___\")\n",
    "\n",
    "# your code here\n",
    "raise NotImplementedError\n",
    "avocado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "max_height": 100,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "cc20f687128a75a828c6c2056cfaeb51",
     "grade": true,
     "grade_id": "cell-a968fbd8b038ba4b",
     "locked": true,
     "points": 3,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "from hashlib import sha1\n",
    "assert sha1(str(type(avocado is None)).encode(\"utf-8\")+b\"01e1ca663d7919ea\").hexdigest() == \"4806d5b3d3ab634224f6daab678c8a2896179475\", \"type of avocado is None is not bool. avocado is None should be a bool\"\n",
    "assert sha1(str(avocado is None).encode(\"utf-8\")+b\"01e1ca663d7919ea\").hexdigest() == \"a1aa9dabe44451b7c6ce4a4a1d01a43aee944789\", \"boolean value of avocado is None is not correct\"\n",
    "\n",
    "assert sha1(str(type(avocado)).encode(\"utf-8\")+b\"6c4ef97df9a36795\").hexdigest() == \"cff32071e83c8054c99601f1868691d0921595f2\", \"type of type(avocado) is not correct\"\n",
    "\n",
    "assert sha1(str(type(avocado.shape)).encode(\"utf-8\")+b\"9f47bf535c511c29\").hexdigest() == \"3e2c639b013a4a7165155653339f74f1aef16e08\", \"type of avocado.shape is not tuple. avocado.shape should be a tuple\"\n",
    "assert sha1(str(len(avocado.shape)).encode(\"utf-8\")+b\"9f47bf535c511c29\").hexdigest() == \"c31baac0debd31eada1e39209bbff6b1f2e2bb72\", \"length of avocado.shape is not correct\"\n",
    "assert sha1(str(sorted(map(str, avocado.shape))).encode(\"utf-8\")+b\"9f47bf535c511c29\").hexdigest() == \"c0a6f340b2608c1c875b7b53933609820c333fdb\", \"values of avocado.shape are not correct\"\n",
    "assert sha1(str(avocado.shape).encode(\"utf-8\")+b\"9f47bf535c511c29\").hexdigest() == \"b48ef41dc507fd2e750152888f984cab31fdf7e8\", \"order of elements of avocado.shape is not correct\"\n",
    "\n",
    "assert sha1(str(type(avocado.columns.values)).encode(\"utf-8\")+b\"20b68d3a01878911\").hexdigest() == \"a846460ce4d0967f555d5bc0e8fd520572399cd6\", \"type of avocado.columns.values is not correct\"\n",
    "assert sha1(str(avocado.columns.values).encode(\"utf-8\")+b\"20b68d3a01878911\").hexdigest() == \"6a7b6b465bce153aef784b93f289d59315c223dd\", \"value of avocado.columns.values is not correct\"\n",
    "\n",
    "print('Success!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "7611db6be106b97fedf0ff0bf4023e9f",
     "grade": false,
     "grade_id": "cell-31ff875d27e26cf4",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Before we get started doing our analysis, let's learn about the chaining notation, as it can be very helpful when doing data analysis in Python!\n",
    "\n",
    "### Chaining Notation\n",
    "Chaining Notation allows you to chain together different functions - it takes the output of one statement and makes it the input of the next statement. It is used for making multiple method calls on the same object, using the object reference just once.\n",
    "\n",
    "If we wanted to subset the avocado data to obtain just the average prices for organic avocados, we would need to first filter the `type` column using `[]` for the rows where the type is organic. Then, we again use `[]` to get just the average price column.\n",
    "\n",
    "Below we illustrate how to do this using chaining notation instead of creating an intermediate object as we have in past worksheets: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "c293dc400267e1d24e6e01a790fa470a",
     "grade": false,
     "grade_id": "cell-f88c70052691a93e",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# run this cell\n",
    "avocado[avocado[\"type\"] == \"organic\"][\"average_price\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that we could do the equivalent operation using the `loc` function in a single step. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run this cell\n",
    "avocado.loc[avocado[\"type\"] == \"organic\", \"average_price\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "7c89d17600705e7016c7708d5448173a",
     "grade": false,
     "grade_id": "cell-80ee505836e01bce",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**Question 1.4**\n",
    "\n",
    "{points: 1}\n",
    "\n",
    "To answer our question, let's now create the scatter plot where we plot `average_price` on the y-axis versus `Date` on the x-axis. Fill in the `___` in the cell below. \n",
    "\n",
    "*Assign your answer to an object called `avocado_plot`. Don't forget to create proper English axis labels.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "18d1089d858a8a426c699662fac006cf",
     "grade": false,
     "grade_id": "cell-fd8156be131e6ab6",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# ___ = (\n",
    "#     alt.Chart(___)\n",
    "#     .mark_point()\n",
    "#     .encode(x=alt.X(___, title=___), y=alt.Y(___, title=___))\n",
    "#     .configure_axis(labelFontSize=20, titleFontSize=20)\n",
    "# )\n",
    "\n",
    "# your code here\n",
    "raise NotImplementedError\n",
    "avocado_plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "max_height": 100,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "6b77266a737c12baf336758b7323b352",
     "grade": true,
     "grade_id": "cell-89b7338558e28dbc",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "from hashlib import sha1\n",
    "assert sha1(str(type(avocado_plot is None)).encode(\"utf-8\")+b\"600b7797911e51b4\").hexdigest() == \"0b6f8ce954bfca5f230b97f7c63d65f1f162cf2d\", \"type of avocado_plot is None is not bool. avocado_plot is None should be a bool\"\n",
    "assert sha1(str(avocado_plot is None).encode(\"utf-8\")+b\"600b7797911e51b4\").hexdigest() == \"589f1b267363628bbd2ce71315e47ca7c0d17dd1\", \"boolean value of avocado_plot is None is not correct\"\n",
    "\n",
    "assert sha1(str(type(avocado_plot.encoding.x.field)).encode(\"utf-8\")+b\"631cf12f8acd22b6\").hexdigest() == \"24ca7615d9c7f88266b429963d3fbe826c527b3d\", \"type of avocado_plot.encoding.x.field is not str. avocado_plot.encoding.x.field should be an str\"\n",
    "assert sha1(str(len(avocado_plot.encoding.x.field)).encode(\"utf-8\")+b\"631cf12f8acd22b6\").hexdigest() == \"553ed19c72559eadee82982c812592bb485d1865\", \"length of avocado_plot.encoding.x.field is not correct\"\n",
    "assert sha1(str(avocado_plot.encoding.x.field.lower()).encode(\"utf-8\")+b\"631cf12f8acd22b6\").hexdigest() == \"b9453d482a234a27e9777ec42385b8df991ecc2a\", \"value of avocado_plot.encoding.x.field is not correct\"\n",
    "assert sha1(str(avocado_plot.encoding.x.field).encode(\"utf-8\")+b\"631cf12f8acd22b6\").hexdigest() == \"eb76653e35de1f00ece7f7b163bdbb6b30f5f13e\", \"correct string value of avocado_plot.encoding.x.field but incorrect case of letters\"\n",
    "\n",
    "assert sha1(str(type(avocado_plot.encoding.y.field)).encode(\"utf-8\")+b\"45d65cc77b5736a0\").hexdigest() == \"bd00f57fee0db4600e204a10518878fa2190b0e3\", \"type of avocado_plot.encoding.y.field is not str. avocado_plot.encoding.y.field should be an str\"\n",
    "assert sha1(str(len(avocado_plot.encoding.y.field)).encode(\"utf-8\")+b\"45d65cc77b5736a0\").hexdigest() == \"2625415e8a1e7ccefbf935cb5d8172f6e521df86\", \"length of avocado_plot.encoding.y.field is not correct\"\n",
    "assert sha1(str(avocado_plot.encoding.y.field.lower()).encode(\"utf-8\")+b\"45d65cc77b5736a0\").hexdigest() == \"c67027425f88050e4dd1980c6056f6812ff0533b\", \"value of avocado_plot.encoding.y.field is not correct\"\n",
    "assert sha1(str(avocado_plot.encoding.y.field).encode(\"utf-8\")+b\"45d65cc77b5736a0\").hexdigest() == \"c67027425f88050e4dd1980c6056f6812ff0533b\", \"correct string value of avocado_plot.encoding.y.field but incorrect case of letters\"\n",
    "\n",
    "assert sha1(str(type(avocado_plot.mark)).encode(\"utf-8\")+b\"8fcb9b9cf6e65fdc\").hexdigest() == \"370c113606197d5e0ca3716d82168b23f7f45aba\", \"type of avocado_plot.mark is not str. avocado_plot.mark should be an str\"\n",
    "assert sha1(str(len(avocado_plot.mark)).encode(\"utf-8\")+b\"8fcb9b9cf6e65fdc\").hexdigest() == \"1f814737d9c427f214ff9d0907110ef1f71635bf\", \"length of avocado_plot.mark is not correct\"\n",
    "assert sha1(str(avocado_plot.mark.lower()).encode(\"utf-8\")+b\"8fcb9b9cf6e65fdc\").hexdigest() == \"75c86c51328e596fc59b4525ddcb26c913ffbf83\", \"value of avocado_plot.mark is not correct\"\n",
    "assert sha1(str(avocado_plot.mark).encode(\"utf-8\")+b\"8fcb9b9cf6e65fdc\").hexdigest() == \"75c86c51328e596fc59b4525ddcb26c913ffbf83\", \"correct string value of avocado_plot.mark but incorrect case of letters\"\n",
    "\n",
    "assert sha1(str(type(avocado_plot.encoding.y.title != avocado_plot.encoding.y.field)).encode(\"utf-8\")+b\"39b6c57b996f7fc0\").hexdigest() == \"66e6ab2058f7e6cab64fedb30f9cd4b53aaf2b48\", \"type of avocado_plot.encoding.y.title != avocado_plot.encoding.y.field is not bool. avocado_plot.encoding.y.title != avocado_plot.encoding.y.field should be a bool\"\n",
    "assert sha1(str(avocado_plot.encoding.y.title != avocado_plot.encoding.y.field).encode(\"utf-8\")+b\"39b6c57b996f7fc0\").hexdigest() == \"1ac41c3b12593a534e85c647d58d48c006844e81\", \"boolean value of avocado_plot.encoding.y.title != avocado_plot.encoding.y.field is not correct\"\n",
    "\n",
    "print('Success!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "86f6e3df6a50f63a8b5fd49234680a37",
     "grade": false,
     "grade_id": "cell-f5bf4e53775781f8",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "This is a big plot! You can scroll and maybe see some trends, but really what we see in the plot above is not very informative. Why? Because there is a lot of overplotting (data points sitting on top of other data points). What can we do? One solution is to reduce/aggregate the data in a meaningful way to help anwer our question. Remember that we are interested in determining if there are times when the price of avocados are less expensive so that we can recommend when restaurants should put dishes on the menu that contain avocado to maximize their profits for those dishes.\n",
    "\n",
    "In the data we plotted above, each row is the total sales for avocados for that region for each year. Lets use `.groupby` + `.mean` calculate the average price for each week across years and region. We can then plot that aggregated price against the week and perhaps get a clearer picture."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "0951f84f24205b00aca078de96c04031",
     "grade": false,
     "grade_id": "cell-07909555b45c6c28",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "**Question 1.5**\n",
    "<br> {points: 1}\n",
    "\n",
    "Create a reduced/aggregated version of the `avocado` data set and name it `avocado_aggregate`. To do this you will want to `groupby` the `wk` column and then use `mean` to calculate the average price. We pass `numeric_only=True` to tell pandas that we want the mean only of the numeric columns. Note: after applying `groupby` to the dataframe, it will automatically set the `groupby` column as index. Since we would like to use the `wk` column later in the plot, we would apply `reset_index` to reset the index for the dataframe.\n",
    "\n",
    "*Assign your answer to an object called `avocado_aggregate`.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "5aec532f49434ebec6a1885829e1f0aa",
     "grade": false,
     "grade_id": "cell-25fc8f43f1d193db",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# ___ = ___.groupby(___).mean(numeric_only=True).reset_index()\n",
    "\n",
    "# your code here\n",
    "raise NotImplementedError\n",
    "avocado_aggregate.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "max_height": 100,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "6fd56aa96900db2f9c648e6336744362",
     "grade": true,
     "grade_id": "cell-81ec3e479caeb7d7",
     "locked": true,
     "points": 3,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "from hashlib import sha1\n",
    "assert str(type(avocado_aggregate is None)) == \"<class 'bool'>\", \"type of avocado_aggregate is None is not bool. avocado_aggregate is None should be a bool\"\n",
    "assert str(avocado_aggregate is None) == \"False\", \"boolean value of avocado_aggregate is None is not correct\"\n",
    "\n",
    "assert str(type(avocado_aggregate.shape)) == \"<class 'tuple'>\", \"type of avocado_aggregate.shape is not tuple. avocado_aggregate.shape should be a tuple\"\n",
    "assert str(len(avocado_aggregate.shape)) == \"2\", \"length of avocado_aggregate.shape is not correct\"\n",
    "assert str(sorted(map(str, avocado_aggregate.shape))) == \"['53', '6']\", \"values of avocado_aggregate.shape are not correct\"\n",
    "assert str(avocado_aggregate.shape) == \"(53, 6)\", \"order of elements of avocado_aggregate.shape is not correct\"\n",
    "\n",
    "assert sha1(str(type(sum(avocado_aggregate.wk))).encode(\"utf-8\")+b\"1997aa27cd8dd97b\").hexdigest() == \"61a6bcbfd81e736a389650dca4b023d82f59642e\", \"type of sum(avocado_aggregate.wk) is not int. Please make sure it is int and not np.int64, etc. You can cast your value into an int using int()\"\n",
    "assert sha1(str(sum(avocado_aggregate.wk)).encode(\"utf-8\")+b\"1997aa27cd8dd97b\").hexdigest() == \"4998c1822b8134b55717b050c1f029177c38275f\", \"value of sum(avocado_aggregate.wk) is not correct\"\n",
    "\n",
    "assert sha1(str(type(sum(avocado_aggregate.average_price))).encode(\"utf-8\")+b\"c542bae885cd821e\").hexdigest() == \"5c166a167faf47a57f2442e49583d202508281c7\", \"type of sum(avocado_aggregate.average_price) is not float. Please make sure it is float and not np.float64, etc. You can cast your value into a float using float()\"\n",
    "assert sha1(str(round(sum(avocado_aggregate.average_price), 2)).encode(\"utf-8\")+b\"c542bae885cd821e\").hexdigest() == \"76331cdb2fd13086a4cd0ffe1d48d5d98c4f617a\", \"value of sum(avocado_aggregate.average_price) is not correct (rounded to 2 decimal places)\"\n",
    "\n",
    "print('Success!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "fbba5212c3a8a5f630eb507c02a70989",
     "grade": false,
     "grade_id": "cell-aa0422ac0aade558",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "**Question 1.6**\n",
    "<br> {points: 1}\n",
    "\n",
    "Now let's take the `avocado_aggregate` data frame and use it to create a scatter plot where we plot `average_price` on the y-axis versus `wk` on the x-axis. \n",
    "\n",
    "*Assign your answer to an object called `avocado_aggregate_plot`. Don't forget to create proper English axis labels.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "3a05e33cc843beec638109468ca7e4b8",
     "grade": false,
     "grade_id": "cell-e081bf3fd0e40162",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# ___ = (\n",
    "#     alt.Chart(___)\n",
    "#     .mark_point()\n",
    "#     .encode(\n",
    "#         x=alt.X(___, title=___),\n",
    "#         y=alt.Y(\n",
    "#             ___,\n",
    "#             title=___,\n",
    "#             scale=alt.Scale(zero=False),\n",
    "#         ),\n",
    "#     )\n",
    "#     .configure_axis(labelFontSize=20, titleFontSize=20)\n",
    "# )\n",
    "\n",
    "# your code here\n",
    "raise NotImplementedError\n",
    "avocado_aggregate_plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "max_height": 100,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "d4a0947c18d46471ab37538ea186fa02",
     "grade": true,
     "grade_id": "cell-d70b07b4c2dc0202",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "from hashlib import sha1\n",
    "assert sha1(str(type(avocado_aggregate_plot is None)).encode(\"utf-8\")+b\"c833ae582d7d1912\").hexdigest() == \"8ba72fd8f4877e3f139ccabef48a8531e5c5dc2f\", \"type of avocado_aggregate_plot is None is not bool. avocado_aggregate_plot is None should be a bool\"\n",
    "assert sha1(str(avocado_aggregate_plot is None).encode(\"utf-8\")+b\"c833ae582d7d1912\").hexdigest() == \"5a06f1c3169994ba84ff4db2e9aeffb9f33d4159\", \"boolean value of avocado_aggregate_plot is None is not correct\"\n",
    "\n",
    "assert sha1(str(type(avocado_aggregate_plot.encoding.x.field)).encode(\"utf-8\")+b\"f3589600e6098723\").hexdigest() == \"95e77c207be5a55e7524e8f1a411c88f201e7af5\", \"type of avocado_aggregate_plot.encoding.x.field is not str. avocado_aggregate_plot.encoding.x.field should be an str\"\n",
    "assert sha1(str(len(avocado_aggregate_plot.encoding.x.field)).encode(\"utf-8\")+b\"f3589600e6098723\").hexdigest() == \"b92c2b0aa2ec6f15e1dbc29b0197b719e8eb0af7\", \"length of avocado_aggregate_plot.encoding.x.field is not correct\"\n",
    "assert sha1(str(avocado_aggregate_plot.encoding.x.field.lower()).encode(\"utf-8\")+b\"f3589600e6098723\").hexdigest() == \"2418e2419676549a3fde68fc434c5333bbb95179\", \"value of avocado_aggregate_plot.encoding.x.field is not correct\"\n",
    "assert sha1(str(avocado_aggregate_plot.encoding.x.field).encode(\"utf-8\")+b\"f3589600e6098723\").hexdigest() == \"2418e2419676549a3fde68fc434c5333bbb95179\", \"correct string value of avocado_aggregate_plot.encoding.x.field but incorrect case of letters\"\n",
    "\n",
    "assert sha1(str(type(avocado_aggregate_plot.encoding.y.field)).encode(\"utf-8\")+b\"34139595f3131645\").hexdigest() == \"d28c46d1a27b4069b5619df8f9ffa4d12a646f66\", \"type of avocado_aggregate_plot.encoding.y.field is not str. avocado_aggregate_plot.encoding.y.field should be an str\"\n",
    "assert sha1(str(len(avocado_aggregate_plot.encoding.y.field)).encode(\"utf-8\")+b\"34139595f3131645\").hexdigest() == \"018eec99b25a597861f44ed58001c5877fdd9c19\", \"length of avocado_aggregate_plot.encoding.y.field is not correct\"\n",
    "assert sha1(str(avocado_aggregate_plot.encoding.y.field.lower()).encode(\"utf-8\")+b\"34139595f3131645\").hexdigest() == \"786c36a6f860f20a0bbccf57a7c2fc3283563524\", \"value of avocado_aggregate_plot.encoding.y.field is not correct\"\n",
    "assert sha1(str(avocado_aggregate_plot.encoding.y.field).encode(\"utf-8\")+b\"34139595f3131645\").hexdigest() == \"786c36a6f860f20a0bbccf57a7c2fc3283563524\", \"correct string value of avocado_aggregate_plot.encoding.y.field but incorrect case of letters\"\n",
    "\n",
    "assert sha1(str(type(avocado_aggregate_plot.mark)).encode(\"utf-8\")+b\"101832a8e843f988\").hexdigest() == \"181a161f7809d3109c6ac2eb1f5bbf7dea9dc46f\", \"type of avocado_aggregate_plot.mark is not str. avocado_aggregate_plot.mark should be an str\"\n",
    "assert sha1(str(len(avocado_aggregate_plot.mark)).encode(\"utf-8\")+b\"101832a8e843f988\").hexdigest() == \"c42c7b08c09c6a30bd831263195e70475ac6f69d\", \"length of avocado_aggregate_plot.mark is not correct\"\n",
    "assert sha1(str(avocado_aggregate_plot.mark.lower()).encode(\"utf-8\")+b\"101832a8e843f988\").hexdigest() == \"fc09b63c5b57b2044b97fba88f2def03ccd26e5d\", \"value of avocado_aggregate_plot.mark is not correct\"\n",
    "assert sha1(str(avocado_aggregate_plot.mark).encode(\"utf-8\")+b\"101832a8e843f988\").hexdigest() == \"fc09b63c5b57b2044b97fba88f2def03ccd26e5d\", \"correct string value of avocado_aggregate_plot.mark but incorrect case of letters\"\n",
    "\n",
    "assert sha1(str(type(avocado_aggregate_plot.encoding.x.title != avocado_aggregate_plot.encoding.x.field)).encode(\"utf-8\")+b\"3acc9bdfde34e6e9\").hexdigest() == \"d28eddfdef85851292b542bdc7a0fb85cc6c992a\", \"type of avocado_aggregate_plot.encoding.x.title != avocado_aggregate_plot.encoding.x.field is not bool. avocado_aggregate_plot.encoding.x.title != avocado_aggregate_plot.encoding.x.field should be a bool\"\n",
    "assert sha1(str(avocado_aggregate_plot.encoding.x.title != avocado_aggregate_plot.encoding.x.field).encode(\"utf-8\")+b\"3acc9bdfde34e6e9\").hexdigest() == \"d9492c91110bfe7f3185892017d8e12720b750b3\", \"boolean value of avocado_aggregate_plot.encoding.x.title != avocado_aggregate_plot.encoding.x.field is not correct\"\n",
    "\n",
    "assert sha1(str(type(avocado_aggregate_plot.encoding.y.title != avocado_aggregate_plot.encoding.y.field)).encode(\"utf-8\")+b\"199d38cbca796085\").hexdigest() == \"82b5b3c7b3868565c83516713fbd73466842abc5\", \"type of avocado_aggregate_plot.encoding.y.title != avocado_aggregate_plot.encoding.y.field is not bool. avocado_aggregate_plot.encoding.y.title != avocado_aggregate_plot.encoding.y.field should be a bool\"\n",
    "assert sha1(str(avocado_aggregate_plot.encoding.y.title != avocado_aggregate_plot.encoding.y.field).encode(\"utf-8\")+b\"199d38cbca796085\").hexdigest() == \"88b4d34d27a7f4d435096ff3bc2d7a305b47fb56\", \"boolean value of avocado_aggregate_plot.encoding.y.title != avocado_aggregate_plot.encoding.y.field is not correct\"\n",
    "\n",
    "print('Success!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "536f294b841952b053e6f231262c2319",
     "grade": false,
     "grade_id": "cell-b8dfe798ae35428d",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "We can now see that the prices of avocados does indeed fluctuate throughout the year. And we could use this information to recommend to restaurants that if they want to maximize profit from menu items that contain avocados, they should only offer them on the menu roughly between December and May. \n",
    "\n",
    "Why might this happen? Perhaps price has something to do with supply? We can also use this data set to get some insight into that question by plotting total avocado volume (y-axis) versus week. To do this, we will first have to create a column called `total_volume` whose value is the sum of the small, large and extra large-sized avocado volumes. To do this we will have to go back to the original `avocado` data frame we loaded."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "5c294fea4a8f49eb5936c7df453ca4a8",
     "grade": false,
     "grade_id": "cell-11acd47d959662ee",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "**Question 1.7**\n",
    "<br> {points: 1}\n",
    "\n",
    "Our next step to plotting `total_volume` per week against week is to create a new column in the `avocado` data frame called `total_volume` which is equal to the sum of all three volume columns:\n",
    "\n",
    "Fill in the `___` in the cell below. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "1e6d243c14d15db505be8f4e1e1d15ce",
     "grade": false,
     "grade_id": "cell-20ec4476bb9540db",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# ___[___] = ___ + ___ + ___\n",
    "\n",
    "\n",
    "# your code here\n",
    "raise NotImplementedError\n",
    "avocado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "max_height": 100,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "2b86979fb9476302ae965a040ffa30cb",
     "grade": true,
     "grade_id": "cell-1b331febb2ce27b5",
     "locked": true,
     "points": 3,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "from hashlib import sha1\n",
    "assert str(type(avocado is None)) == \"<class 'bool'>\", \"type of avocado is None is not bool. avocado is None should be a bool\"\n",
    "assert str(avocado is None) == \"False\", \"boolean value of avocado is None is not correct\"\n",
    "\n",
    "assert str(type(avocado.shape)) == \"<class 'tuple'>\", \"type of avocado.shape is not tuple. avocado.shape should be a tuple\"\n",
    "assert str(len(avocado.shape)) == \"2\", \"length of avocado.shape is not correct\"\n",
    "assert str(sorted(map(str, avocado.shape))) == \"['10', '17911']\", \"values of avocado.shape are not correct\"\n",
    "assert str(avocado.shape) == \"(17911, 10)\", \"order of elements of avocado.shape is not correct\"\n",
    "\n",
    "assert sha1(str(type(sum(avocado.total_volume.dropna()))).encode(\"utf-8\")+b\"99d3ba6e34ddc7da\").hexdigest() == \"de9a67c246c4f085e496ddfe9b5a9e35469fbb0a\", \"type of sum(avocado.total_volume.dropna()) is not float. Please make sure it is float and not np.float64, etc. You can cast your value into a float using float()\"\n",
    "assert sha1(str(round(sum(avocado.total_volume.dropna()), 2)).encode(\"utf-8\")+b\"99d3ba6e34ddc7da\").hexdigest() == \"2b03f6b806f8c4ba80f3a3bb247dd92bce774ee1\", \"value of sum(avocado.total_volume.dropna()) is not correct (rounded to 2 decimal places)\"\n",
    "\n",
    "print('Success!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "25d9eb34d5c359093e35b0249e5ffbb9",
     "grade": false,
     "grade_id": "cell-97fc42a8c2d802d8",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "**Question 1.8** \n",
    "<br> {points: 1}\n",
    "\n",
    "Now, create another reduced/aggregated version of the `avocado` data frame and name it `avocado_aggregate_2`. To do this you will want to `groupby` the `wk` column and then use `mean` to calculate the average total volume."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "3e5e9ff06a9512c6f27886166a2f65b7",
     "grade": false,
     "grade_id": "cell-d3d0314b483daf3c",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# ___ = ___.groupby(___).mean().reset_index()\n",
    "\n",
    "\n",
    "# your code here\n",
    "raise NotImplementedError\n",
    "avocado_aggregate_2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "max_height": 100,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "1a7622c30632b9338a7842449c36625f",
     "grade": true,
     "grade_id": "cell-975338ad4661f5af",
     "locked": true,
     "points": 3,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "from hashlib import sha1\n",
    "assert str(type(avocado_aggregate_2 is None)) == \"<class 'bool'>\", \"type of avocado_aggregate_2 is None is not bool. avocado_aggregate_2 is None should be a bool\"\n",
    "assert str(avocado_aggregate_2 is None) == \"False\", \"boolean value of avocado_aggregate_2 is None is not correct\"\n",
    "\n",
    "assert str(type(avocado_aggregate_2.shape)) == \"<class 'tuple'>\", \"type of avocado_aggregate_2.shape is not tuple. avocado_aggregate_2.shape should be a tuple\"\n",
    "assert str(len(avocado_aggregate_2.shape)) == \"2\", \"length of avocado_aggregate_2.shape is not correct\"\n",
    "assert str(sorted(map(str, avocado_aggregate_2.shape))) == \"['53', '7']\", \"values of avocado_aggregate_2.shape are not correct\"\n",
    "assert str(avocado_aggregate_2.shape) == \"(53, 7)\", \"order of elements of avocado_aggregate_2.shape is not correct\"\n",
    "\n",
    "assert sha1(str(type(sum(avocado_aggregate_2.total_volume))).encode(\"utf-8\")+b\"9eef3280d3eca0a8\").hexdigest() == \"729e583ae652d2bba5435257fa1965f2b87a2eda\", \"type of sum(avocado_aggregate_2.total_volume) is not float. Please make sure it is float and not np.float64, etc. You can cast your value into a float using float()\"\n",
    "assert sha1(str(round(sum(avocado_aggregate_2.total_volume), 2)).encode(\"utf-8\")+b\"9eef3280d3eca0a8\").hexdigest() == \"3d6aaeb37a921f0d4e7eac48149d519ae139fa8b\", \"value of sum(avocado_aggregate_2.total_volume) is not correct (rounded to 2 decimal places)\"\n",
    "\n",
    "assert sha1(str(type(sum(avocado_aggregate_2.wk))).encode(\"utf-8\")+b\"a729d472f6b68854\").hexdigest() == \"08adf09c7e3fdaced0a21f406c10a5c04e847a17\", \"type of sum(avocado_aggregate_2.wk) is not int. Please make sure it is int and not np.int64, etc. You can cast your value into an int using int()\"\n",
    "assert sha1(str(sum(avocado_aggregate_2.wk)).encode(\"utf-8\")+b\"a729d472f6b68854\").hexdigest() == \"752877bbb4eb180338997ec7f16b2a46491915a4\", \"value of sum(avocado_aggregate_2.wk) is not correct\"\n",
    "\n",
    "print('Success!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "59114583ff055f715682d0748985136a",
     "grade": false,
     "grade_id": "cell-ea1a11950f66b4f5",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "**Question 1.10** \n",
    "<br> {points: 1}\n",
    "\n",
    "Now let's take the `avocado_aggregate_2` data frame and use it to create a scatter plot where we plot average `total_volume` (in pounds, lbs) on the y-axis versus `wk` on the x-axis. Assign your answer to an object called `avocado_aggregate_plot_2`. Don't forget to create proper English axis labels.\n",
    "\n",
    "> Hint: don't forget to include the units for volume in your data visualization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "dd4cf33554cc8643ece05b039b61fca8",
     "grade": false,
     "grade_id": "cell-11af7abfd81fb0f2",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# ___ = (\n",
    "#     alt.Chart(___)\n",
    "#     .___\n",
    "#     .encode(\n",
    "#         x=alt.X(___, title=___),\n",
    "#         y=alt.Y(\n",
    "#             ___,\n",
    "#             title=___,\n",
    "#             scale=alt.Scale(zero=False),\n",
    "#         ),\n",
    "#     )\n",
    "#     .configure_axis(labelFontSize=20, titleFontSize=20)\n",
    "# )\n",
    "\n",
    "# your code here\n",
    "raise NotImplementedError\n",
    "avocado_aggregate_plot_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "max_height": 100,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "815c20565309abf05f2968b60c236287",
     "grade": true,
     "grade_id": "cell-7a0b7fca31c9c8ec",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "from hashlib import sha1\n",
    "assert sha1(str(type(avocado_aggregate_plot_2 is None)).encode(\"utf-8\")+b\"822b79ad66c8fd3c\").hexdigest() == \"a11ae509cc120f0c0dfaad7d8e175842d23747cb\", \"type of avocado_aggregate_plot_2 is None is not bool. avocado_aggregate_plot_2 is None should be a bool\"\n",
    "assert sha1(str(avocado_aggregate_plot_2 is None).encode(\"utf-8\")+b\"822b79ad66c8fd3c\").hexdigest() == \"46388295e4ab59c74f331dadc7854fba618051c8\", \"boolean value of avocado_aggregate_plot_2 is None is not correct\"\n",
    "\n",
    "assert sha1(str(type(avocado_aggregate_plot_2.encoding.x.field)).encode(\"utf-8\")+b\"a4dd271a51da6c3e\").hexdigest() == \"17df094c4602bb70b4c9dcc5186994824245d2cf\", \"type of avocado_aggregate_plot_2.encoding.x.field is not str. avocado_aggregate_plot_2.encoding.x.field should be an str\"\n",
    "assert sha1(str(len(avocado_aggregate_plot_2.encoding.x.field)).encode(\"utf-8\")+b\"a4dd271a51da6c3e\").hexdigest() == \"f549460617108bcbe6b7d061bf2afa1522458691\", \"length of avocado_aggregate_plot_2.encoding.x.field is not correct\"\n",
    "assert sha1(str(avocado_aggregate_plot_2.encoding.x.field.lower()).encode(\"utf-8\")+b\"a4dd271a51da6c3e\").hexdigest() == \"a0088bbeaadfd3f7cfb4154ba09378f0d73708b9\", \"value of avocado_aggregate_plot_2.encoding.x.field is not correct\"\n",
    "assert sha1(str(avocado_aggregate_plot_2.encoding.x.field).encode(\"utf-8\")+b\"a4dd271a51da6c3e\").hexdigest() == \"a0088bbeaadfd3f7cfb4154ba09378f0d73708b9\", \"correct string value of avocado_aggregate_plot_2.encoding.x.field but incorrect case of letters\"\n",
    "\n",
    "assert sha1(str(type(avocado_aggregate_plot_2.encoding.y.field)).encode(\"utf-8\")+b\"1042233276873580\").hexdigest() == \"6aa2d594b875c89144fdbe0847cef95cb64a7a28\", \"type of avocado_aggregate_plot_2.encoding.y.field is not str. avocado_aggregate_plot_2.encoding.y.field should be an str\"\n",
    "assert sha1(str(len(avocado_aggregate_plot_2.encoding.y.field)).encode(\"utf-8\")+b\"1042233276873580\").hexdigest() == \"34275f8cb793d13250355fcb3ad91d4dbe04a5f1\", \"length of avocado_aggregate_plot_2.encoding.y.field is not correct\"\n",
    "assert sha1(str(avocado_aggregate_plot_2.encoding.y.field.lower()).encode(\"utf-8\")+b\"1042233276873580\").hexdigest() == \"da3e5c8e41a018b4e9a1b24aeb988aef66cdcac6\", \"value of avocado_aggregate_plot_2.encoding.y.field is not correct\"\n",
    "assert sha1(str(avocado_aggregate_plot_2.encoding.y.field).encode(\"utf-8\")+b\"1042233276873580\").hexdigest() == \"da3e5c8e41a018b4e9a1b24aeb988aef66cdcac6\", \"correct string value of avocado_aggregate_plot_2.encoding.y.field but incorrect case of letters\"\n",
    "\n",
    "assert sha1(str(type(avocado_aggregate_plot_2.mark)).encode(\"utf-8\")+b\"33bed7211d4d8813\").hexdigest() == \"78d7b7eaf5c62c8e1622e7b897e7bbf26c42ab5d\", \"type of avocado_aggregate_plot_2.mark is not str. avocado_aggregate_plot_2.mark should be an str\"\n",
    "assert sha1(str(len(avocado_aggregate_plot_2.mark)).encode(\"utf-8\")+b\"33bed7211d4d8813\").hexdigest() == \"18a9020bacf149262233aa7895280de08657285d\", \"length of avocado_aggregate_plot_2.mark is not correct\"\n",
    "assert sha1(str(avocado_aggregate_plot_2.mark.lower()).encode(\"utf-8\")+b\"33bed7211d4d8813\").hexdigest() == \"aebf2390f96f0b2bcacbae1fbb2ace789beeb204\", \"value of avocado_aggregate_plot_2.mark is not correct\"\n",
    "assert sha1(str(avocado_aggregate_plot_2.mark).encode(\"utf-8\")+b\"33bed7211d4d8813\").hexdigest() == \"aebf2390f96f0b2bcacbae1fbb2ace789beeb204\", \"correct string value of avocado_aggregate_plot_2.mark but incorrect case of letters\"\n",
    "\n",
    "assert sha1(str(type(avocado_aggregate_plot_2.encoding.x.title != avocado_aggregate_plot_2.encoding.x.field)).encode(\"utf-8\")+b\"67857a678244e4cd\").hexdigest() == \"1e731f9db0e036d438fb5f8e56aba7e21b7f69e5\", \"type of avocado_aggregate_plot_2.encoding.x.title != avocado_aggregate_plot_2.encoding.x.field is not bool. avocado_aggregate_plot_2.encoding.x.title != avocado_aggregate_plot_2.encoding.x.field should be a bool\"\n",
    "assert sha1(str(avocado_aggregate_plot_2.encoding.x.title != avocado_aggregate_plot_2.encoding.x.field).encode(\"utf-8\")+b\"67857a678244e4cd\").hexdigest() == \"1b1c5607ab6f631db4f84eac83e089402071d9c3\", \"boolean value of avocado_aggregate_plot_2.encoding.x.title != avocado_aggregate_plot_2.encoding.x.field is not correct\"\n",
    "\n",
    "assert sha1(str(type(avocado_aggregate_plot_2.encoding.y.title != avocado_aggregate_plot_2.encoding.y.field)).encode(\"utf-8\")+b\"13259fb7a530f330\").hexdigest() == \"24050a25dd06431817e37a9fe0ee7e6b9d462781\", \"type of avocado_aggregate_plot_2.encoding.y.title != avocado_aggregate_plot_2.encoding.y.field is not bool. avocado_aggregate_plot_2.encoding.y.title != avocado_aggregate_plot_2.encoding.y.field should be a bool\"\n",
    "assert sha1(str(avocado_aggregate_plot_2.encoding.y.title != avocado_aggregate_plot_2.encoding.y.field).encode(\"utf-8\")+b\"13259fb7a530f330\").hexdigest() == \"468ae4c430a01198b32994f44e1b77ba1204e930\", \"boolean value of avocado_aggregate_plot_2.encoding.y.title != avocado_aggregate_plot_2.encoding.y.field is not correct\"\n",
    "\n",
    "print('Success!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "0e53d03902f6638ab153df8dfd95379d",
     "grade": false,
     "grade_id": "cell-83ce58105c97d477",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "We can see from the above plot of the average total volume versus the week that there are more avocados sold (and perhaps this reflects what is available for sale) roughly between January to May. This time period of increased volume corresponds with the lower avocado prices. We can *hypothesize* (but not conclude, of course) that the lower prices may be due to an increased availability of avocados during this time period."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "df304d903814167320ad048736e36c94",
     "grade": false,
     "grade_id": "cell-15b71c3a5274adf6",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## 2. Sea Surface Temperatures in Departure Bay\n",
    "The next data set that we will be looking at contains environmental data from 1914 to 2018. The data was collected by the DFO (Canada's Department of Fisheries and Oceans) at the Pacific Biological Station (Departure Bay). Daily sea surface temperature (in degrees Celsius) and salinity (in practical salinity units, PSU) observations have been carried out at several locations on the coast of British Columbia. The number of stations reporting at any given time has varied as sampling has been discontinued at some stations, and started or resumed at others.\n",
    "\n",
    "Presently termed the British Columbia Shore Station Oceanographic Program (BCSOP), there are 12 participating stations; most of these are staffed by Fisheries and Oceans Canada. You can look at data from other stations at http://www.pac.dfo-mpo.gc.ca/science/oceans/data-donnees/lightstations-phares/index-eng.html \n",
    "\n",
    "Further information from the Government of Canada's website indicates: \n",
    ">  Observations are made daily using seawater collected in a bucket lowered into the surface water at or near the daytime high tide. This sampling method was designed long ago by Dr. John P. Tully and has not been changed in the interests of a homogeneous data set. This means, for example, that if an observer starts sampling one day at 6 a.m., and continues to sample at the daytime high tide on the second day the sample will be taken at about 06:50 the next day, 07:40 the day after etc. When the daytime high-tide gets close to 6 p.m. the observer will then begin again to sample early in the morning, and the cycle continues. Since there is a day/night variation in the sea surface temperatures the daily time series will show a signal that varies with the14-day tidal cycle. This artifact does not affect the monthly sea surface temperature data.\n",
    "\n",
    "In this worksheet, we want to see if the sea surface temperature has been changing over time. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "e12239e7c50041fc0f15fa3d9084638b",
     "grade": false,
     "grade_id": "cell-8f4dc9433ea2a7e9",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "**Question 2.1** True or False:\n",
    "<br> {points: 1}\n",
    "\n",
    "The sampling of surface water occurs at the same time each day. \n",
    "\n",
    "*Assign your answer to an object called `answer2_1`. Make sure your answer is a boolean. i.e. `True` or `False`.* "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "fbe12e6b0a0d4bf6519aafe93b7c8baa",
     "grade": false,
     "grade_id": "cell-4eb1407dda8e1fe2",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# your code here\n",
    "raise NotImplementedError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "max_height": 100,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "1f1f97dab6e8785d09ac462746e690b6",
     "grade": true,
     "grade_id": "cell-aef90db69249870d",
     "locked": true,
     "points": 3,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "from hashlib import sha1\n",
    "assert sha1(str(type(answer2_1)).encode(\"utf-8\")+b\"49c48cb278894fa5\").hexdigest() == \"e1aa1c949d66dbd11220177eed71a7333b5aea14\", \"type of answer2_1 is not bool. answer2_1 should be a bool\"\n",
    "assert sha1(str(answer2_1).encode(\"utf-8\")+b\"49c48cb278894fa5\").hexdigest() == \"4c5b735c9360d4e90a278b148b191dd74a848874\", \"boolean value of answer2_1 is not correct\"\n",
    "\n",
    "print('Success!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "f646082b34259ea6cb09a5a39741d412",
     "grade": false,
     "grade_id": "cell-0155ff05e1bac66f",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "**Question 2.2** Multiple Choice:\n",
    "<br> {points: 1}\n",
    "\n",
    "If high tide occurred at 9am today, what time would the scientist collect data tomorrow?\n",
    "\n",
    "A. 11:10 am \n",
    "\n",
    "B. 9:50 am \n",
    "\n",
    "C. 10:00 pm \n",
    "\n",
    "D. Trick question... you skip days when collecting data. \n",
    "\n",
    "*Assign your answer to an object called `answer2_2`. Make sure your answer is an uppercase letter and is surrounded by quotation marks (e.g. `\"F\"`).* "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "726830a8f448dd5426e2a7630b9ce486",
     "grade": false,
     "grade_id": "cell-c93cda405137fbfd",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# your code here\n",
    "raise NotImplementedError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "max_height": 100,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "4da9eaac1b714193c057d6ac75be68fb",
     "grade": true,
     "grade_id": "cell-957f2b6edf976bfd",
     "locked": true,
     "points": 3,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "from hashlib import sha1\n",
    "assert sha1(str(type(answer2_2)).encode(\"utf-8\")+b\"f02af2eadac209d9\").hexdigest() == \"9407f38412a64864d9f5560881cff9528bb29aec\", \"type of answer2_2 is not str. answer2_2 should be an str\"\n",
    "assert sha1(str(len(answer2_2)).encode(\"utf-8\")+b\"f02af2eadac209d9\").hexdigest() == \"edf8e8d6721139e73cf04fa8974bdb68de49d9e8\", \"length of answer2_2 is not correct\"\n",
    "assert sha1(str(answer2_2.lower()).encode(\"utf-8\")+b\"f02af2eadac209d9\").hexdigest() == \"53ebf8ba9c1aa935e1ebead6e381bdf921eace9b\", \"value of answer2_2 is not correct\"\n",
    "assert sha1(str(answer2_2).encode(\"utf-8\")+b\"f02af2eadac209d9\").hexdigest() == \"a9d391e09dc2574434787b694b3ccf2dfba06edc\", \"correct string value of answer2_2 but incorrect case of letters\"\n",
    "\n",
    "print('Success!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "64ea8b6e015b231655313dd81d9d84aa",
     "grade": false,
     "grade_id": "cell-e1bf20ed85ae3d0d",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "**Question 2.3**\n",
    "<br> {points: 1}\n",
    "\n",
    "To begin working with this data, read the file `departure_bay_temperature.csv` using a relative path. Note, this file (just like the avocado data set) is found within the `data` directory. \n",
    "\n",
    "*Assign your answer to an object called `sea_surface`.* \n",
    "\n",
    "> Hint: check out the data file in the editor mode to see from which row the actual data begins, and you will need to specify the `skiprows` argument accordingly in the suitable `pandas` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "e633fcc8fc92649def199838df544382",
     "grade": false,
     "grade_id": "cell-b10c1a879331aa37",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# your code here\n",
    "raise NotImplementedError\n",
    "sea_surface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "max_height": 100,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "a4103d755283028f9ba59eae91cb7ae9",
     "grade": true,
     "grade_id": "cell-09a9fd7ca9f44ada",
     "locked": true,
     "points": 3,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "from hashlib import sha1\n",
    "assert str(type(sea_surface is None)) == \"<class 'bool'>\", \"type of sea_surface is None is not bool. sea_surface is None should be a bool\"\n",
    "assert str(sea_surface is None) == \"False\", \"boolean value of sea_surface is None is not correct\"\n",
    "\n",
    "assert str(type(sea_surface)) == \"<class 'pandas.core.frame.DataFrame'>\", \"type of type(sea_surface) is not correct\"\n",
    "\n",
    "assert str(type(sea_surface.shape)) == \"<class 'tuple'>\", \"type of sea_surface.shape is not tuple. sea_surface.shape should be a tuple\"\n",
    "assert str(len(sea_surface.shape)) == \"2\", \"length of sea_surface.shape is not correct\"\n",
    "assert str(sorted(map(str, sea_surface.shape))) == \"['105', '13']\", \"values of sea_surface.shape are not correct\"\n",
    "assert str(sea_surface.shape) == \"(105, 13)\", \"order of elements of sea_surface.shape is not correct\"\n",
    "\n",
    "assert str(type(sea_surface.columns.values)) == \"<class 'numpy.ndarray'>\", \"type of sea_surface.columns.values is not correct\"\n",
    "assert str(sea_surface.columns.values) == \"['Year' 'Jan' 'Feb' 'Mar' 'Apr' 'May' 'Jun' 'Jul' 'Aug' 'Sep' 'Oct' 'Nov'\\n 'Dec']\", \"value of sea_surface.columns.values is not correct\"\n",
    "\n",
    "assert sha1(str(type(sum(sea_surface.Year))).encode(\"utf-8\")+b\"6f7dfac266c570c6\").hexdigest() == \"7429eb3e66376d82f82ecd42167e9acc208fc0c6\", \"type of sum(sea_surface.Year) is not int. Please make sure it is int and not np.int64, etc. You can cast your value into an int using int()\"\n",
    "assert sha1(str(sum(sea_surface.Year)).encode(\"utf-8\")+b\"6f7dfac266c570c6\").hexdigest() == \"ccbe05518284a0f85fdf48a51c1347d988576b5c\", \"value of sum(sea_surface.Year) is not correct\"\n",
    "\n",
    "print('Success!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "f3e9a738394e878d85f6910cc4faf4bf",
     "grade": false,
     "grade_id": "cell-e755c156454253ba",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**Question 2.3.1**\n",
    "<br> {points: 1}\n",
    "\n",
    "The data above in Question 2.3 is not tidy, which reasons listed below explain why?\n",
    "\n",
    "A. There are NaN's in the data set\n",
    "\n",
    "B. The variable temperature is split across more than one column\n",
    "\n",
    "C. Values for the variable month are stored as column names\n",
    "\n",
    "D. A and C\n",
    "\n",
    "E. B and C\n",
    "\n",
    "F. All of the above\n",
    "\n",
    "*Assign your answer to an object called `answer2_3_1`.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "8df82700e71e72597edc665d455334ec",
     "grade": false,
     "grade_id": "cell-6e1789eb7032fc30",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# your code here\n",
    "raise NotImplementedError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "max_height": 100,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "0a238e1888df1f14249da64815a4ac95",
     "grade": true,
     "grade_id": "cell-f449a87635bac905",
     "locked": true,
     "points": 3,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "from hashlib import sha1\n",
    "assert sha1(str(type(answer2_3_1)).encode(\"utf-8\")+b\"c738a66e5b134a39\").hexdigest() == \"01c36e78a93139b11b1b1d577d66722edbd949fa\", \"type of answer2_3_1 is not str. answer2_3_1 should be an str\"\n",
    "assert sha1(str(len(answer2_3_1)).encode(\"utf-8\")+b\"c738a66e5b134a39\").hexdigest() == \"8716c46df9de38480555b0e40673d9fc5b881422\", \"length of answer2_3_1 is not correct\"\n",
    "assert sha1(str(answer2_3_1.lower()).encode(\"utf-8\")+b\"c738a66e5b134a39\").hexdigest() == \"5385f314ee30efde2bc2dc6f115f92230c73b168\", \"value of answer2_3_1 is not correct\"\n",
    "assert sha1(str(answer2_3_1).encode(\"utf-8\")+b\"c738a66e5b134a39\").hexdigest() == \"7431d1f278e8838a39fbfce3afdf7bf8cc30bfb5\", \"correct string value of answer2_3_1 but incorrect case of letters\"\n",
    "\n",
    "print('Success!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "be09f73e797a675759dde138198d7106",
     "grade": false,
     "grade_id": "cell-0b23c682c8caa306",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "**Question 2.4**\n",
    "<br> {points: 1}\n",
    "\n",
    "Given `altair` expects tidy data, we need to convert our data into that format. To do this we will use the `melt` function. We would like our data to end up looking like this:\n",
    "\n",
    "| Year | Month | Temperature |\n",
    "|------|-------|-------------|\n",
    "| 1914 | Jan   | 7.2         |\n",
    "| 1915 | Jan   | 5.6         |\n",
    "| 1916 | Jan   | 1.2         |\n",
    "| 1917 | Jan   | 3.8         |\n",
    "| 1918 | Jan   | 3.7         |\n",
    "| ...  | ...   | ...         |\n",
    "| 2014 | Dec   | 7.1         |\n",
    "| 2015 | Dec   | 6.8         |\n",
    "| 2016 | Dec   | 5.5         |\n",
    "| 2017 | Dec   | 6.9         |\n",
    "| 2018 | Dec   | NaN         |\n",
    "\n",
    "\n",
    "Fill in the `___` in the cell below. \n",
    "\n",
    "*Assign your answer to an object called `tidy_temp`.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "bcd0ddb2dd805451efb28897c9f768c4",
     "grade": false,
     "grade_id": "cell-422718995704f040",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# ___ = sea_surface.___(id_vars=['Year'],  var_name='___', value_name='Temperature')\n",
    "\n",
    "\n",
    "# your code here\n",
    "raise NotImplementedError\n",
    "tidy_temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "max_height": 100,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "7ccba47050f837a752439bfeac9be82c",
     "grade": true,
     "grade_id": "cell-afb070ca8361d0a7",
     "locked": true,
     "points": 3,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "from hashlib import sha1\n",
    "assert str(type(tidy_temp is None)) == \"<class 'bool'>\", \"type of tidy_temp is None is not bool. tidy_temp is None should be a bool\"\n",
    "assert str(tidy_temp is None) == \"False\", \"boolean value of tidy_temp is None is not correct\"\n",
    "\n",
    "assert str(type(tidy_temp.shape)) == \"<class 'tuple'>\", \"type of tidy_temp.shape is not tuple. tidy_temp.shape should be a tuple\"\n",
    "assert str(len(tidy_temp.shape)) == \"2\", \"length of tidy_temp.shape is not correct\"\n",
    "assert str(sorted(map(str, tidy_temp.shape))) == \"['1260', '3']\", \"values of tidy_temp.shape are not correct\"\n",
    "assert str(tidy_temp.shape) == \"(1260, 3)\", \"order of elements of tidy_temp.shape is not correct\"\n",
    "\n",
    "assert str(type(tidy_temp.columns)) == \"<class 'pandas.core.indexes.base.Index'>\", \"type of tidy_temp.columns is not correct\"\n",
    "assert str(tidy_temp.columns) == \"Index(['Year', 'Month', 'Temperature'], dtype='object')\", \"value of tidy_temp.columns is not correct\"\n",
    "\n",
    "assert sha1(str(type(sum(tidy_temp.Temperature.dropna()))).encode(\"utf-8\")+b\"1d2b6a13657559e0\").hexdigest() == \"763ae2b926345614760dc31b72d63037929ba901\", \"type of sum(tidy_temp.Temperature.dropna()) is not float. Please make sure it is float and not np.float64, etc. You can cast your value into a float using float()\"\n",
    "assert sha1(str(round(sum(tidy_temp.Temperature.dropna()), 2)).encode(\"utf-8\")+b\"1d2b6a13657559e0\").hexdigest() == \"c620dc4a23c5cc91363bbc35b0f41401b2c8b995\", \"value of sum(tidy_temp.Temperature.dropna()) is not correct (rounded to 2 decimal places)\"\n",
    "\n",
    "print('Success!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "55ed46c9448dcf39c135a58751cc47a0",
     "grade": false,
     "grade_id": "cell-4d3484d80d9f0854",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "**Question 2.5**\n",
    "<br> {points: 1}\n",
    "\n",
    "Now that we have our data in a tidy format, we can create our plot that compares the average monthly sea surface temperatures (in degrees Celsius) to the year they were recorded. To make our plots more informative, we should plot each month separately. We can filter the data before we pipe our data into the `alt.Chart` function. Let's start out by just plotting the data for the month of November. As usual, use proper English to label your axes :)\n",
    "\n",
    "*Assign your answer to an object called `nov_temp_plot`.*\n",
    "\n",
    "> Hint: don't forget to include the units for temperature in your data visualization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "4447e276c91efec8a5244ff4f8b8365c",
     "grade": false,
     "grade_id": "cell-b1ac578751969b78",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# ___ = (\n",
    "#     alt.Chart(___[___[___] == \"Nov\"])\n",
    "#     .mark_point()\n",
    "#     .encode(\n",
    "#         x=alt.X(\n",
    "#             ___,\n",
    "#             title=___,\n",
    "#             scale=alt.Scale(zero=False),\n",
    "#         ),\n",
    "#         y=alt.Y(\n",
    "#             ___,\n",
    "#             title=___,\n",
    "#             scale=alt.Scale(zero=False),\n",
    "#         ),\n",
    "#     )\n",
    "#     .configure_axis(labelFontSize=20, titleFontSize=20)\n",
    "# )\n",
    "\n",
    "\n",
    "# your code here\n",
    "raise NotImplementedError\n",
    "nov_temp_plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "max_height": 100,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "3eb8662371e0f8a99df3a774fcea3de3",
     "grade": true,
     "grade_id": "cell-8ddfbb3c8b82e695",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "from hashlib import sha1\n",
    "assert sha1(str(type(nov_temp_plot is None)).encode(\"utf-8\")+b\"ce141035de597b04\").hexdigest() == \"c2b0c869fe8654a92ec1f5390c1dbafa723f5ac5\", \"type of nov_temp_plot is None is not bool. nov_temp_plot is None should be a bool\"\n",
    "assert sha1(str(nov_temp_plot is None).encode(\"utf-8\")+b\"ce141035de597b04\").hexdigest() == \"d9e225bb6d1da2d687510c7173dd7526c37ca4a4\", \"boolean value of nov_temp_plot is None is not correct\"\n",
    "\n",
    "assert sha1(str(type(nov_temp_plot.data.Month.unique())).encode(\"utf-8\")+b\"342ca85ed59dbe97\").hexdigest() == \"518ced317da8268bca4042833f3fb5cafd51b80d\", \"type of nov_temp_plot.data.Month.unique() is not correct\"\n",
    "assert sha1(str(nov_temp_plot.data.Month.unique()).encode(\"utf-8\")+b\"342ca85ed59dbe97\").hexdigest() == \"c7bda964dbf8bf7acc65f15262a3534b2d04dc56\", \"value of nov_temp_plot.data.Month.unique() is not correct\"\n",
    "\n",
    "assert sha1(str(type(nov_temp_plot.encoding.x.field)).encode(\"utf-8\")+b\"a5ace5d0ae18b401\").hexdigest() == \"c89f01e70f77410cbce8c80c6a6ff0f63717f09d\", \"type of nov_temp_plot.encoding.x.field is not str. nov_temp_plot.encoding.x.field should be an str\"\n",
    "assert sha1(str(len(nov_temp_plot.encoding.x.field)).encode(\"utf-8\")+b\"a5ace5d0ae18b401\").hexdigest() == \"58d131b754f4d6ebfcbcc6153a8983072247cd1c\", \"length of nov_temp_plot.encoding.x.field is not correct\"\n",
    "assert sha1(str(nov_temp_plot.encoding.x.field.lower()).encode(\"utf-8\")+b\"a5ace5d0ae18b401\").hexdigest() == \"17e96447126112308b019ea64732e193f9dcae56\", \"value of nov_temp_plot.encoding.x.field is not correct\"\n",
    "assert sha1(str(nov_temp_plot.encoding.x.field).encode(\"utf-8\")+b\"a5ace5d0ae18b401\").hexdigest() == \"0ab6be7927d734b123d8d1d49e88bbd21a149a56\", \"correct string value of nov_temp_plot.encoding.x.field but incorrect case of letters\"\n",
    "\n",
    "assert sha1(str(type(nov_temp_plot.encoding.y.field)).encode(\"utf-8\")+b\"63580602fb7b6bf7\").hexdigest() == \"97c55328b32582e6e170b48396a8c89faf597d03\", \"type of nov_temp_plot.encoding.y.field is not str. nov_temp_plot.encoding.y.field should be an str\"\n",
    "assert sha1(str(len(nov_temp_plot.encoding.y.field)).encode(\"utf-8\")+b\"63580602fb7b6bf7\").hexdigest() == \"95f47be049b218033462af26b8a253a66b37643d\", \"length of nov_temp_plot.encoding.y.field is not correct\"\n",
    "assert sha1(str(nov_temp_plot.encoding.y.field.lower()).encode(\"utf-8\")+b\"63580602fb7b6bf7\").hexdigest() == \"a5ff685a4111a03152b91e7d5e1c679e04fed8e7\", \"value of nov_temp_plot.encoding.y.field is not correct\"\n",
    "assert sha1(str(nov_temp_plot.encoding.y.field).encode(\"utf-8\")+b\"63580602fb7b6bf7\").hexdigest() == \"0e6fcbbdd87b05873d727ee47bc4cff67d6ebcd4\", \"correct string value of nov_temp_plot.encoding.y.field but incorrect case of letters\"\n",
    "\n",
    "assert sha1(str(type(nov_temp_plot.mark)).encode(\"utf-8\")+b\"60944847c4694f63\").hexdigest() == \"9e98ff3de8f38f388513952bf248efc68ed061a8\", \"type of nov_temp_plot.mark is not str. nov_temp_plot.mark should be an str\"\n",
    "assert sha1(str(len(nov_temp_plot.mark)).encode(\"utf-8\")+b\"60944847c4694f63\").hexdigest() == \"ce04add748be0057ee2ea7078576280f201b7e41\", \"length of nov_temp_plot.mark is not correct\"\n",
    "assert sha1(str(nov_temp_plot.mark.lower()).encode(\"utf-8\")+b\"60944847c4694f63\").hexdigest() == \"554a4ac887f5af3e9366814dbfca6dc98fbdb81e\", \"value of nov_temp_plot.mark is not correct\"\n",
    "assert sha1(str(nov_temp_plot.mark).encode(\"utf-8\")+b\"60944847c4694f63\").hexdigest() == \"554a4ac887f5af3e9366814dbfca6dc98fbdb81e\", \"correct string value of nov_temp_plot.mark but incorrect case of letters\"\n",
    "\n",
    "print('Success!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "ae77e75d827d91d25f0b0d2d8840b78d",
     "grade": false,
     "grade_id": "cell-9de2b3c001bbe02d",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "We can see that there may be a small decrease in colder temperatures in recent years, and/or the temperatures in recent years look less variable compared to years before 1975. What about other months? Let's plot them! \n",
    "\n",
    "Instead of repeating the code above for the 11 other months, we'll take advantage of a `altair` function that we haven't met yet, `facet`. We will learn more about this function next week, this week we will give you the code for it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "d0de957dfb2d82f1bb77800334ab680b",
     "grade": false,
     "grade_id": "cell-27e2c5089e6710ef",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "**Question 2.6**\n",
    "<br> {points: 1}\n",
    "\n",
    "Fill in the missing code below to plot the average monthly sea surface temperatures to the year they were recorded for all months. \n",
    "\n",
    "*Assign your answer to an object called `all_temp_plot`.*\n",
    "\n",
    "> Hint: don't forget to include the units for temperature in your data visualization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "ec7137be147989ea6c1eeed9b7233ff2",
     "grade": false,
     "grade_id": "cell-6a5d54a80ebdc73c",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# ___ = (\n",
    "#     alt.Chart(___)\n",
    "#     .mark_point()\n",
    "#     .encode(\n",
    "#         x=alt.X(\n",
    "#             ___,\n",
    "#             title=___,\n",
    "#             scale=alt.Scale(zero=False),\n",
    "#         ),\n",
    "#         y=alt.Y(\n",
    "#             ___,\n",
    "#             title=___,\n",
    "#             scale=alt.Scale(zero=False),\n",
    "#         ),\n",
    "#     )\n",
    "#     .facet(\"Month\", columns=4)\n",
    "#     .configure_axis(labelFontSize=20, titleFontSize=20)\n",
    "# )\n",
    "\n",
    "# your code here\n",
    "raise NotImplementedError\n",
    "all_temp_plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "max_height": 100,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "e188ec53ffc7a5778a2ba3d7eba69270",
     "grade": true,
     "grade_id": "cell-4529c8b1eb657878",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "from hashlib import sha1\n",
    "assert sha1(str(type(all_temp_plot is None)).encode(\"utf-8\")+b\"777a7e55eea36113\").hexdigest() == \"a893e1fcc2731a88830560005dae53560e3e736d\", \"type of all_temp_plot is None is not bool. all_temp_plot is None should be a bool\"\n",
    "assert sha1(str(all_temp_plot is None).encode(\"utf-8\")+b\"777a7e55eea36113\").hexdigest() == \"47966e7210bd8108da1c56c5198e52da95619c2e\", \"boolean value of all_temp_plot is None is not correct\"\n",
    "\n",
    "assert sha1(str(type(\"Month\" in all_temp_plot.data.columns)).encode(\"utf-8\")+b\"48511a36e41e39b2\").hexdigest() == \"1cde0260d90a9c09371d3b2b36b59000e710f8a4\", \"type of \\\"Month\\\" in all_temp_plot.data.columns is not bool. \\\"Month\\\" in all_temp_plot.data.columns should be a bool\"\n",
    "assert sha1(str(\"Month\" in all_temp_plot.data.columns).encode(\"utf-8\")+b\"48511a36e41e39b2\").hexdigest() == \"3d7f43d17707f0242d6551de6e3cc76db3cfaa73\", \"boolean value of \\\"Month\\\" in all_temp_plot.data.columns is not correct\"\n",
    "\n",
    "assert sha1(str(type(all_temp_plot.facet)).encode(\"utf-8\")+b\"544c8116c9298a24\").hexdigest() == \"a94adb1f308d6f15983d68045cf68d190f269484\", \"type of all_temp_plot.facet is not correct\"\n",
    "assert sha1(str(all_temp_plot.facet).encode(\"utf-8\")+b\"544c8116c9298a24\").hexdigest() == \"3dc6bdf149e910ecde8381ebf1ce20462c3e2754\", \"value of all_temp_plot.facet is not correct\"\n",
    "\n",
    "print('Success!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "ae37273c57e7f7f4b8619bfe745f2ff5",
     "grade": false,
     "grade_id": "cell-5406840f482b0738",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "We can see above that some months show a small, but general increase in temperatures, whereas others don't. And some months show a change in variability and others do not. From this it is clear to us that if we are trying to understand temperature changes over time, we best keep data from different months separate."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "d8218a3c7217edb9483fa20667e9d437",
     "grade": false,
     "grade_id": "cell-4fed26cd837beb2b",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## 3. Pollution in Madrid\n",
    "We're working with a data set from Kaggle once again! [This data](https://www.kaggle.com/decide-soluciones/air-quality-madrid) was collected under the instructions from Madrid's City Council and is publicly available on their website. In recent years, high levels of pollution during certain dry periods has forced the authorities to take measures against the use of cars and act as a reasoning to propose certain regulations. This data includes daily and hourly measurements of air quality from 2001 to 2008. Pollutants are categorized based on their chemical properties.\n",
    "\n",
    "There are a number of stations set up around Madrid and each station's data frame contains all particle measurements that such station has registered from 01/2001 - 04/2008. Not every station has the same equipment, therefore each station can measure only a certain subset of particles. The complete list of possible measurements and their explanations are given by the website:\n",
    "\n",
    "- `SO_2`: sulphur dioxide level measured in μg/m³. High levels can produce irritation in the skin and membranes, and worsen asthma or heart diseases in sensitive groups.\n",
    "- `CO`: carbon monoxide level measured in mg/m³. Carbon monoxide poisoning involves headaches, dizziness and confusion in short exposures and can result in loss of consciousness, arrhythmias, seizures or even death.\n",
    "- `NO_2`: nitrogen dioxide level measured in μg/m³. Long-term exposure is a cause of chronic lung diseases, and are harmful for the vegetation.\n",
    "- `PM10`: particles smaller than 10 μm. Even though they cannot penetrate the alveolus, they can still penetrate through the lungs and affect other organs. Long term exposure can result in lung cancer and cardiovascular complications.\n",
    "- `NOx`: nitrous oxides level measured in μg/m³. Affect the human respiratory system worsening asthma or other diseases, and are responsible of the yellowish-brown color of photochemical smog.\n",
    "- `O_3`: ozone level measured in μg/m³. High levels can produce asthma, bronchytis or other chronic pulmonary diseases in sensitive groups or outdoor workers.\n",
    "- `TOL`: toluene (methylbenzene) level measured in μg/m³. Long-term exposure to this substance (present in tobacco smoke as well) can result in kidney complications or permanent brain damage.\n",
    "- `BEN`: benzene level measured in μg/m³. Benzene is a eye and skin irritant, and long exposures may result in several types of cancer, leukaemia and anaemias. Benzene is considered a group 1 carcinogenic to humans.\n",
    "- `EBE`: ethylbenzene level measured in μg/m³. Long term exposure can cause hearing or kidney problems and the IARC has concluded that long-term exposure can produce cancer.\n",
    "- `MXY`: m-xylene level measured in μg/m³. Xylenes can affect not only air but also water and soil, and a long exposure to high levels of xylenes can result in diseases affecting the liver, kidney and nervous system.\n",
    "- `PXY`: p-xylene level measured in μg/m³. See MXY for xylene exposure effects on health.\n",
    "- `OXY`: o-xylene level measured in μg/m³. See MXY for xylene exposure effects on health.\n",
    "- `TCH`: total hydrocarbons level measured in mg/m³. This group of substances can be responsible of different blood, immune system, liver, spleen, kidneys or lung diseases.\n",
    "- `NMHC`: non-methane hydrocarbons (volatile organic compounds) level measured in mg/m³. Long exposure to some of these substances can result in damage to the liver, kidney, and central nervous system. Some of them are suspected to cause cancer in humans."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "f4ffcadff0d22e56abe5dd706008b13f",
     "grade": false,
     "grade_id": "cell-892f43f18911d0ba",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "The goal of this assignment is to see if pollutants are decreasing (is air quality improving) and also compare which pollutant has decreased the most over the span of 5 years (2001 - 2006). \n",
    "1. First do a plot of one of the pollutants (EBE). \n",
    "2. Next, group it by month and year; calculate the maximum value and plot it (to see the trend through time). \n",
    "3. Now we will look at which pollutant decreased the most. First we will look at pollution in 2001 (get the maximum value for each of the pollutants). And then do the same for 2006. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "c9d249a6060690c7b00190e86c91ff02",
     "grade": false,
     "grade_id": "cell-a99486a2f16469ae",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "**Question 3.1** Multiple Choice: \n",
    "<br> {points: 1}\n",
    "\n",
    "What big picture question are we trying to answer?\n",
    "\n",
    "A. Did EBE decrease in Madrid between 2001 and 2006?\n",
    "\n",
    "B. Of all the pollutants, which decreased the most between 2001 and 2006? \n",
    "\n",
    "C. Of all the pollutants, which decreased the least between 2001 and 2006?\n",
    "\n",
    "D. Did EBE increase in Madrid between 2001 and 2006?\n",
    "\n",
    "*Assign your answer to an object called `answer3_1`. Make sure your answer is an uppercase letter and is surrounded by quotation marks (e.g. `\"F\"`).*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "e8e54c80e73f166a37cd9925a8273f23",
     "grade": false,
     "grade_id": "cell-fffa52c5bf768a43",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# your code here\n",
    "raise NotImplementedError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "max_height": 100,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "506841039ca1881f813d0ac712f7d51a",
     "grade": true,
     "grade_id": "cell-d67db6d2cd3971aa",
     "locked": true,
     "points": 3,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "from hashlib import sha1\n",
    "assert sha1(str(type(all_temp_plot)).encode(\"utf-8\")+b\"e3f09b6e9e3f906f\").hexdigest() == \"a024fcdec2c352c5cbf218cc7440ac4968009fe6\", \"type of all_temp_plot is not correct\"\n",
    "assert sha1(str(all_temp_plot).encode(\"utf-8\")+b\"e3f09b6e9e3f906f\").hexdigest() == \"6ec59f2954a54c7050ca04c6264b1622f1cc6b7a\", \"value of all_temp_plot is not correct\"\n",
    "\n",
    "print('Success!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "6ca799de6ed748a3edc5b899b77ed28b",
     "grade": false,
     "grade_id": "cell-beefc03e5d6c203d",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "**Question 3.2** \n",
    "<br> {points: 1}\n",
    "\n",
    "To begin working with this data, read the file `madrid_pollution.csv`. Note, this file (just like the avocado and sea surface data set) is found in the `data` directory. \n",
    "\n",
    "*Assign your answer to an object called `madrid`.* \n",
    "\n",
    "> Hint: check out the data file in the editor mode to see which delimitor is used, and then select the proper `pandas` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "6ed2835265606c0ce9872adb082bd06b",
     "grade": false,
     "grade_id": "cell-7f7939bcc9bebde2",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# your code here\n",
    "raise NotImplementedError\n",
    "madrid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "max_height": 100,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "3005b978bbd10eba3f4390c4361cdbf6",
     "grade": true,
     "grade_id": "cell-902507dc58ec5428",
     "locked": true,
     "points": 3,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "from hashlib import sha1\n",
    "assert str(type(madrid is None)) == \"<class 'bool'>\", \"type of madrid is None is not bool. madrid is None should be a bool\"\n",
    "assert str(madrid is None) == \"False\", \"boolean value of madrid is None is not correct\"\n",
    "\n",
    "assert str(type(madrid)) == \"<class 'pandas.core.frame.DataFrame'>\", \"type of type(madrid) is not correct\"\n",
    "\n",
    "assert str(type(madrid.shape)) == \"<class 'tuple'>\", \"type of madrid.shape is not tuple. madrid.shape should be a tuple\"\n",
    "assert str(len(madrid.shape)) == \"2\", \"length of madrid.shape is not correct\"\n",
    "assert str(sorted(map(str, madrid.shape))) == \"['17', '51864']\", \"values of madrid.shape are not correct\"\n",
    "assert str(madrid.shape) == \"(51864, 17)\", \"order of elements of madrid.shape is not correct\"\n",
    "\n",
    "assert str(type(madrid.columns.values)) == \"<class 'numpy.ndarray'>\", \"type of madrid.columns.values is not correct\"\n",
    "assert str(madrid.columns.values) == \"['date' 'BEN' 'CO' 'EBE' 'MXY' 'NMHC' 'NO_2' 'NOx' 'OXY' 'O_3' 'PM10'\\n 'PXY' 'SO_2' 'TCH' 'TOL' 'year' 'mnth']\", \"value of madrid.columns.values is not correct\"\n",
    "\n",
    "assert sha1(str(type(sum(madrid.BEN.dropna()))).encode(\"utf-8\")+b\"e6e57fcb7f04e6a5\").hexdigest() == \"06da406d468a397a67407e321db477b9916b4760\", \"type of sum(madrid.BEN.dropna()) is not float. Please make sure it is float and not np.float64, etc. You can cast your value into a float using float()\"\n",
    "assert sha1(str(round(sum(madrid.BEN.dropna()), 2)).encode(\"utf-8\")+b\"e6e57fcb7f04e6a5\").hexdigest() == \"78584b25f1e26d4fe7a2741b6677bcca2db18fca\", \"value of sum(madrid.BEN.dropna()) is not correct (rounded to 2 decimal places)\"\n",
    "\n",
    "print('Success!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "c1079d6a21c027f50dc2d5a6cfd14af1",
     "grade": false,
     "grade_id": "cell-da06d5b257b928f0",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "**Question 3.3**\n",
    "<br> {points: 1}\n",
    "\n",
    "Now that the data is loaded in Python, create a scatter plot that compares ethylbenzene (`EBE`) values against the date they were recorded. This graph will showcase the concentration of ethylbenzene in Madrid over time. As usual, label your axes: \n",
    "\n",
    "- x = Date\n",
    "- y = Ethylbenzene (μg/m³)\n",
    "\n",
    "*Assign your answer to an object called `EBE_pollution`.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "0787481048efa1db17b55f25bcddb492",
     "grade": false,
     "grade_id": "cell-14614015f46ccfff",
     "locked": false,
     "schema_version": 3,
     "solution": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ___ = (\n",
    "#     alt.Chart(___)\n",
    "#     .mark_point()\n",
    "#     .encode(\n",
    "#         x=alt.X(\n",
    "#             \"date:T\", # to tell Altair to parse the date column as datetime objects\n",
    "#             title=___,\n",
    "#             scale=alt.Scale(zero=False),\n",
    "#         ),\n",
    "#         y=alt.Y(\n",
    "#             ___,\n",
    "#             title= ___,\n",
    "#             scale=alt.Scale(zero=False),\n",
    "#         ),\n",
    "#     )\n",
    "#     .configure_axis(labelFontSize=20, titleFontSize=20)\n",
    "# )\n",
    "# your code here\n",
    "raise NotImplementedError\n",
    "EBE_pollution\n",
    "\n",
    "# Are levels increasing or decreasing?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "max_height": 100,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "862c9dbe135091a45217191c3796ed0c",
     "grade": true,
     "grade_id": "cell-4de75a47d9cc2dca",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "from hashlib import sha1\n",
    "assert sha1(str(type(EBE_pollution is None)).encode(\"utf-8\")+b\"ad92f8d6ba481de5\").hexdigest() == \"49a76143b517e89aeaac4e95f55ccbd1e5e04825\", \"type of EBE_pollution is None is not bool. EBE_pollution is None should be a bool\"\n",
    "assert sha1(str(EBE_pollution is None).encode(\"utf-8\")+b\"ad92f8d6ba481de5\").hexdigest() == \"ff8206467adf1bd9b4eb44e0889ea4c46eb7116c\", \"boolean value of EBE_pollution is None is not correct\"\n",
    "\n",
    "assert sha1(str(type(EBE_pollution.encoding.x.field)).encode(\"utf-8\")+b\"c3d8f2a2201038c6\").hexdigest() == \"7560f101dffc4759c938e3b36b1b2edc6808c794\", \"type of EBE_pollution.encoding.x.field is not str. EBE_pollution.encoding.x.field should be an str\"\n",
    "assert sha1(str(len(EBE_pollution.encoding.x.field)).encode(\"utf-8\")+b\"c3d8f2a2201038c6\").hexdigest() == \"a439ea3f0cd322611abd0afc3b078824edc6d799\", \"length of EBE_pollution.encoding.x.field is not correct\"\n",
    "assert sha1(str(EBE_pollution.encoding.x.field.lower()).encode(\"utf-8\")+b\"c3d8f2a2201038c6\").hexdigest() == \"d5db44e59db00587866047c2eed5271a426da313\", \"value of EBE_pollution.encoding.x.field is not correct\"\n",
    "assert sha1(str(EBE_pollution.encoding.x.field).encode(\"utf-8\")+b\"c3d8f2a2201038c6\").hexdigest() == \"d5db44e59db00587866047c2eed5271a426da313\", \"correct string value of EBE_pollution.encoding.x.field but incorrect case of letters\"\n",
    "\n",
    "assert sha1(str(type(EBE_pollution.encoding.y.field)).encode(\"utf-8\")+b\"1c2d8a6589d2dfc8\").hexdigest() == \"3fa1e629c8d44d4e04c71bf9c91cfd932c624ac5\", \"type of EBE_pollution.encoding.y.field is not str. EBE_pollution.encoding.y.field should be an str\"\n",
    "assert sha1(str(len(EBE_pollution.encoding.y.field)).encode(\"utf-8\")+b\"1c2d8a6589d2dfc8\").hexdigest() == \"54b8f1618f468011efc950e30d0b604f365f791a\", \"length of EBE_pollution.encoding.y.field is not correct\"\n",
    "assert sha1(str(EBE_pollution.encoding.y.field.lower()).encode(\"utf-8\")+b\"1c2d8a6589d2dfc8\").hexdigest() == \"48411ee5f87f19903cbc7f79f57d6287be866888\", \"value of EBE_pollution.encoding.y.field is not correct\"\n",
    "assert sha1(str(EBE_pollution.encoding.y.field).encode(\"utf-8\")+b\"1c2d8a6589d2dfc8\").hexdigest() == \"22b42672177ddf39d4458f827bc2a72e4f9f981d\", \"correct string value of EBE_pollution.encoding.y.field but incorrect case of letters\"\n",
    "\n",
    "assert sha1(str(type(EBE_pollution.mark)).encode(\"utf-8\")+b\"888da7e03c9025c7\").hexdigest() == \"41379180536adc53e43e34415d1ca0461abe168d\", \"type of EBE_pollution.mark is not str. EBE_pollution.mark should be an str\"\n",
    "assert sha1(str(len(EBE_pollution.mark)).encode(\"utf-8\")+b\"888da7e03c9025c7\").hexdigest() == \"44de848bbc9e52c84af5e57a88996faa2041d529\", \"length of EBE_pollution.mark is not correct\"\n",
    "assert sha1(str(EBE_pollution.mark.lower()).encode(\"utf-8\")+b\"888da7e03c9025c7\").hexdigest() == \"a5beb55c16172db0747b4f3430298dbd3ee85832\", \"value of EBE_pollution.mark is not correct\"\n",
    "assert sha1(str(EBE_pollution.mark).encode(\"utf-8\")+b\"888da7e03c9025c7\").hexdigest() == \"a5beb55c16172db0747b4f3430298dbd3ee85832\", \"correct string value of EBE_pollution.mark but incorrect case of letters\"\n",
    "\n",
    "assert sha1(str(type(EBE_pollution.encoding.x.title != EBE_pollution.encoding.x.field)).encode(\"utf-8\")+b\"eaf09355a0801372\").hexdigest() == \"5699668238469146872a11c750cbd61751fb16e7\", \"type of EBE_pollution.encoding.x.title != EBE_pollution.encoding.x.field is not bool. EBE_pollution.encoding.x.title != EBE_pollution.encoding.x.field should be a bool\"\n",
    "assert sha1(str(EBE_pollution.encoding.x.title != EBE_pollution.encoding.x.field).encode(\"utf-8\")+b\"eaf09355a0801372\").hexdigest() == \"5650ee678727e1794c696554e32927bcd15eecbc\", \"boolean value of EBE_pollution.encoding.x.title != EBE_pollution.encoding.x.field is not correct\"\n",
    "\n",
    "assert sha1(str(type(EBE_pollution.encoding.y.title != EBE_pollution.encoding.y.field)).encode(\"utf-8\")+b\"8e54f08a6c9ecee0\").hexdigest() == \"6a853d984cb13dddbc028f3b1b1242238d276db9\", \"type of EBE_pollution.encoding.y.title != EBE_pollution.encoding.y.field is not bool. EBE_pollution.encoding.y.title != EBE_pollution.encoding.y.field should be a bool\"\n",
    "assert sha1(str(EBE_pollution.encoding.y.title != EBE_pollution.encoding.y.field).encode(\"utf-8\")+b\"8e54f08a6c9ecee0\").hexdigest() == \"6620f02903666680576704e6419aa89bc3f8313a\", \"boolean value of EBE_pollution.encoding.y.title != EBE_pollution.encoding.y.field is not correct\"\n",
    "\n",
    "print('Success!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "b658b04f5daef6e4549c08a50bdfd2f3",
     "grade": false,
     "grade_id": "cell-112c1b3ac6b6c720",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "We can see from this plot that over time, there are less and less high (> 25 μg/m³) EBE values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "bc00b2facaf1d3667e5e63996fec87d9",
     "grade": false,
     "grade_id": "cell-648260c1e625b576",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "**Question 3.4**\n",
    "<br> {points: 1}\n",
    "\n",
    "The question above asks you to write out code that allows visualization of all EBE recordings - which are taken every single hour of every day. Consequently the graph consists of many points and appears densely plotted. In this question, we are going to clean up the graph and focus on max EBE readings from each month. To further investigate if this trend is changing over time, we will use `groupby` and `max` to create a new data set.\n",
    "\n",
    "Fill in the `___` in the cell below. \n",
    "\n",
    "*Assign your answer to an object called `madrid_pollution`.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "8514621883a2b6697273f4b6478a8052",
     "grade": false,
     "grade_id": "cell-dbd1c81ead522ff6",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# ___ = ___.groupby([\"year\", ___]).max(\"EBE\").reset_index()\n",
    "\n",
    "# your code here\n",
    "raise NotImplementedError\n",
    "madrid_pollution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "max_height": 100,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "9a4879250ae2a97cea7beecf04201a12",
     "grade": true,
     "grade_id": "cell-d04ca4acf0f5f6bc",
     "locked": true,
     "points": 3,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "from hashlib import sha1\n",
    "assert sha1(str(type(madrid_pollution is None)).encode(\"utf-8\")+b\"2fdbca2bbed9224d\").hexdigest() == \"ca5d6c277e390358a278043f62725e123094c9c2\", \"type of madrid_pollution is None is not bool. madrid_pollution is None should be a bool\"\n",
    "assert sha1(str(madrid_pollution is None).encode(\"utf-8\")+b\"2fdbca2bbed9224d\").hexdigest() == \"7d72e637138a6017a14baa576f1b6c85bc3b56d1\", \"boolean value of madrid_pollution is None is not correct\"\n",
    "\n",
    "assert sha1(str(type(madrid_pollution.shape)).encode(\"utf-8\")+b\"5e20335d3eb7f40e\").hexdigest() == \"6218bcdf8910651e3e16d636a06ea55c67c922af\", \"type of madrid_pollution.shape is not tuple. madrid_pollution.shape should be a tuple\"\n",
    "assert sha1(str(len(madrid_pollution.shape)).encode(\"utf-8\")+b\"5e20335d3eb7f40e\").hexdigest() == \"5026c80566f9ec825f07e22edd5f871c8f34bc4c\", \"length of madrid_pollution.shape is not correct\"\n",
    "assert sha1(str(sorted(map(str, madrid_pollution.shape))).encode(\"utf-8\")+b\"5e20335d3eb7f40e\").hexdigest() == \"7e7d350937bd879f9fd95956c65f68b740564271\", \"values of madrid_pollution.shape are not correct\"\n",
    "assert sha1(str(madrid_pollution.shape).encode(\"utf-8\")+b\"5e20335d3eb7f40e\").hexdigest() == \"863994b96f9a0d7498c5569b7ec53c0e22e36bd1\", \"order of elements of madrid_pollution.shape is not correct\"\n",
    "\n",
    "assert sha1(str(type(sum(madrid_pollution.year))).encode(\"utf-8\")+b\"c73d570452bbc669\").hexdigest() == \"7f74e7085a4281bd390f669130dce1455d33f5b3\", \"type of sum(madrid_pollution.year) is not int. Please make sure it is int and not np.int64, etc. You can cast your value into an int using int()\"\n",
    "assert sha1(str(sum(madrid_pollution.year)).encode(\"utf-8\")+b\"c73d570452bbc669\").hexdigest() == \"9db9f0a812ee29324e5549356ce5fac19114123c\", \"value of sum(madrid_pollution.year) is not correct\"\n",
    "\n",
    "print('Success!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "12741172ba84ffc08233a15200a7cc78",
     "grade": false,
     "grade_id": "cell-7275e7512b1bd674",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "**Question 3.5**\n",
    "<br> {points: 1}\n",
    "\n",
    "Plot the new maximum EBE values versus the month they were recorded, split into side-by-side plots for each year. Again, we will use facetting (more on this next week) to plot each year side-by-side. \n",
    "\n",
    "*Assign your answer to an object called `madrid_plot`. Remember to label your axes.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "9bbb08324643086ade03eddf44c5a833",
     "grade": false,
     "grade_id": "cell-a406232e78b0e3ab",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# ___ = (\n",
    "#     alt.Chart(___)\n",
    "#     .mark_point()\n",
    "#     .encode(\n",
    "#         x=alt.X(\n",
    "#             ___,\n",
    "#             title=___,\n",
    "#             scale=alt.Scale(zero=False),\n",
    "#         ),\n",
    "#         y=alt.Y(\n",
    "#             ___,\n",
    "#             title=___,\n",
    "#             scale=alt.Scale(zero=False),\n",
    "#         ),\n",
    "#     )\n",
    "#     .facet(\"year\")\n",
    "#     .configure_axis(labelFontSize=20, titleFontSize=20)\n",
    "# )\n",
    "\n",
    "# your code here\n",
    "raise NotImplementedError\n",
    "madrid_plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "max_height": 100,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "d64b3ebc8916cb2ff505dc1a1825627d",
     "grade": true,
     "grade_id": "cell-b12cea24ac607772",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "from hashlib import sha1\n",
    "assert str(type(madrid_plot is None)) == \"<class 'bool'>\", \"type of madrid_plot is None is not bool. madrid_plot is None should be a bool\"\n",
    "assert str(madrid_plot is None) == \"False\", \"boolean value of madrid_plot is None is not correct\"\n",
    "\n",
    "assert str(type(madrid_plot.facet)) == \"<class 'altair.vegalite.v4.schema.channels.Facet'>\", \"type of madrid_plot.facet is not correct\"\n",
    "assert str(madrid_plot.facet) == \"Facet({\\n  field: 'year',\\n  type: 'quantitative'\\n})\", \"value of madrid_plot.facet is not correct\"\n",
    "\n",
    "print('Success!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "0ecbe97711b38306a4cb7a83ba7fdf62",
     "grade": false,
     "grade_id": "cell-f8e81164975da6e9",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "**Question 3.6**\n",
    "<br> {points: 1}\n",
    "\n",
    "Now we want to see which of the pollutants has decreased the most. Therefore, we must repeat the same thing that we did in the questions above but for every pollutant (using the original data set)!  \n",
    "\n",
    "First we will look at Madrid pollution in 2001 (filter for this year). Next we have to drop the columns that should be excluded (such as the date). Lastly, use the `max` function to create max values for all columns. Note: The `max` function would return a pandas series. But since we would need a dataframe for later exercises, we need to convert the series to a dataframe by using `pd.DataFrame`. And applying `transpose` to the dataframe would reflect the dataFrame over its main diagonal by writing rows as columns and vice-versa. Please feel free to remove `transpose` to check the difference.\n",
    "\n",
    "Fill in the `___` in the cell below.\n",
    "\n",
    "*Assign your answer to an object called `pollution_2001`.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "87878cad4207016b7cc5f7fb06c4f3b5",
     "grade": false,
     "grade_id": "cell-be1574acc60b53e9",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# ___ = pd.DataFrame(madrid[madrid[___] == ___].drop(columns=[___, ___, ___]).max()).transpose()\n",
    "\n",
    "\n",
    "# your code here\n",
    "raise NotImplementedError\n",
    "pollution_2001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "max_height": 100,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "d1f0523b4cfb2655e923f45e7e31d739",
     "grade": true,
     "grade_id": "cell-23ecb8f3102f3435",
     "locked": true,
     "points": 3,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "from hashlib import sha1\n",
    "assert sha1(str(type(pollution_2001 is None)).encode(\"utf-8\")+b\"d73db9028cb6a39a\").hexdigest() == \"50b0452c370da2e85a8380cd21d8b0c8fce923a3\", \"type of pollution_2001 is None is not bool. pollution_2001 is None should be a bool\"\n",
    "assert sha1(str(pollution_2001 is None).encode(\"utf-8\")+b\"d73db9028cb6a39a\").hexdigest() == \"8146db3f67f092a5c7d60adb326f3d779aa94349\", \"boolean value of pollution_2001 is None is not correct\"\n",
    "\n",
    "assert sha1(str(type(pollution_2001.shape)).encode(\"utf-8\")+b\"9c1057dcd762e9d3\").hexdigest() == \"a7fba4629082ea184c5d8dda51e0de219793c63f\", \"type of pollution_2001.shape is not tuple. pollution_2001.shape should be a tuple\"\n",
    "assert sha1(str(len(pollution_2001.shape)).encode(\"utf-8\")+b\"9c1057dcd762e9d3\").hexdigest() == \"1370a84bd6c4bf1fb2d4c77c42c034e3ce2c8395\", \"length of pollution_2001.shape is not correct\"\n",
    "assert sha1(str(sorted(map(str, pollution_2001.shape))).encode(\"utf-8\")+b\"9c1057dcd762e9d3\").hexdigest() == \"5012dca1c10796a5dea3111afa099546e3af1c3e\", \"values of pollution_2001.shape are not correct\"\n",
    "assert sha1(str(pollution_2001.shape).encode(\"utf-8\")+b\"9c1057dcd762e9d3\").hexdigest() == \"04fea55ff7fa87debf393f0c965c392df1b913da\", \"order of elements of pollution_2001.shape is not correct\"\n",
    "\n",
    "assert sha1(str(type(pollution_2001.MXY.values)).encode(\"utf-8\")+b\"63b738962bde30c6\").hexdigest() == \"54355d9f2b15aff22166a885e870285fdc06827c\", \"type of pollution_2001.MXY.values is not correct\"\n",
    "assert sha1(str(pollution_2001.MXY.values).encode(\"utf-8\")+b\"63b738962bde30c6\").hexdigest() == \"04ab19a8d9873c5501edfd52a8dd333760d7f52e\", \"value of pollution_2001.MXY.values is not correct\"\n",
    "\n",
    "assert sha1(str(type(pollution_2001.values.sum())).encode(\"utf-8\")+b\"e164fc25c35f6e0d\").hexdigest() == \"82e9fe609e3534e2928e815bd51c9add8383f1ba\", \"type of pollution_2001.values.sum() is not correct\"\n",
    "assert sha1(str(pollution_2001.values.sum()).encode(\"utf-8\")+b\"e164fc25c35f6e0d\").hexdigest() == \"f26663bbfd597df9f48a0f65f862b1b84e26c87f\", \"value of pollution_2001.values.sum() is not correct\"\n",
    "\n",
    "print('Success!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "4e7a96c4f21bfc5fb9e81ae4c20ade55",
     "grade": false,
     "grade_id": "cell-e39870b13e1cfdbc",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "**Question 3.7**\n",
    "<br> {points: 1}\n",
    "\n",
    "Now repeat what you did for Question 3.6, but filter for 2006 instead. \n",
    "\n",
    "*Assign your answer to an object called `pollution_2006`.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "94e97bf90f8fe784d1973e27c11928da",
     "grade": false,
     "grade_id": "cell-f32f902d017d6f0f",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# your code here\n",
    "raise NotImplementedError\n",
    "pollution_2006"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "max_height": 100,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "133207f07240ad20d455deea902f95fb",
     "grade": true,
     "grade_id": "cell-df023e23794302c6",
     "locked": true,
     "points": 3,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "from hashlib import sha1\n",
    "assert str(type(pollution_2006 is None)) == \"<class 'bool'>\", \"type of pollution_2006 is None is not bool. pollution_2006 is None should be a bool\"\n",
    "assert str(pollution_2006 is None) == \"False\", \"boolean value of pollution_2006 is None is not correct\"\n",
    "\n",
    "assert str(type(pollution_2006.shape)) == \"<class 'tuple'>\", \"type of pollution_2006.shape is not tuple. pollution_2006.shape should be a tuple\"\n",
    "assert str(len(pollution_2006.shape)) == \"2\", \"length of pollution_2006.shape is not correct\"\n",
    "assert str(sorted(map(str, pollution_2006.shape))) == \"['1', '14']\", \"values of pollution_2006.shape are not correct\"\n",
    "assert str(pollution_2006.shape) == \"(1, 14)\", \"order of elements of pollution_2006.shape is not correct\"\n",
    "\n",
    "assert sha1(str(type(pollution_2006.MXY.values)).encode(\"utf-8\")+b\"2be4068989360448\").hexdigest() == \"2a8a6b5054afc7f1e5aa6871313c920629a5c5c1\", \"type of pollution_2006.MXY.values is not correct\"\n",
    "assert sha1(str(pollution_2006.MXY.values).encode(\"utf-8\")+b\"2be4068989360448\").hexdigest() == \"c78f638fbdaa1ceb3a3e29305ad5ea19999acc0f\", \"value of pollution_2006.MXY.values is not correct\"\n",
    "\n",
    "assert sha1(str(type(pollution_2006.values.sum())).encode(\"utf-8\")+b\"8ee4d4efcad202ee\").hexdigest() == \"620f866c6d8c5c7fb199adc046e33ee26987cfa1\", \"type of pollution_2006.values.sum() is not correct\"\n",
    "assert sha1(str(pollution_2006.values.sum()).encode(\"utf-8\")+b\"8ee4d4efcad202ee\").hexdigest() == \"b0c046da31e10514d8e75bda9cfaf781baf63809\", \"value of pollution_2006.values.sum() is not correct\"\n",
    "\n",
    "print('Success!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "ecc042d43f280cdc8e6fa3f36b83e117",
     "grade": false,
     "grade_id": "cell-a16e6e9379986fdd",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "**Question 3.8** \n",
    "<br> {points: 1}\n",
    "\n",
    "Which pollutant decreased by the greatest magnitude between 2001 and 2006? Given that your the two objects you just created, `pollution_2001` and `pollution_2006` are data frames with the same columns you should be able to subtract the two objects to find which pollutant decreased by the greatest magnitude between the two years. \n",
    "\n",
    "*Assign your answer to an object called `answer3_8`. Make sure to write the answer exactly as it is given in the data set.* Example: \n",
    "\n",
    "```\n",
    "answer3_8 = \"BEN\"\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "c003c9b98d2d227c7fb824f738676fda",
     "grade": false,
     "grade_id": "cell-37d1d8a36a3010c8",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# your code here\n",
    "raise NotImplementedError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "max_height": 100,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "63c7ffa80a4c2d3739a9c2090684c9fa",
     "grade": true,
     "grade_id": "cell-5ed11e7cbe1ac843",
     "locked": true,
     "points": 3,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "from hashlib import sha1\n",
    "assert sha1(str(type(answer3_8)).encode(\"utf-8\")+b\"e175514f4226a8da\").hexdigest() == \"5b373976488fde5c4c9b34f6ac8a9a7510dded10\", \"type of answer3_8 is not str. answer3_8 should be an str\"\n",
    "assert sha1(str(len(answer3_8)).encode(\"utf-8\")+b\"e175514f4226a8da\").hexdigest() == \"d490740705304cb94acb079e60b04d0339874e64\", \"length of answer3_8 is not correct\"\n",
    "assert sha1(str(answer3_8.lower()).encode(\"utf-8\")+b\"e175514f4226a8da\").hexdigest() == \"6bb55b99de2dbed813cac79e51fef7e79a66330f\", \"value of answer3_8 is not correct\"\n",
    "assert sha1(str(answer3_8).encode(\"utf-8\")+b\"e175514f4226a8da\").hexdigest() == \"0e9ccfadcd6c0f433ac9c640995be68d7b8387ee\", \"correct string value of answer3_8 but incorrect case of letters\"\n",
    "\n",
    "print('Success!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "fabf7b47998a71ea8afd9ed6ceb24321",
     "grade": false,
     "grade_id": "cell-39c7d54ce32a3cf3",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "**Question 3.9**\n",
    "<br> {points: 1}\n",
    "\n",
    "Given that there were only 14 columns in the data frame above, you could use your eyes to pick out which pollutant decreased by the greatest magnitude between 2001 and 2006. But what would you do if you had 100 columns? Or 1000 columns? It would take A LONG TIME for your human eyeballs to find the biggest difference. Maybe you could use the min funcion by specifying `axis=1` (horizontally):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "c4c46f5cccfd17742f297cc6c14a12ac",
     "grade": false,
     "grade_id": "cell-3e5f51fc465018c3",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# run this cell\n",
    "(pollution_2006 - pollution_2001).min(axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "7ce41cb786907c1c71338be09fb2c104",
     "grade": false,
     "grade_id": "cell-6281bc171c2d9074",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "This is a step in the right direction, but you get the value and not the column name... What are we to do? Tidy our data! Our data is not in tidy format, and so it's difficult to access the values for the variable pollutant because they are stuck as column headers. Let's use `melt` to tidy our data and make it look like this:\n",
    "\n",
    "| pollutant | value  |\n",
    "|-----------|--------|\n",
    "| BEN       | -33.04 |\n",
    "| CO        | -6.91  |\n",
    "| ...       | ...    |\n",
    "\n",
    "To answer this question, fill in the `___` in the cell below. \n",
    "\n",
    "*Assign your answer to an object called `pollution_diff` and ensure it has the same column names as the table pictured above.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "c70d664f8482b90fa7f1b1d59234e413",
     "grade": false,
     "grade_id": "cell-96e5081abb9ab341",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "pollution_diff = pollution_2006 - pollution_2001\n",
    "# pollution_diff = ___.melt(var_name=___, value_name=___)\n",
    "\n",
    "\n",
    "# your code here\n",
    "raise NotImplementedError\n",
    "pollution_diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "max_height": 100,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "d2775aada5e5eb068553f65ea630344e",
     "grade": true,
     "grade_id": "cell-434094b036007273",
     "locked": true,
     "points": 3,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "from hashlib import sha1\n",
    "assert sha1(str(type(pollution_diff is None)).encode(\"utf-8\")+b\"fad8df0a360f1a4f\").hexdigest() == \"76a528924e05ab1f17bcbcb6d2d546236ed43264\", \"type of pollution_diff is None is not bool. pollution_diff is None should be a bool\"\n",
    "assert sha1(str(pollution_diff is None).encode(\"utf-8\")+b\"fad8df0a360f1a4f\").hexdigest() == \"ce525f646fdbcf4c217cc7bf9067d02cf1338c8b\", \"boolean value of pollution_diff is None is not correct\"\n",
    "\n",
    "assert sha1(str(type(pollution_diff.shape)).encode(\"utf-8\")+b\"b5da11d958d43cd3\").hexdigest() == \"5438c34c8389813691f62f329c2dd623d4f5bd70\", \"type of pollution_diff.shape is not tuple. pollution_diff.shape should be a tuple\"\n",
    "assert sha1(str(len(pollution_diff.shape)).encode(\"utf-8\")+b\"b5da11d958d43cd3\").hexdigest() == \"39dde6ac350393783599b04356f31e32bc5acd4c\", \"length of pollution_diff.shape is not correct\"\n",
    "assert sha1(str(sorted(map(str, pollution_diff.shape))).encode(\"utf-8\")+b\"b5da11d958d43cd3\").hexdigest() == \"b202ff666f2f99515c5896257e2b1c6e51120ab0\", \"values of pollution_diff.shape are not correct\"\n",
    "assert sha1(str(pollution_diff.shape).encode(\"utf-8\")+b\"b5da11d958d43cd3\").hexdigest() == \"d2d28aa5cc2fcd4eaa010f718b4a33edc9cb9fa2\", \"order of elements of pollution_diff.shape is not correct\"\n",
    "\n",
    "assert sha1(str(type(pollution_diff.columns.values)).encode(\"utf-8\")+b\"2983b88e295a66a2\").hexdigest() == \"c76593508b180beb7a1cba3a9de57c601f13f6c8\", \"type of pollution_diff.columns.values is not correct\"\n",
    "assert sha1(str(pollution_diff.columns.values).encode(\"utf-8\")+b\"2983b88e295a66a2\").hexdigest() == \"834bf6dde661a8fefa214d7ff20d4ddeb70de147\", \"value of pollution_diff.columns.values is not correct\"\n",
    "\n",
    "assert sha1(str(type(sum(pollution_diff.value))).encode(\"utf-8\")+b\"f83055ec3734b1b8\").hexdigest() == \"223fb0358691e4812db193386e009f9a6c05ff4d\", \"type of sum(pollution_diff.value) is not float. Please make sure it is float and not np.float64, etc. You can cast your value into a float using float()\"\n",
    "assert sha1(str(round(sum(pollution_diff.value), 2)).encode(\"utf-8\")+b\"f83055ec3734b1b8\").hexdigest() == \"f4338b85b6ace81a3dcc6f13c44abd8325dfc926\", \"value of sum(pollution_diff.value) is not correct (rounded to 2 decimal places)\"\n",
    "\n",
    "print('Success!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "812d2ec14e8a81e751e06db626ebf1d0",
     "grade": false,
     "grade_id": "cell-8933eb3ea15101f3",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "**Question 3.10**\n",
    "<br> {points: 1}\n",
    "\n",
    "Now that you have tidy data, you can use `sort_values` and argument `ascending=False` to order the data in descending order. Each element of the `value` column corresponds to an amount of decrease in a pollutant; so the *largest decrease* in pollutant should be *most negative entry*, i.e., the last row in the resulting dataframe. Therefore, we can take the sorted dataframe and chain it to `tail` (with the argument `1`) to return only the last row of the data frame.\n",
    "\n",
    "(the function `tail` is just like `head`, except it returns the last rows of the dataframe instead of the first rows.)\n",
    "\n",
    "To answer this question, fill in the `___` in the cell below. \n",
    "\n",
    "*Assign your answer to an object called `max_pollution_diff`.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "1c8e98272b17f2687700eeba3998ea5d",
     "grade": false,
     "grade_id": "cell-b25d71fbf02fa70e",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# max_pollution_diff = ___.sort_values(by=___, ascending=False).tail(1)\n",
    "\n",
    "# your code here\n",
    "raise NotImplementedError\n",
    "max_pollution_diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "max_height": 100,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "3b5f11284f115eee6f890c5244f02d6a",
     "grade": true,
     "grade_id": "cell-f9cfd97235c900d5",
     "locked": true,
     "points": 3,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "from hashlib import sha1\n",
    "assert sha1(str(type(max_pollution_diff is None)).encode(\"utf-8\")+b\"84f3415dad407275\").hexdigest() == \"9c1e492ae7c2eb2a38db5dedb23536e5c68c1475\", \"type of max_pollution_diff is None is not bool. max_pollution_diff is None should be a bool\"\n",
    "assert sha1(str(max_pollution_diff is None).encode(\"utf-8\")+b\"84f3415dad407275\").hexdigest() == \"11bc84d06f1219e0dac48d3e6d271ccf8ddcfecc\", \"boolean value of max_pollution_diff is None is not correct\"\n",
    "\n",
    "assert sha1(str(type(max_pollution_diff.shape)).encode(\"utf-8\")+b\"8b20498974ba31d5\").hexdigest() == \"da1bdcd98e76aac4577d95adcee545eb25d093d7\", \"type of max_pollution_diff.shape is not tuple. max_pollution_diff.shape should be a tuple\"\n",
    "assert sha1(str(len(max_pollution_diff.shape)).encode(\"utf-8\")+b\"8b20498974ba31d5\").hexdigest() == \"f85222960e76c7a1e14c334fb0f06a9388b4e053\", \"length of max_pollution_diff.shape is not correct\"\n",
    "assert sha1(str(sorted(map(str, max_pollution_diff.shape))).encode(\"utf-8\")+b\"8b20498974ba31d5\").hexdigest() == \"67762b84da9813babfc60152742cc48d18e3f91a\", \"values of max_pollution_diff.shape are not correct\"\n",
    "assert sha1(str(max_pollution_diff.shape).encode(\"utf-8\")+b\"8b20498974ba31d5\").hexdigest() == \"5598cc30717dc5f039887f1fc0fae9c36ad753a2\", \"order of elements of max_pollution_diff.shape is not correct\"\n",
    "\n",
    "assert sha1(str(type(max_pollution_diff.columns.values)).encode(\"utf-8\")+b\"1f922de122fca91b\").hexdigest() == \"e12b8ab5c463b1fd94f8287da75347e074fb5798\", \"type of max_pollution_diff.columns.values is not correct\"\n",
    "assert sha1(str(max_pollution_diff.columns.values).encode(\"utf-8\")+b\"1f922de122fca91b\").hexdigest() == \"950c62acb74638e82c08f088de4dd0d46cc0c8e7\", \"value of max_pollution_diff.columns.values is not correct\"\n",
    "\n",
    "assert sha1(str(type(sum(max_pollution_diff.value))).encode(\"utf-8\")+b\"2b966cd54b1959dc\").hexdigest() == \"4f1dbec17c1c06107045954944beb75ec5cc76b8\", \"type of sum(max_pollution_diff.value) is not float. Please make sure it is float and not np.float64, etc. You can cast your value into a float using float()\"\n",
    "assert sha1(str(round(sum(max_pollution_diff.value), 2)).encode(\"utf-8\")+b\"2b966cd54b1959dc\").hexdigest() == \"b1b32c313dd5dc6310c9f3c4e033e06f97230377\", \"value of sum(max_pollution_diff.value) is not correct (rounded to 2 decimal places)\"\n",
    "\n",
    "print('Success!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "764ce1e60976980e7a5d13cde20d8fa7",
     "grade": false,
     "grade_id": "cell-cc19d9a2d3663e09",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "At the end of this data wrangling worksheet, we'll leave you with a couple quotes to ponder:\n",
    "\n",
    "> “Happy families are all alike; every unhappy family is unhappy in its own way.” –– Leo Tolstoy\n",
    "\n",
    "> “Tidy datasets are all alike, but every messy dataset is messy in its own way.” –– Hadley Wickham\n"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "encoding": "# -*- coding: utf-8 -*-"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
