{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "7c6b7ff9caf26bb46f3f1139cf91eefa",
     "grade": false,
     "grade_id": "cell-63e551f4dad255b8",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# Tutorial: Regression II: linear regression\n",
    "\n",
    "This worksheet covers the [Regression II: linear regression](https://datasciencebook.ca/regression2.html) chapter of the online textbook, which also lists the learning objectives for this worksheet. You should read the textbook chapter before attempting this worksheet. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "cdac7eb557055833e61ab37ec40a33ad",
     "grade": false,
     "grade_id": "cell-7b457a3bc36388de",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "### Run this cell before continuing.\n",
    "library(tidyverse)\n",
    "library(repr)\n",
    "library(tidymodels)\n",
    "library(GGally)\n",
    "library(ISLR)\n",
    "options(repr.matrix.max.rows = 6)\n",
    "source(\"cleanup.R\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "4dcf7fc04c1db294415cac5732c32b8a",
     "grade": false,
     "grade_id": "cell-c422b97008fe2c60",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Predicting credit card balance\n",
    "\n",
    "<img src='https://media.giphy.com/media/LCdPNT81vlv3y/giphy-downsized-large.gif' align=\"left\" width='400'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "333345e00ec1f82749f73a17935beb96",
     "grade": false,
     "grade_id": "cell-7383d2428d0d989a",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Source: https://media.giphy.com/media/LCdPNT81vlv3y/giphy-downsized-large.gif\n",
    "\n",
    "Here in this worksheet we will work with a simulated data set that contains information that we can use to create a model to predict customer credit card balance. A bank might use such information to predict which customers might be the most profitable to lend to (customers who carry a balance, but do not default, for example).\n",
    "\n",
    "Specifically, we wish to build a model to predict credit card balance (`Balance` column) based on income (`Income` column) and credit rating (`Rating` column)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "235de1cda4994aae55cc3c1a70a0f196",
     "grade": false,
     "grade_id": "cell-802418710dd13a37",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "We access this data set by reading it from an R data package that we loaded at the beginning of the worksheet, `ISLR`. Loading that package gives access to a variety of data sets, including the `Credit` data set that we will be working with. We will rename this data set `credit_original` to avoid confusion later in the worksheet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "33b2c059ba7f85882d29f71e245be006",
     "grade": false,
     "grade_id": "cell-7429888f4a5a274a",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# run this cell\n",
    "credit_original <- Credit\n",
    "credit_original"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "ca4a729d729182201f0505f69a97f730",
     "grade": false,
     "grade_id": "cell-50099db20db03328",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**Question 1.1**\n",
    "<br> {points: 1}\n",
    "\n",
    "Select only the columns of data we are interested in using for our prediction (both the predictors and the response variable) and use the `as_tibble` function to convert it to a tibble (it is currently a base R data frame). Name the modified data frame `credit` (using a lowercase c).\n",
    "\n",
    "*Note: We could alternatively just leave these variables in and use our recipe formula below to specify our predictors and response. But for this worksheet, let's select the relevant columns first.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "9981c9c66ba813fab33808a277d6bed9",
     "grade": false,
     "grade_id": "cell-f8ecf1ab64d52b66",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# your code here\n",
    "fail() # No Answer - remove if you provide an answer\n",
    "credit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "10f04d85dda6576bb204a4c4e427a68f",
     "grade": true,
     "grade_id": "cell-9342aee7f4b97ddf",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "library(digest)\n",
    "stopifnot(\"credit should be a data frame\"= setequal(digest(paste(toString('data.frame' %in% class(credit)), \"41948\")), \"47887f4381811afaeed160e085573c66\"))\n",
    "stopifnot(\"dimensions of credit are not correct\"= setequal(digest(paste(toString(dim(credit)), \"41948\")), \"5561fb1869136739c7cd11e9a68a354c\"))\n",
    "stopifnot(\"column names of credit are not correct\"= setequal(digest(paste(toString(sort(colnames(credit))), \"41948\")), \"c397410b1e9214f51494d32aa3228039\"))\n",
    "stopifnot(\"types of columns in credit are not correct\"= setequal(digest(paste(toString(sort(unlist(sapply(credit, class)))), \"41948\")), \"9ee230d24e007d573c49bd16e8db504d\"))\n",
    "stopifnot(\"values in one or more numerical columns in credit are not correct\"= setequal(digest(paste(toString(if (any(sapply(credit, is.numeric))) sort(round(sapply(credit[, sapply(credit, is.numeric)], sum, na.rm = TRUE), 2)) else 0), \"41948\")), \"2a5c4d5e6c638e97e7d0398bdaff93ff\"))\n",
    "stopifnot(\"values in one or more character columns in credit are not correct\"= setequal(digest(paste(toString(if (any(sapply(credit, is.character))) sum(sapply(credit[sapply(credit, is.character)], function(x) length(unique(x)))) else 0), \"41948\")), \"8517ae3c3200cc12e21edfe848ff3de5\"))\n",
    "stopifnot(\"values in one or more factor columns in credit are not correct\"= setequal(digest(paste(toString(if (any(sapply(credit, is.factor))) sum(sapply(credit[, sapply(credit, is.factor)], function(col) length(unique(col)))) else 0), \"41948\")), \"8517ae3c3200cc12e21edfe848ff3de5\"))\n",
    "\n",
    "print('Success!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "2f272644edbfc9334ad082035c268ef0",
     "grade": false,
     "grade_id": "cell-505c4d1e16fc257f",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**Question 1.2**\n",
    "<br> {points: 1}\n",
    "\n",
    "**Before** we perform exploratory data analysis, we should create our training and testing data sets. First, split the `credit` data set. Use 60% of the data and set the variables we want to predict as the `strata` argument. Assign your answer to an object called `credit_split`.\n",
    "\n",
    "Assign your training data set to an object called `credit_training` and your testing data set to an object called `credit_testing`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "7c1dc4f5df9c94a67389c26ad8c7fdea",
     "grade": false,
     "grade_id": "cell-0a1b215548c7e884",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "set.seed(2000)\n",
    "# your code here\n",
    "fail() # No Answer - remove if you provide an answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "d7f0db1961af786154bef98e2bc6dec8",
     "grade": true,
     "grade_id": "cell-c6bf91ef0c8f21b5",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "library(digest)\n",
    "stopifnot(\"type of 'rsplit' %in% class(credit_split) is not logical\"= setequal(digest(paste(toString(class('rsplit' %in% class(credit_split))), \"b41d3\")), \"aa67b03756a157b72a6aae231d6d953b\"))\n",
    "stopifnot(\"logical value of 'rsplit' %in% class(credit_split) is not correct\"= setequal(digest(paste(toString('rsplit' %in% class(credit_split)), \"b41d3\")), \"9273a9a5e78c05174cb9e45cec815be9\"))\n",
    "\n",
    "stopifnot(\"credit_training should be a data frame\"= setequal(digest(paste(toString('data.frame' %in% class(credit_training)), \"b41d4\")), \"65d777529714b161c33ec340e268e530\"))\n",
    "stopifnot(\"dimensions of credit_training are not correct\"= setequal(digest(paste(toString(dim(credit_training)), \"b41d4\")), \"9727ff9f4f6f1cfcfbccb5c7b1a7faaf\"))\n",
    "stopifnot(\"column names of credit_training are not correct\"= setequal(digest(paste(toString(sort(colnames(credit_training))), \"b41d4\")), \"8bb96f152cfc3d889425ce266bddfa8d\"))\n",
    "stopifnot(\"types of columns in credit_training are not correct\"= setequal(digest(paste(toString(sort(unlist(sapply(credit_training, class)))), \"b41d4\")), \"9c1b708dee533f02dddc4f6e47c004bf\"))\n",
    "stopifnot(\"values in one or more numerical columns in credit_training are not correct\"= setequal(digest(paste(toString(if (any(sapply(credit_training, is.numeric))) sort(round(sapply(credit_training[, sapply(credit_training, is.numeric)], sum, na.rm = TRUE), 2)) else 0), \"b41d4\")), \"c4b578f35d54f879b92e2e7e18fdbd4a\"))\n",
    "stopifnot(\"values in one or more character columns in credit_training are not correct\"= setequal(digest(paste(toString(if (any(sapply(credit_training, is.character))) sum(sapply(credit_training[sapply(credit_training, is.character)], function(x) length(unique(x)))) else 0), \"b41d4\")), \"2a2589dae9a11d469d9da6c1e25688c2\"))\n",
    "stopifnot(\"values in one or more factor columns in credit_training are not correct\"= setequal(digest(paste(toString(if (any(sapply(credit_training, is.factor))) sum(sapply(credit_training[, sapply(credit_training, is.factor)], function(col) length(unique(col)))) else 0), \"b41d4\")), \"2a2589dae9a11d469d9da6c1e25688c2\"))\n",
    "\n",
    "stopifnot(\"credit_testing should be a data frame\"= setequal(digest(paste(toString('data.frame' %in% class(credit_testing)), \"b41d5\")), \"f4112672ee3e032b36a45d4bf1aab7c2\"))\n",
    "stopifnot(\"dimensions of credit_testing are not correct\"= setequal(digest(paste(toString(dim(credit_testing)), \"b41d5\")), \"92217945074434ab190db3e16b8203cf\"))\n",
    "stopifnot(\"column names of credit_testing are not correct\"= setequal(digest(paste(toString(sort(colnames(credit_testing))), \"b41d5\")), \"6ccdd2f49517d22e8efec4938c4ad088\"))\n",
    "stopifnot(\"types of columns in credit_testing are not correct\"= setequal(digest(paste(toString(sort(unlist(sapply(credit_testing, class)))), \"b41d5\")), \"5d63f7dbf804bc8ed6641f0d32effef3\"))\n",
    "stopifnot(\"values in one or more numerical columns in credit_testing are not correct\"= setequal(digest(paste(toString(if (any(sapply(credit_testing, is.numeric))) sort(round(sapply(credit_testing[, sapply(credit_testing, is.numeric)], sum, na.rm = TRUE), 2)) else 0), \"b41d5\")), \"70ede31b355ea2b12c9cf33e03e7f30f\"))\n",
    "stopifnot(\"values in one or more character columns in credit_testing are not correct\"= setequal(digest(paste(toString(if (any(sapply(credit_testing, is.character))) sum(sapply(credit_testing[sapply(credit_testing, is.character)], function(x) length(unique(x)))) else 0), \"b41d5\")), \"16927925c833da6c82a6646840466778\"))\n",
    "stopifnot(\"values in one or more factor columns in credit_testing are not correct\"= setequal(digest(paste(toString(if (any(sapply(credit_testing, is.factor))) sum(sapply(credit_testing[, sapply(credit_testing, is.factor)], function(col) length(unique(col)))) else 0), \"b41d5\")), \"16927925c833da6c82a6646840466778\"))\n",
    "\n",
    "print('Success!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "e832a23d7f1ced73ea3a1dabd643e3f4",
     "grade": false,
     "grade_id": "cell-8fb9e925bafe7b08",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**Question 1.3**\n",
    "<br> {points: 1}\n",
    "\n",
    "Using only the observations in the training data set, use the `ggpairs` library create a pairplot (also called \"scatter plot matrix\") of all the columns we are interested in including in our model. Since we have not covered how to create these in the textbook, we have provided you with most of the code below and you just need to provide suitable options for the size of the plot.\n",
    "\n",
    "The pairplot contains a scatter plot of each pair of columns that you are plotting in the lower left corner, the diagonal contains smoothed histograms of each individual column, and the upper right corner contains the correlation coefficient (a quantitative measure of the relation between two variables)\n",
    "\n",
    "*Name the plot object `credit_pairplot`.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "66525386546c97c0e63b062c1235d387",
     "grade": false,
     "grade_id": "cell-4a1c52e071e0b23e",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# options(...)\n",
    "# credit_pairplot <- credit_training |> \n",
    "#     ggpairs(mapping = aes(alpha = 0.4)) +\n",
    "#     theme(text = element_text(size = 20))\n",
    "\n",
    "# your code here\n",
    "fail() # No Answer - remove if you provide an answer\n",
    "credit_pairplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "464bc1c09fd51552827b625be2f68a0a",
     "grade": true,
     "grade_id": "cell-883edd273699e4b7",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "library(digest)\n",
    "stopifnot(\"type of ('ggmatrix' %in% c(class(credit_pairplot))) is not logical\"= setequal(digest(paste(toString(class(('ggmatrix' %in% c(class(credit_pairplot))))), \"19d5a\")), \"a4aac42f2ce4e5027c668c77c60cd78d\"))\n",
    "stopifnot(\"logical value of ('ggmatrix' %in% c(class(credit_pairplot))) is not correct\"= setequal(digest(paste(toString(('ggmatrix' %in% c(class(credit_pairplot)))), \"19d5a\")), \"08e38bf77f0f71ca45eeaa541d42c31a\"))\n",
    "\n",
    "print('Success!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "ca9eaca8a37dcc89f1d9f8d9ee248cb8",
     "grade": false,
     "grade_id": "cell-8c160d0c2cc2e44b",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**Question 1.4** Multiple Choice:\n",
    "<br> {points: 1} \n",
    "\n",
    "Looking at the `ggpairs` plot above, which of the following statements is **incorrect**?\n",
    "\n",
    "A. There is a strong positive relationship between the response variable (`Balance`) and the `Rating` predictor\n",
    "\n",
    "B. There is a strong positive relationship between the two predictors (`Income` and `Rating`)\n",
    "\n",
    "C. There is a strong positive relationship between the response variable (`Balance`) and the `Income` predictor\n",
    "\n",
    "D. None of the above statements are incorrect\n",
    "\n",
    "*Assign your answer to an object called `answer1.4`. Make sure your answer is an uppercase letter and is surrounded by quotation marks (e.g. `\"F\"`).*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "d9100063d5fb43eaec13a065d9f68c60",
     "grade": false,
     "grade_id": "cell-60cc3240844fe505",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# your code here\n",
    "fail() # No Answer - remove if you provide an answer\n",
    "answer1.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "d68100a263d043d78808187f31926211",
     "grade": true,
     "grade_id": "cell-921cf1869c166f49",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "library(digest)\n",
    "stopifnot(\"type of answer1.4 is not character\"= setequal(digest(paste(toString(class(answer1.4)), \"2470e\")), \"92083ff14963ea52805cb525e8b9a97b\"))\n",
    "stopifnot(\"length of answer1.4 is not correct\"= setequal(digest(paste(toString(length(answer1.4)), \"2470e\")), \"0c72f34e39b62bab8f303b80bc1e68ff\"))\n",
    "stopifnot(\"value of answer1.4 is not correct\"= setequal(digest(paste(toString(tolower(answer1.4)), \"2470e\")), \"6c5da10615814fa775e8ce0c963130fd\"))\n",
    "stopifnot(\"letters in string value of answer1.4 are correct but case is not correct\"= setequal(digest(paste(toString(answer1.4), \"2470e\")), \"b64109fc8b41777dbd3a68c99230ab9a\"))\n",
    "\n",
    "print('Success!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "882278e84431f486d8ec778b6621a600",
     "grade": false,
     "grade_id": "cell-ec78a305c07838f3",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**Question 1.5**\n",
    "<br> {points: 1}\n",
    "\n",
    "Now that we have our training data, we will fit a linear regression model.\n",
    "\n",
    "- Create and assign your linear regression model specification to an object called `lm_spec`.  \n",
    "- Create a recipe for the model. Assign your answer to an object called `credit_recipe`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "591584ea817ae977213aa48f70fbb35b",
     "grade": false,
     "grade_id": "cell-9736241c0c2966b9",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "set.seed(2020) #DO NOT REMOVE\n",
    "\n",
    "# your code here\n",
    "fail() # No Answer - remove if you provide an answer\n",
    "print(lm_spec)\n",
    "print(credit_recipe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "7f1fee2d47fb19e3d1e332b72415f8cc",
     "grade": true,
     "grade_id": "cell-a647adab28a3dfb2",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "library(digest)\n",
    "stopifnot(\"lm_spec should be a model specification\"= setequal(digest(paste(toString('model_spec' %in% class(lm_spec)), \"4359f\")), \"c3de4adb350c9e72231be36e3e1eb182\"))\n",
    "stopifnot(\"model specification in lm_spec is not correct\"= setequal(digest(paste(toString(lm_spec$mode), \"4359f\")), \"62b85f5ef268656caad854508d4abfda\"))\n",
    "stopifnot(\"computational engine in lm_spec is not correct\"= setequal(digest(paste(toString(lm_spec$engine), \"4359f\")), \"39f6e4d4d36e0daef96c9b118fe1d1c5\"))\n",
    "\n",
    "stopifnot(\"credit_recipe should be a recipe\"= setequal(digest(paste(toString('recipe' %in% class(credit_recipe)), \"435a0\")), \"a647787d013d8bcd1694e360b1e6fd2c\"))\n",
    "stopifnot(\"response variable of credit_recipe is not correct\"= setequal(digest(paste(toString(sort(filter(credit_recipe$var_info, role == 'outcome')$variable)), \"435a0\")), \"b64c7a642289dc1c8234eb9dafbc6829\"))\n",
    "stopifnot(\"predictor variable(s) of credit_recipe are not correct\"= setequal(digest(paste(toString(sort(filter(credit_recipe$var_info, role == 'predictor')$variable)), \"435a0\")), \"2c77215bbbe86725386f42bed206b92f\"))\n",
    "stopifnot(\"credit_recipe does not contain the correct data, might need to be standardized\"= setequal(digest(paste(toString(round(sum(bake(prep(credit_recipe), credit_recipe$template) %>% select_if(is.numeric), na.rm = TRUE), 2)), \"435a0\")), \"fcffff419aaf2314a613292ab7f9a70b\"))\n",
    "\n",
    "print('Success!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "bd2a0a4c5e85cacef68b09d90e93ee16",
     "grade": false,
     "grade_id": "cell-caf742da4236e6a8",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**Question 1.6**\n",
    "<br> {points: 1}\n",
    "\n",
    "Now that we have our model specification and recipe, let's put them together in a workflow, and fit our simple linear regression model. Assign the fit to an object called `credit_fit`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "d84efb98584068f8bb6c1f9b134fbb3e",
     "grade": false,
     "grade_id": "cell-6131349a47c37876",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "set.seed(2020) # DO NOT REMOVE\n",
    "\n",
    "# your code here\n",
    "fail() # No Answer - remove if you provide an answer\n",
    "credit_fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "f94cab8b6853c77a2e5cb7012b59dce7",
     "grade": true,
     "grade_id": "cell-4664079ebe7d0892",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "library(digest)\n",
    "stopifnot(\"credit_fit should be a workflow\"= setequal(digest(paste(toString('workflow' %in% class(credit_fit)), \"da8fd\")), \"08b5402a06e4e7d505f86c790e04cdd5\"))\n",
    "stopifnot(\"computational engine used in credit_fit is not correct\"= setequal(digest(paste(toString(credit_fit$fit$actions$model$spec$engine), \"da8fd\")), \"eff86ec04cc914c8876e049edf0bc11a\"))\n",
    "stopifnot(\"model specification used in credit_fit is not correct\"= setequal(digest(paste(toString(credit_fit$fit$actions$model$spec$mode), \"da8fd\")), \"a009304440d323b364eb9bcfdbf5945f\"))\n",
    "stopifnot(\"credit_fit must be a trained workflow, make sure to call the fit() function\"= setequal(digest(paste(toString(credit_fit$trained), \"da8fd\")), \"08b5402a06e4e7d505f86c790e04cdd5\"))\n",
    "stopifnot(\"predictor variable(s) of credit_fit are not correct\"= setequal(digest(paste(toString(sort(filter(credit_fit$pre$actions$recipe$recipe$var_info, role == 'predictor')$variable)), \"da8fd\")), \"401a1c3a99cd85bff827fdbf95dd05bb\"))\n",
    "stopifnot(\"credit_fit does not contain the correct data\"= setequal(digest(paste(toString(sort(vapply(credit_fit$pre$mold$predictors[, sapply(credit_fit$pre$mold$predictors, is.numeric)], function(col) if(!is.null(col)) round(sum(col), 2) else NA_real_, numeric(1)), na.last = NA)), \"da8fd\")), \"73e8abdd4f024e52cb135781464de30a\"))\n",
    "stopifnot(\"did not fit credit_fit on the training dataset\"= setequal(digest(paste(toString(nrow(credit_fit$pre$mold$outcomes)), \"da8fd\")), \"97a0796a6babc345e0a5344b0295a6a8\"))\n",
    "stopifnot(\"for classification/regression models, weight function is not correct\"= setequal(digest(paste(toString(quo_name(credit_fit$fit$actions$model$spec$args$weight_func)), \"da8fd\")), \"308a615b6fa74f4c90a75b0de572e617\"))\n",
    "stopifnot(\"for classification/regression models, response variable of credit_fit is not correct\"= setequal(digest(paste(toString(sort(filter(credit_fit$pre$actions$recipe$recipe$var_info, role == 'outcome')$variable)), \"da8fd\")), \"9a592cadad15dc40ffa84567eb830818\"))\n",
    "stopifnot(\"for KNN models, number of neighbours is not correct\"= setequal(digest(paste(toString(quo_name(credit_fit$fit$actions$model$spec$args$neighbors)), \"da8fd\")), \"308a615b6fa74f4c90a75b0de572e617\"))\n",
    "stopifnot(\"for clustering models, the clustering is not correct\"= setequal(digest(paste(toString(credit_fit$fit$fit$fit$cluster), \"da8fd\")), \"e59bb1522a273640eccd2ef95be05fdd\"))\n",
    "stopifnot(\"for clustering models, the total within-cluster sum-of-squared distances is not correct\"= setequal(digest(paste(toString(if (!is.null(credit_fit$fit$fit$fit$tot.withinss)) round(credit_fit$fit$fit$fit$tot.withinss, 2) else NULL), \"da8fd\")), \"e59bb1522a273640eccd2ef95be05fdd\"))\n",
    "\n",
    "print('Success!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "7a719239377063eb5f55584fb50289d3",
     "grade": false,
     "grade_id": "cell-7719909c65940401",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**Question 1.7** Multiple Choice:\n",
    "<br> {points: 1}\n",
    "\n",
    "Looking at the slopes/coefficients above from each of the predictors, which of the following mathematical equations is correct for your prediction model?\n",
    "\n",
    "A. $credit\\: card \\: balance = -528.014 -7.583*income  + 3.937*credit\\: card\\: rating$\n",
    "\n",
    "B. $credit\\: card \\: balance = -528.014 + 3.937*income  -7.583*credit\\: card\\: rating$\n",
    "\n",
    "C. $credit\\: card \\: balance = 528.014 -7.583*income  - 3.937*credit\\: card\\: rating$\n",
    "\n",
    "D. $credit\\: card \\: balance = 528.014 - 3.937*income  + 7.583*credit\\: card\\: rating$\n",
    "\n",
    "*Assign your answer to an object called `answer1.7`. Make sure your answer is an uppercase letter and is surrounded by quotation marks (e.g. `\"F\"`).*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "975b6169f7da0281e5027c6c4a88f430",
     "grade": false,
     "grade_id": "cell-9f0416355ca0cc31",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# your code here\n",
    "fail() # No Answer - remove if you provide an answer\n",
    "answer1.7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "9081c20900c36d166eb56ab315b06de1",
     "grade": true,
     "grade_id": "cell-7cb05955d5df0d29",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "library(digest)\n",
    "stopifnot(\"type of answer1.7 is not character\"= setequal(digest(paste(toString(class(answer1.7)), \"c7d33\")), \"5d0f5ba005fb57b8f62027a2e6e2dcdd\"))\n",
    "stopifnot(\"length of answer1.7 is not correct\"= setequal(digest(paste(toString(length(answer1.7)), \"c7d33\")), \"350efce462fcd4f546cb60b9b91c0ca9\"))\n",
    "stopifnot(\"value of answer1.7 is not correct\"= setequal(digest(paste(toString(tolower(answer1.7)), \"c7d33\")), \"ebd9146c0435d6b190731b9392b38463\"))\n",
    "stopifnot(\"letters in string value of answer1.7 are correct but case is not correct\"= setequal(digest(paste(toString(answer1.7), \"c7d33\")), \"adc580d20efbbb241cebd46879fdcefd\"))\n",
    "\n",
    "print('Success!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "fc6ace68a03d16950d92357844aa4374",
     "grade": false,
     "grade_id": "cell-7b9b2114fd06d867",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**Question 1.8**\n",
    "<br> {points: 1}\n",
    "\n",
    "Calculate the $RMSE$ to assess goodness of fit on `credit_fit` (remember this is how well it predicts on the training data used to fit the model). Return a single numerical value named `lm_rmse`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "8f1e98376e0d5239fc55746d68445240",
     "grade": false,
     "grade_id": "cell-12064d256dd640e2",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "set.seed(2020) # DO NOT REMOVE\n",
    "\n",
    "#... <- credit_fit |>\n",
    "#         predict(...) |>\n",
    "#         bind_cols(...) |>\n",
    "#         ...(truth = ..., estimate = ...) |>\n",
    "#         filter(.metric == ...) |>\n",
    "#         select(...) |>\n",
    "#         pull()\n",
    "\n",
    "# your code here\n",
    "fail() # No Answer - remove if you provide an answer\n",
    "lm_rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "2372f7183244e073a0b39a452ba8a2e3",
     "grade": true,
     "grade_id": "cell-8de81bb18dedbb48",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "library(digest)\n",
    "stopifnot(\"type of round(lm_rmse, 2) is not numeric\"= setequal(digest(paste(toString(class(round(lm_rmse, 2))), \"90585\")), \"6a9a39be28e580cc8d4c18896f797996\"))\n",
    "stopifnot(\"value of round(lm_rmse, 2) is not correct (rounded to 2 decimal places)\"= setequal(digest(paste(toString(round(round(lm_rmse, 2), 2)), \"90585\")), \"6fa56a60d830b3be9852ded837c36390\"))\n",
    "stopifnot(\"length of round(lm_rmse, 2) is not correct\"= setequal(digest(paste(toString(length(round(lm_rmse, 2))), \"90585\")), \"4ed611d7e1139df7d957b9c733499f31\"))\n",
    "stopifnot(\"values of round(lm_rmse, 2) are not correct\"= setequal(digest(paste(toString(sort(round(round(lm_rmse, 2), 2))), \"90585\")), \"6fa56a60d830b3be9852ded837c36390\"))\n",
    "\n",
    "print('Success!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "7c4f24ec39c37c951718172bfd25303e",
     "grade": false,
     "grade_id": "cell-f873952538d4f725",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**Question 1.9**\n",
    "<br> {points: 1}\n",
    "\n",
    "Calculate $RMSPE$ using the test data. Return a single numerical value named `lm_rmspe`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "8ebda83d7f617c3622b563526f69d179",
     "grade": false,
     "grade_id": "cell-5f42a9ac9068cfdf",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "set.seed(2020) # DO NOT REMOVE\n",
    "\n",
    "# your code here\n",
    "fail() # No Answer - remove if you provide an answer\n",
    "lm_rmspe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "94af8df159045fa331222a0b5dea7e51",
     "grade": true,
     "grade_id": "cell-41031aad5e75b436",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "library(digest)\n",
    "stopifnot(\"type of round(lm_rmspe, 2) is not numeric\"= setequal(digest(paste(toString(class(round(lm_rmspe, 2))), \"d4d4e\")), \"77487a178cef06539698a33a47356441\"))\n",
    "stopifnot(\"value of round(lm_rmspe, 2) is not correct (rounded to 2 decimal places)\"= setequal(digest(paste(toString(round(round(lm_rmspe, 2), 2)), \"d4d4e\")), \"1f76be0333f694c6626e4a04cb355366\"))\n",
    "stopifnot(\"length of round(lm_rmspe, 2) is not correct\"= setequal(digest(paste(toString(length(round(lm_rmspe, 2))), \"d4d4e\")), \"56dae57dc27a17e694234b2c468c7283\"))\n",
    "stopifnot(\"values of round(lm_rmspe, 2) are not correct\"= setequal(digest(paste(toString(sort(round(round(lm_rmspe, 2), 2))), \"d4d4e\")), \"1f76be0333f694c6626e4a04cb355366\"))\n",
    "\n",
    "print('Success!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "09c33a2af6c0198e95b449354d0ee751",
     "grade": false,
     "grade_id": "cell-f26f28bfc681966f",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**Question 1.9.1**\n",
    "<br> {points: 3}\n",
    "\n",
    "Redo this analysis using $k$-nn regression instead of linear regression. Use `set.seed(2000)` at the beginning of this code cell to make it reproducible. Use the same predictors and train - test data splits as you used for linear regression, and use 5-fold cross validation to **choose $k$ from the range 1-10**. Remember to scale and shift your predictors on your training data, and to apply that same standardization to your test data! \n",
    "Assign a single numeric value for $RMSPE$ for your k-nn model as your answer, and name it `knn_rmspe`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "45fb86a0ae1c06151284f4806d810d02",
     "grade": true,
     "grade_id": "cell-99f8a777ffd9b3e7",
     "locked": false,
     "points": 3,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "set.seed(2000) # DO NOT REMOVE\n",
    "\n",
    "# your code here\n",
    "fail() # No Answer - remove if you provide an answer\n",
    "knn_rmspe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "eac4896007ac91fc952be6aedf227196",
     "grade": false,
     "grade_id": "cell-8826c38ee017c109",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**Question 1.9.2** \n",
    "<br> {points: 3}\n",
    "\n",
    "Discuss which model, linear regression versus $k$-nn regression, gives better predictions and why you think that might be happening."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "c22fcd3031290228e3df02c09fecc609",
     "grade": true,
     "grade_id": "cell-051a638d3bfe7568",
     "locked": false,
     "points": 3,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "DOUBLE CLICK TO EDIT **THIS CELL** AND REPLACE THIS TEXT WITH YOUR ANSWER."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "64289e0aede7c718007b9f18070269fc",
     "grade": false,
     "grade_id": "cell-053902c100826449",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## 2. Ames Housing Prices\n",
    "\n",
    "<img src=\"https://media.giphy.com/media/xUPGGuzpmG3jfeYWIg/giphy.gif\" width = \"600\"/>\n",
    "\n",
    "Source: https://media.giphy.com/media/xUPGGuzpmG3jfeYWIg/giphy.gif\n",
    "\n",
    "If we take a look at the Business Insider report [What do millenials want in a home?](https://www.businessinsider.com/what-do-millennials-want-in-a-home-2017-2), we can see that millenials like newer houses that have their own defined spaces. Today we are going to be looking at housing data to understand how the sale price of a house is determined. Finding highly detailed housing data with the final sale prices is very hard, however researchers from Truman State Univeristy have studied and made available a dataset containing multiple variables for the city of Ames, Iowa. The data set describes the sale of individual residential property in Ames, Iowa\n",
    "from 2006 to 2010. You can read more about the data set [here](http://jse.amstat.org/v19n3/decock.pdf). Today we will be looking at 5 different variables to predict the sale price of a house. These variables are: \n",
    "\n",
    "- Lot Area: `lot_area`\n",
    "- Year Built: `year_built`\n",
    "- Basement Square Footage: `bsmt_sf`\n",
    "- First Floor Square Footage: `first_sf`\n",
    "- Second Floor Square Footage: `second_sf`\n",
    "\n",
    "First, load the data with the script given below. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "992ebb563ca096121d2732a731a70687",
     "grade": false,
     "grade_id": "cell-789ffdb0a2a88b3b",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# run this cell\n",
    "\n",
    "ames_data <- read_csv('data/ames.csv', col_types = cols()) |>\n",
    "    select(lot_area = Lot.Area, \n",
    "           year_built = Year.Built, \n",
    "           bsmt_sf = Total.Bsmt.SF, \n",
    "           first_sf = `X1st.Flr.SF`, \n",
    "           second_sf = `X2nd.Flr.SF`, \n",
    "           sale_price = SalePrice) |>\n",
    "    filter(!is.na(bsmt_sf))\n",
    "\n",
    "ames_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "233dcca362a292997c5d3789b6714dfd",
     "grade": false,
     "grade_id": "cell-e5207881e329c2a0",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**Question 2.1**\n",
    "<br> {points: 3}\n",
    "\n",
    "Split the data into a train dataset and a test dataset, based on a 70%-30% train-test split. Use `set.seed(2019)`. Remember that we want to predict the `sale_price` based on all of the other variables. \n",
    "\n",
    "Assign the objects to `ames_split`, `ames_training`, and `ames_testing`, respectively. \n",
    "\n",
    "*Use 2019 as your seed for the split.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "fd42296cc0e8349d1e2a7869c2d0b370",
     "grade": false,
     "grade_id": "cell-4677940cbd08ded9",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "set.seed(2019) # DO NOT CHANGE!\n",
    "# your code here\n",
    "fail() # No Answer - remove if you provide an answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "b872a4e065577720b19b0963ae3d5246",
     "grade": true,
     "grade_id": "cell-416374a3ce562c44",
     "locked": true,
     "points": 3,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "library(digest)\n",
    "stopifnot(\"type of exists('ames_split') is not logical\"= setequal(digest(paste(toString(class(exists('ames_split'))), \"230f3\")), \"9bfe53b14af9936e829981faefd1ec9c\"))\n",
    "stopifnot(\"logical value of exists('ames_split') is not correct\"= setequal(digest(paste(toString(exists('ames_split')), \"230f3\")), \"dfb66d669e47e49afa08a37014151e74\"))\n",
    "\n",
    "stopifnot(\"type of exists('ames_training') is not logical\"= setequal(digest(paste(toString(class(exists('ames_training'))), \"230f4\")), \"c882555a076c4abf44c38637add9ddcd\"))\n",
    "stopifnot(\"logical value of exists('ames_training') is not correct\"= setequal(digest(paste(toString(exists('ames_training')), \"230f4\")), \"5b023101d4defc826a7de694302ffea4\"))\n",
    "\n",
    "stopifnot(\"type of exists('ames_testing') is not logical\"= setequal(digest(paste(toString(class(exists('ames_testing'))), \"230f5\")), \"40374f0ff3e682bc183a4c1fe1c24f99\"))\n",
    "stopifnot(\"logical value of exists('ames_testing') is not correct\"= setequal(digest(paste(toString(exists('ames_testing')), \"230f5\")), \"0bd00aba3fcaac4eebd0f42423851903\"))\n",
    "\n",
    "# The rest of the tests are intentionally hidden so that you can practice deciding \n",
    "# when you have found the correct answer. \n",
    "print('Success!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "552618d5d5278b4e1b4873c2930dafcd",
     "grade": false,
     "grade_id": "cell-1060b3c866d44767",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**Question 2.2**\n",
    "<br> {points: 3}\n",
    "\n",
    "Let's start by exploring the training data. Use the `ggpairs()` function from the GGally package to explore the relationships between the different variables. \n",
    "\n",
    "Assign your plot object to a variable named `answer2.2`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "6dd2144c428f60171732366d7d422c2e",
     "grade": false,
     "grade_id": "cell-93bef9e4a6864e86",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "set.seed(2020) # DO NOT REMOVE\n",
    "\n",
    "# your code here\n",
    "fail() # No Answer - remove if you provide an answer\n",
    "answer2.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "787d27217349b525ef900200cd6928ca",
     "grade": true,
     "grade_id": "cell-ee3115b616837197",
     "locked": true,
     "points": 3,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "library(digest)\n",
    "stopifnot(\"type of exists('answer2.2') is not logical\"= setequal(digest(paste(toString(class(exists('answer2.2'))), \"33164\")), \"7f6a081159192ad6c81340cd01e689fd\"))\n",
    "stopifnot(\"logical value of exists('answer2.2') is not correct\"= setequal(digest(paste(toString(exists('answer2.2')), \"33164\")), \"a1a12956e60caacb314157d83642106f\"))\n",
    "\n",
    "# The rest of the tests are intentionally hidden so that you can practice deciding \n",
    "# when you have found the correct answer. \n",
    "print('Success!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "d18c00d77911e3d705db9bef32814dcf",
     "grade": false,
     "grade_id": "cell-e69b196736971fb3",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**Question 2.3** Multiple Choice:\n",
    "<br> {points: 1}\n",
    "\n",
    "Now that we have seen all the relationships between the variables, based solely on the scatterplots displayed above, which of the following variables would *not* be a  strong predictor for `sale_price`?\n",
    "\n",
    "A. `bsmt_sf`\n",
    "\n",
    "B. `year_built`\n",
    "\n",
    "C. `first_sf`\n",
    "\n",
    "D. `lot_area`\n",
    "\n",
    "E. `second_sf`\n",
    "\n",
    "F. It isn't clear from these plots\n",
    "\n",
    "*Assign your answer to an object called `answer2.3`. Make sure your answer is an uppercase letter and is surrounded by quotation marks (e.g. `\"F\"`).*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "0240bfa9c6d9530fab790f2ffa08d874",
     "grade": false,
     "grade_id": "cell-1a14adeddf034fe9",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# your code here\n",
    "fail() # No Answer - remove if you provide an answer\n",
    "answer2.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "4b91c2d90e5520b283d2bc8695783775",
     "grade": true,
     "grade_id": "cell-020aa6e5f8a70372",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "library(digest)\n",
    "stopifnot(\"type of exists('answer2.3') is not logical\"= setequal(digest(paste(toString(class(exists('answer2.3'))), \"6c22\")), \"aaf085d3f505a408e74d60bece2dbe20\"))\n",
    "stopifnot(\"logical value of exists('answer2.3') is not correct\"= setequal(digest(paste(toString(exists('answer2.3')), \"6c22\")), \"f6fba0ece7a6dd9c23e333aef11bc0d3\"))\n",
    "\n",
    "# The rest of the tests are intentionally hidden so that you can practice deciding \n",
    "# when you have found the correct answer. \n",
    "print('Success!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "3fb9246ee5b427164dd30ea792b607e6",
     "grade": false,
     "grade_id": "cell-f133a2d80fdd9cd3",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**Question 2.4 - Linear Regression**\n",
    "<br> {points: 3}\n",
    "\n",
    "Fit a linear regression model using `tidymodels` with `ames_training` using **all** the variables in the data set. \n",
    "- create a model specification called `lm_spec`\n",
    "- create a recipe called `ames_recipe`\n",
    "- create a workflow with your model spec and recipe, and then create the model fit and name it `ames_fit`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "4ffcf69255fc2560de92be92a4697a9b",
     "grade": false,
     "grade_id": "cell-a81625dc68efe574",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "set.seed(2020) # DO NOT REMOVE\n",
    "\n",
    "# your code here\n",
    "fail() # No Answer - remove if you provide an answer\n",
    "ames_fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "21c26bc9c6a407e2d8f5c5694b737053",
     "grade": true,
     "grade_id": "cell-664d89562f972a45",
     "locked": true,
     "points": 3,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "library(digest)\n",
    "stopifnot(\"type of exists('lm_spec') is not logical\"= setequal(digest(paste(toString(class(exists('lm_spec'))), \"73522\")), \"49c7807dc3a214063b40fddf0333551f\"))\n",
    "stopifnot(\"logical value of exists('lm_spec') is not correct\"= setequal(digest(paste(toString(exists('lm_spec')), \"73522\")), \"d004d6c80a083270385cb8c0e77149e5\"))\n",
    "\n",
    "stopifnot(\"type of exists('ames_recipe') is not logical\"= setequal(digest(paste(toString(class(exists('ames_recipe'))), \"73523\")), \"6bdad682f3eaad44db008153c640bb15\"))\n",
    "stopifnot(\"logical value of exists('ames_recipe') is not correct\"= setequal(digest(paste(toString(exists('ames_recipe')), \"73523\")), \"5372abab632d76e476569b114029933c\"))\n",
    "\n",
    "stopifnot(\"type of exists('ames_fit') is not logical\"= setequal(digest(paste(toString(class(exists('ames_fit'))), \"73524\")), \"29d905c7132e32e05293edf27b0725fe\"))\n",
    "stopifnot(\"logical value of exists('ames_fit') is not correct\"= setequal(digest(paste(toString(exists('ames_fit')), \"73524\")), \"2a3d3e68ef4a8292c382d33d560f8c34\"))\n",
    "\n",
    "# The rest of the tests are intentionally hidden so that you can practice deciding \n",
    "# when you have found the correct answer. \n",
    "print('Success!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "32585d4cd22317e98945a370c2c71f41",
     "grade": false,
     "grade_id": "cell-f5aa9d2d7559db6b",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**Question 2.5** True or False:\n",
    "<br> {points: 1}\n",
    "\n",
    "Aside from the intercept, all the variables have a positive relationship with the `sale_price`. This can be interpreted as the value of the variables decrease, the prices of the houses increase. \n",
    "\n",
    "*Assign your answer to an object called `answer2.5`. Make sure your answer is in lowercase letters and is surrounded by quotation marks (e.g. `\"true\"` or `\"false\"`).*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "9705d4715800f2635b5a7a4bc499a787",
     "grade": false,
     "grade_id": "cell-bb9de39d3d1ef72f",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# run this cell\n",
    "ames_fit$fit$fit$fit$coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "f5923486188c4827dabe1fa9a5bed28a",
     "grade": false,
     "grade_id": "cell-b2700d5cb1ebe069",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# your code here\n",
    "fail() # No Answer - remove if you provide an answer\n",
    "answer2.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "77dc5fcf40572a07e28e5a1b6686adca",
     "grade": true,
     "grade_id": "cell-d02d466ab600f590",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "library(digest)\n",
    "stopifnot(\"type of exists('answer2.5') is not logical\"= setequal(digest(paste(toString(class(exists('answer2.5'))), \"2c2b7\")), \"311acaef9c6b078459c07aa3c5e924a7\"))\n",
    "stopifnot(\"logical value of exists('answer2.5') is not correct\"= setequal(digest(paste(toString(exists('answer2.5')), \"2c2b7\")), \"bc92b54ba4e255635ba60ec9ad18fdd1\"))\n",
    "\n",
    "# The rest of the tests are intentionally hidden so that you can practice deciding \n",
    "# when you have found the correct answer. \n",
    "print('Success!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "cf3e4515adfe6af758c6ed01ed679c4c",
     "grade": false,
     "grade_id": "cell-ffcca6c97ae145c9",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**Question 2.6**\n",
    "<br> {points: 3}\n",
    "\n",
    "Looking at the coefficients and intercept produced from the cell block above, write down the equation for the linear model.\n",
    "\n",
    "Make sure to use correct math typesetting syntax (surround your answer with dollar signs, e.g. `$0.5 * a$`)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "885eb92a051da5f3bff81612c6175550",
     "grade": true,
     "grade_id": "cell-8234d8869e1be009",
     "locked": false,
     "points": 3,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "DOUBLE CLICK TO EDIT **THIS CELL** AND REPLACE THIS TEXT WITH YOUR ANSWER.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "9001f42c1ee56b21deddaced6167c3bb",
     "grade": false,
     "grade_id": "cell-33e696f6e5c6f880",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**Question 2.7** Multiple Choice:\n",
    "<br> {points: 1}\n",
    "\n",
    "Why can we not easily visualize the model above as a line or a plane in a single plot?\n",
    "\n",
    "A. This is not true, we can actually easily visualize the model\n",
    "\n",
    "B. The intercept is much larger (6 digits) than the coefficients (single/double digits)\n",
    "\n",
    "C. There are more than 2 predictors\n",
    "\n",
    "D. None of the above\n",
    "\n",
    "*Assign your answer to an object called `answer2.7`. Make sure your answer is an uppercase letter and is surrounded by quotation marks (e.g. `\"F\"`).*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "db866fef00cd7c616cee04861c3aefd0",
     "grade": false,
     "grade_id": "cell-9780a869a47de365",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# your code here\n",
    "fail() # No Answer - remove if you provide an answer\n",
    "answer2.7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "6c1815815e7a64b65ef5cee530ec24ca",
     "grade": true,
     "grade_id": "cell-e9fe30e9345df159",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "library(digest)\n",
    "stopifnot(\"type of exists('answer2.7') is not logical\"= setequal(digest(paste(toString(class(exists('answer2.7'))), \"cb6da\")), \"7f3c950e77b17682f55f873011f770fd\"))\n",
    "stopifnot(\"logical value of exists('answer2.7') is not correct\"= setequal(digest(paste(toString(exists('answer2.7')), \"cb6da\")), \"5bce8d430bab7188a2a77689dd184827\"))\n",
    "\n",
    "# The rest of the tests are intentionally hidden so that you can practice deciding \n",
    "# when you have found the correct answer. \n",
    "print('Success!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "8d03e13df884c417dd362853097a4cdc",
     "grade": false,
     "grade_id": "cell-10c2a24200d6582f",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**Question 2.8**\n",
    "<br> {points: 3}\n",
    "\n",
    "We need to evaluate how well our model is doing. For this question, calculate the $RMSPE$ (a single numerical value) of the linear regression model using the test data set and assign it to an object named `ames_rmspe`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "90c72d9eadc24ba632f1ad34cbfbd22d",
     "grade": false,
     "grade_id": "cell-d3d15c7887e2325a",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "set.seed(2020) # DO NOT REMOVE\n",
    "\n",
    "# your code here\n",
    "fail() # No Answer - remove if you provide an answer\n",
    "ames_rmspe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "fa0c1c738c7dd4a3dacafd19ad9567e3",
     "grade": true,
     "grade_id": "cell-83731b933e194459",
     "locked": true,
     "points": 3,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "library(digest)\n",
    "stopifnot(\"type of exists('ames_rmspe') is not logical\"= setequal(digest(paste(toString(class(exists('ames_rmspe'))), \"bfd0\")), \"965c939f8d7144c3c043b0e8ff1ff3a9\"))\n",
    "stopifnot(\"logical value of exists('ames_rmspe') is not correct\"= setequal(digest(paste(toString(exists('ames_rmspe')), \"bfd0\")), \"5b75a9b11a7a7b727f4a1c3fd4b1e3e8\"))\n",
    "\n",
    "# The rest of the tests are intentionally hidden so that you can practice deciding \n",
    "# when you have found the correct answer. \n",
    "print('Success!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "76a6751d4e5196f5ddf40f5ad2159a81",
     "grade": false,
     "grade_id": "cell-7075ba3a0703c792",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**Question 2.9** Multiple Choice:\n",
    "<br> {points: 1}\n",
    "\n",
    "Which of the following statements is **incorrect**?\n",
    "\n",
    "A. $RMSE$ is a measure of goodness of fit \n",
    "\n",
    "B. $RMSE$ measures how well the model predicts on data it was trained with \n",
    "\n",
    "C. $RMSPE$ measures how well the model predicts on data it was not trained with \n",
    "\n",
    "D. $RMSPE$ measures how well the model predicts on data it was trained with\n",
    "\n",
    "*Assign your answer to an object called `answer2.9`. Make sure your answer is an uppercase letter and is surrounded by quotation marks (e.g. `\"F\"`).*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "71e364b6d204d2b9d01ca8b315e1d3a8",
     "grade": false,
     "grade_id": "cell-776d29fda029b788",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# your code here\n",
    "fail() # No Answer - remove if you provide an answer\n",
    "answer2.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "79b52f5eb3cff3d5379f91d6e464369a",
     "grade": true,
     "grade_id": "cell-3831c36308e7c582",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "library(digest)\n",
    "stopifnot(\"type of exists('answer2.9') is not logical\"= setequal(digest(paste(toString(class(exists('answer2.9'))), \"1bd43\")), \"b67dc07817e26a91562ec3a728c627fd\"))\n",
    "stopifnot(\"logical value of exists('answer2.9') is not correct\"= setequal(digest(paste(toString(exists('answer2.9')), \"1bd43\")), \"21a9dc1612eeb7a0abfb464fa5f9b30b\"))\n",
    "\n",
    "# The rest of the tests are intentionally hidden so that you can practice deciding \n",
    "# when you have found the correct answer. \n",
    "print('Success!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "05ab974f885349494a16e690d13c923a",
     "grade": false,
     "grade_id": "cell-e90c30e28fd8694e",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "source(\"cleanup.R\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.3.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
