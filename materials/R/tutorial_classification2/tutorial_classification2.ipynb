{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "7cb68f8dda47f70083059d82be9f7167",
     "grade": false,
     "grade_id": "cell-27916401df9a371b",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "# Tutorial: Classification II: evaluation & tuning\n",
    "\n",
    "This worksheet covers the [Classification II: evaluation & tuning](https://datasciencebook.ca/classification2.html) chapter of the online textbook, which also lists the learning objectives for this worksheet. You should read the textbook chapter before attempting this worksheet. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "9bc543e9541519c9d3be5ead600a8e66",
     "grade": false,
     "grade_id": "cell-c1769cb5e6a8eb33",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "## Handwritten Digit Classification using R\n",
    "\n",
    "<img src=\"https://media.giphy.com/media/UwrdbvJz1CNck/giphy.gif\" width = \"600\"/>\n",
    "\n",
    "Source: https://media.giphy.com/media/UwrdbvJz1CNck/giphy.gif\n",
    "\n",
    "MNIST is a computer vision dataset that consists of images of handwritten digits like these:\n",
    "\n",
    "![](img/MNIST.png)\n",
    "\n",
    "It also includes labels for each image, telling us which digit it is. For example, the labels for the above images are 5, 0, 4, and 1.\n",
    "\n",
    "\n",
    "In this tutorial, we’re going to train a classifier to look at images and predict what digits they are. Our goal isn’t to train a really elaborate model that achieves state-of-the-art performance, but rather to dip a toe into using classification with pixelated images. As such, we’re going to keep working with the simple K-nearest neighbour classifier we have been exploring in the last two weeks.\n",
    "\n",
    "\n",
    "\n",
    "### Using image data for classification\n",
    "\n",
    "As mentioned earlier, every MNIST data point has two parts: an image of a handwritten digit and a corresponding label. Both the training set and test set contain images and their corresponding labels.\n",
    "\n",
    "Each image is 28 pixels by 28 pixels. We can interpret this as a big matrix of numbers:\n",
    "\n",
    "<img src=\"img/MNIST-Matrix.png\" width = \"500\"/>\n",
    "\n",
    "\n",
    "We can flatten this matrix into a vector of 28x28 = 784 numbers and give it a class label (here 1 for the number one). It doesn’t matter how we flatten the array, as long as we’re consistent between images. From this perspective, the MNIST images are just a bunch of points in a 784-dimensional vector space, with a very rich structure.\n",
    "\n",
    "<img src=\"img/matrix_to_row.png\" width = \"1000\"/>\n",
    "\n",
    "\n",
    "We do this for every image of the digits we have, and we create a data table like the one shown below that we can use for classification. Note, like any other classification problem that we have seen before, we need many observations for each class. This problem is also a bit different from the first classification problem we have encountered (Wisonsin breast cancer data set), in that we have more than two classes (here we have 10 classes, one for each digit from 0 to 9).\n",
    "\n",
    "<img src=\"img/data_table.png\" width = \"700\"/>\n",
    "\n",
    "This information is taken from: https://tensorflow.rstudio.com/tensorflow/articles/tutorial_mnist_beginners.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "f0c2aff5f54ed0ab826624b3a5cfe3a1",
     "grade": false,
     "grade_id": "cell-dca968079f2b9290",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "###\n",
    "### Run this cell before continuing.\n",
    "###\n",
    "\n",
    "library(repr)\n",
    "library(tidyverse)\n",
    "library(tidymodels)\n",
    "options(repr.matrix.max.rows = 10)\n",
    "source(\"cleanup.R\")\n",
    "\n",
    "# functions needed to work with images\n",
    "# code below sourced from: https://gist.github.com/daviddalpiaz/ae62ae5ccd0bada4b9acd6dbc9008706\n",
    "# helper function for visualization\n",
    "show_digit = function(arr784, col = gray(12:1 / 12), ...) {\n",
    "  arr784$X <- 0  # avoid dark pixel in top left\n",
    "  image(matrix(as.matrix(arr784[-785]), nrow = 28)[, 28:1], col = col, ...)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "87fee6a95d6c99faa7fab1869e43363a",
     "grade": false,
     "grade_id": "cell-35fb4efefa543a62",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "**Question 1.0** Multiple Choice:\n",
    "<br> {points: 1}\n",
    "\n",
    "How many rows and columns does the array of an image have?\n",
    "\n",
    "A. 784 columns and 1 row\n",
    "\n",
    "B. 28 columns and 1 row\n",
    "\n",
    "C. 18 columns and 18 rows\n",
    "\n",
    "D. 28 columns and 28 rows \n",
    "\n",
    "*Assign your answer to an object called `answer1.0`. Make sure the correct answer is an uppercase letter and to surround your answer with quotation marks (e.g. `\"F\"`).*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "da6ac286864840dd4bc529c2fa62b852",
     "grade": false,
     "grade_id": "cell-fd1b70ee04a1b142",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# Replace the fail() with your answer. \n",
    "\n",
    "# your code here\n",
    "fail() # No Answer - remove if you provide an answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "6dfe8016653ba02716dcbdc87bc4de4c",
     "grade": true,
     "grade_id": "cell-d3de0b488458b8ec",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "library(digest)\n",
    "stopifnot(\"type of answer1.0 is not character\"= setequal(digest(paste(toString(class(answer1.0)), \"a9994\")), \"abdb0a633d257ab6c513339f51f435e7\"))\n",
    "stopifnot(\"length of answer1.0 is not correct\"= setequal(digest(paste(toString(length(answer1.0)), \"a9994\")), \"9f10f62042bbe5dd3b65c9688fbe5726\"))\n",
    "stopifnot(\"value of answer1.0 is not correct\"= setequal(digest(paste(toString(tolower(answer1.0)), \"a9994\")), \"ac831492029fd6308eddea85090d78b1\"))\n",
    "stopifnot(\"letters in string value of answer1.0 are correct but case is not correct\"= setequal(digest(paste(toString(answer1.0), \"a9994\")), \"912d860d9c293946a61382c1912b85eb\"))\n",
    "\n",
    "print('Success!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "6fdd98a139dc5dfc590898e3b4a20516",
     "grade": false,
     "grade_id": "cell-311b84a1ac4cb261",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**Question 1.1** Multiple Choice: \n",
    "<br> {points: 1}\n",
    "\n",
    "Once we linearize the array, how many rows represent a number?\n",
    "\n",
    "A. 28\n",
    "\n",
    "B. 784\n",
    "\n",
    "C. 1\n",
    "\n",
    "D. 18\n",
    "\n",
    "*Assign your answer to an object called `answer1.1`. Make sure the correct answer is an uppercase letter and to surround your answer with quotation marks (e.g. `\"F\"`).*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "9976fbe7d9c4aac1d2f914cb161c9858",
     "grade": false,
     "grade_id": "cell-7df0a0a195a36b7b",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# Replace the fail() with your answer. \n",
    "\n",
    "# your code here\n",
    "fail() # No Answer - remove if you provide an answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "6d42715902957f7f8ca73f189eca2166",
     "grade": true,
     "grade_id": "cell-06400b9b6a219006",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "library(digest)\n",
    "stopifnot(\"type of answer1.1 is not character\"= setequal(digest(paste(toString(class(answer1.1)), \"bacc\")), \"d9c65aa0c2ae376af5c72f049e62e39d\"))\n",
    "stopifnot(\"length of answer1.1 is not correct\"= setequal(digest(paste(toString(length(answer1.1)), \"bacc\")), \"46db0350582115642d744df832d04308\"))\n",
    "stopifnot(\"value of answer1.1 is not correct\"= setequal(digest(paste(toString(tolower(answer1.1)), \"bacc\")), \"320a5c1751f93ac7c6f197b17299e9cc\"))\n",
    "stopifnot(\"letters in string value of answer1.1 are correct but case is not correct\"= setequal(digest(paste(toString(answer1.1), \"bacc\")), \"65dbcf5aa2b223588bc0c59961b86bdb\"))\n",
    "\n",
    "print('Success!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "0076ed677c6b622316eee110dde5239e",
     "grade": false,
     "grade_id": "cell-bc4a503b8cd8de26",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "## 2. Exploring the Data\n",
    "\n",
    "Before we move on to do the modeling component, it is always required that we take a look at our data and understand the problem and the structure of the data well. We can start this part by loading the images and taking a look at the first rows of the dataset. You can load the data set by running the cell below. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "c535f928097de7a0be570cd64eb27e0d",
     "grade": false,
     "grade_id": "cell-a9c8149f340b9a2b",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Load images. \n",
    "# Run this cell. \n",
    "training_data <- read_csv('data/mnist_train_small.csv')\n",
    "testing_data  <- read_csv('data/mnist_test_small.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "45a04f47c0b73e0095928c850286c264",
     "grade": false,
     "grade_id": "cell-5295dc267d5bafe5",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Look at the first 6 rows of `training_data`. What do you notice?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "47eab83ec71cbc5f24be9e97fa59992e",
     "grade": false,
     "grade_id": "cell-3acd9d89279d9fda",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "slice(training_data, 1:6)\n",
    "dim(training_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "e35bcb4090a4b44c575bbbd5e07b2ed9",
     "grade": false,
     "grade_id": "cell-0e9a59683551c8cb",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "There are no class labels! This data set has already been split into the X's (which you loaded above) and the labels. In addition, there is an extra \"X\" column which represents the row number (1, 2, 3...). **Keep this in mind for now because we will remove it later on.** Now, let's load the labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "cf3e63412891a6ffb4e151ecd8e8e8d4",
     "grade": false,
     "grade_id": "cell-3bc6f550562af1e1",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Run this cell. \n",
    "training_labels <- read_csv('data/mnist_train_label_small.csv')['y'] |> mutate(y = as_factor(y))\n",
    "testing_labels  <- read_csv('data/mnist_test_label_small.csv')['y'] |> mutate(y = as_factor(y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "34f4ae8de37bdc334b54d244b71cf333",
     "grade": false,
     "grade_id": "cell-b8faa08c9dbf227a",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Look at the first 6 labels of `training_labels` using the `slice(data_frame, 1:6)` function. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "92aeafd1d75fbc6bffe61df097b60b9d",
     "grade": false,
     "grade_id": "cell-47c684f9f540a5f0",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Run this cell.\n",
    "slice(training_labels, 1:6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "689c7fdc38825044bc867925d542bdef",
     "grade": false,
     "grade_id": "cell-121c48480262cb02",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "**Question 2.0**\n",
    "<br> {points: 1}\n",
    "\n",
    "How many rows does the training data set have? Use `nrow()`.\n",
    "\n",
    "*Assign your answer to an object called `number_of_rows`. Make sure your answer is a numeric and so it should not be surrounded by quotation marks.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "f337b75746af02a845235c281b78caee",
     "grade": false,
     "grade_id": "cell-94a5205f6bdfcef1",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# Replace the fail() with your answer. \n",
    "\n",
    "# your code here\n",
    "fail() # No Answer - remove if you provide an answer\n",
    "number_of_rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "65f34bd865026d971f64b977b30a8e22",
     "grade": true,
     "grade_id": "cell-0aef8bdec0794174",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "library(digest)\n",
    "stopifnot(\"type of number_of_rows is not integer\"= setequal(digest(paste(toString(class(number_of_rows)), \"263bd\")), \"1eff13c779d605e1c270828a8ab5cca1\"))\n",
    "stopifnot(\"length of number_of_rows is not correct\"= setequal(digest(paste(toString(length(number_of_rows)), \"263bd\")), \"107cb28bbaa2f60c73db1020b3291ded\"))\n",
    "stopifnot(\"values of number_of_rows are not correct\"= setequal(digest(paste(toString(sort(number_of_rows)), \"263bd\")), \"da228813b78e945409d93acc9e791f9e\"))\n",
    "\n",
    "print('Success!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "777c638cf95936a5fc13c622f711cb22",
     "grade": false,
     "grade_id": "cell-a33eec78947fd0d0",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "**Question 2.1**\n",
    "<br> {points: 1}\n",
    "\n",
    "For mutli-class classification with k-nn it is important for the classes to have about the same number of observations in each class. For example, if  90% of our training set observationas were labeled as 2's, then k-nn classification predict 2 almost every time and we would get an accuracy score of 90% even though our classifier wasn't really doing a great job. \n",
    "\n",
    "Use the `group_by` and `summarize` function to get the counts for each digit in the `training_labels` dataframe, and see if the data set is balanced across the classes (has roughly equal numbers of observation for each class). Name the output `counts`. `counts` should be a data frame with 2 columns, `y` and `count` (the column `count` should have the counts for how many observations there were for each class group)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "baaadae18c576856005db1a633343f6a",
     "grade": false,
     "grade_id": "cell-6324851b7968ef8d",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# Replace the fail() with your answer. \n",
    "\n",
    "# your code here\n",
    "fail() # No Answer - remove if you provide an answer\n",
    "counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "a5ffa3fcb418a59e1161f1fbcb3a43b5",
     "grade": true,
     "grade_id": "cell-dfc9ac244e23c2ce",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "library(digest)\n",
    "stopifnot(\"counts should be a data frame\"= setequal(digest(paste(toString('data.frame' %in% class(counts)), \"a835c\")), \"d7b64de956b2f4cbb4da9348db6a7133\"))\n",
    "stopifnot(\"dimensions of counts are not correct\"= setequal(digest(paste(toString(dim(counts)), \"a835c\")), \"9f07dac76c9bd4f62bf5ead2e4d3ba84\"))\n",
    "stopifnot(\"column names of counts are not correct\"= setequal(digest(paste(toString(sort(colnames(counts))), \"a835c\")), \"4e31d53e3e18dbecf7901693dc9f2e7f\"))\n",
    "stopifnot(\"types of columns in counts are not correct\"= setequal(digest(paste(toString(sort(unlist(sapply(counts, class)))), \"a835c\")), \"fa1f27ef318621653db18fbcd8461885\"))\n",
    "stopifnot(\"values in one or more numerical columns in counts are not correct\"= setequal(digest(paste(toString(if (any(sapply(counts, is.numeric))) sort(round(sapply(counts[, sapply(counts, is.numeric)], sum, na.rm = TRUE), 2)) else 0), \"a835c\")), \"64bf575458e4af08cbee66d06c164ee6\"))\n",
    "stopifnot(\"values in one or more character columns in counts are not correct\"= setequal(digest(paste(toString(if (any(sapply(counts, is.character))) sum(sapply(counts[sapply(counts, is.character)], function(x) length(unique(x)))) else 0), \"a835c\")), \"256a54bce3154a1353fde2f0e2a68c59\"))\n",
    "stopifnot(\"values in one or more factor columns in counts are not correct\"= setequal(digest(paste(toString(if (any(sapply(counts, is.factor))) sum(sapply(counts[, sapply(counts, is.factor)], function(col) length(unique(col)))) else 0), \"a835c\")), \"0dea4f085db27dfdd48539a479326eb5\"))\n",
    "\n",
    "print('Success!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "e98ce5118a1dd0e0012e8bcb45687f9d",
     "grade": false,
     "grade_id": "cell-e00159c5a7b64c0c",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "**Question 2.2** True or False:\n",
    "<br> {points: 1}\n",
    "\n",
    "The classes are roughly balanced. Some of them are just a bit larger or smaller than others. \n",
    "\n",
    "*Assign your answer to an object called `answer2.2`. Make sure your answer is in lowercase and is surrounded by quotation marks (e.g. `\"true\"` or `\"false\"`)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "0d4c6903c4dfbbd818cceb0a54d3e103",
     "grade": false,
     "grade_id": "cell-1752726ae2dba8d8",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Replace the fail() with your answer. \n",
    "\n",
    "# your code here\n",
    "fail() # No Answer - remove if you provide an answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "00b5387fb7b8b6dd902af1f6e6dbdf29",
     "grade": true,
     "grade_id": "cell-bef5286ad6fd2de7",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "library(digest)\n",
    "stopifnot(\"type of answer2.2 is not character\"= setequal(digest(paste(toString(class(answer2.2)), \"6f24c\")), \"0d2245845029bf5a226d6f50756a368d\"))\n",
    "stopifnot(\"length of answer2.2 is not correct\"= setequal(digest(paste(toString(length(answer2.2)), \"6f24c\")), \"b9ca111973f00e4e5746ee05916fd160\"))\n",
    "stopifnot(\"value of answer2.2 is not correct\"= setequal(digest(paste(toString(tolower(answer2.2)), \"6f24c\")), \"5604ee8807f216487ac950dd7dbeefc5\"))\n",
    "stopifnot(\"letters in string value of answer2.2 are correct but case is not correct\"= setequal(digest(paste(toString(answer2.2), \"6f24c\")), \"5604ee8807f216487ac950dd7dbeefc5\"))\n",
    "\n",
    "print('Success!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "9c797c8a20a6b30cf1999e29b38a5f5e",
     "grade": false,
     "grade_id": "cell-b8764501218e8fe2",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "To view an image in the notebook, you can use the `show_digit` function (we gave you the code for this function in the first code cell in the notebook, All you have to do to use it is run the cell below). The `show_digit` function takes the row from the dataset whose image you want to produce, which you can obtain using the `slice` function.\n",
    "\n",
    "The code we provide below will show you the image for the observation in the 200th row from the training data set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "b5c0ba4753d53c5c33a487c19e634ed8",
     "grade": false,
     "grade_id": "cell-ea620b7dc18dbef2",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Run this cell to get the images for the 200th row from the training data set.\n",
    "options(repr.plot.height = 5, repr.plot.width = 5)\n",
    "show_digit(slice(training_data, 200))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "41fa187c046baa731025680c675d8475",
     "grade": false,
     "grade_id": "cell-c160b79336eed6fd",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "**Question 2.3** \n",
    "<br> {points: 3}\n",
    "\n",
    "Show the image for row 102."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "132909fdd5a62d9574bfa32271fef1bf",
     "grade": true,
     "grade_id": "cell-0ec57ff5f0b7ed54",
     "locked": false,
     "points": 3,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "options(repr.plot.height = 5, repr.plot.width = 5)\n",
    "\n",
    "# Replace the fail() with your answer. \n",
    "\n",
    "# your code here\n",
    "fail() # No Answer - remove if you provide an answer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "a63d2c865c9baa57a96732f62f863c84",
     "grade": false,
     "grade_id": "cell-e3eb39a070c23ebe",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "If you are unsure as to what number the plot is depicting (because the handwriting is messy) you can use `slice` to get the label from the `training_labels`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "148961b57b0b5773c98f550ac981687f",
     "grade": false,
     "grade_id": "cell-ac471075633c9d1a",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# run this cell to get the training label for the 200th row\n",
    "training_labels |> \n",
    "    slice(200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "39402905d3fe5bfcc333494a3ecb29d4",
     "grade": false,
     "grade_id": "cell-289e866b3e6e697f",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "**Question 2.4** \n",
    "<br> {points: 1}\n",
    "\n",
    "What is the class label for row 102? Your answer should be a data frame with one column (named `y`) and one row.\n",
    "\n",
    "*Assign your answer to an object called `label_102`.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "3b53f576b8ee0faa5cc5d71c887d570f",
     "grade": false,
     "grade_id": "cell-2fa1179a92f569ee",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# Replace the fail() with your answer. \n",
    "\n",
    "# your code here\n",
    "fail() # No Answer - remove if you provide an answer\n",
    "label_102"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "3f317fc4d465df4aac0ccb39fbf1a1be",
     "grade": true,
     "grade_id": "cell-287f89fa967e941a",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "library(digest)\n",
    "stopifnot(\"label_102 should be a data frame\"= setequal(digest(paste(toString('data.frame' %in% class(label_102)), \"ce07\")), \"911b902d2c8f9cfee1519f8a2a483ed3\"))\n",
    "stopifnot(\"dimensions of label_102 are not correct\"= setequal(digest(paste(toString(dim(label_102)), \"ce07\")), \"3587d0888aeebad9afc1e26129af5b86\"))\n",
    "stopifnot(\"column names of label_102 are not correct\"= setequal(digest(paste(toString(sort(colnames(label_102))), \"ce07\")), \"5854a700c6c8dad347a661ef73941491\"))\n",
    "stopifnot(\"types of columns in label_102 are not correct\"= setequal(digest(paste(toString(sort(unlist(sapply(label_102, class)))), \"ce07\")), \"cc665119c8b6e3895dad4ee9f4a3ac9d\"))\n",
    "stopifnot(\"values in one or more numerical columns in label_102 are not correct\"= setequal(digest(paste(toString(if (any(sapply(label_102, is.numeric))) sort(round(sapply(label_102[, sapply(label_102, is.numeric)], sum, na.rm = TRUE), 2)) else 0), \"ce07\")), \"b7873983a0a6153711b08fc7aab8aaff\"))\n",
    "stopifnot(\"values in one or more character columns in label_102 are not correct\"= setequal(digest(paste(toString(if (any(sapply(label_102, is.character))) sum(sapply(label_102[sapply(label_102, is.character)], function(x) length(unique(x)))) else 0), \"ce07\")), \"b7873983a0a6153711b08fc7aab8aaff\"))\n",
    "stopifnot(\"values in one or more factor columns in label_102 are not correct\"= setequal(digest(paste(toString(if (any(sapply(label_102, is.factor))) sum(sapply(label_102[, sapply(label_102, is.factor)], function(col) length(unique(col)))) else 0), \"ce07\")), \"aba2eb9472e33dda4c2ab73b160d6d43\"))\n",
    "\n",
    "print('Success!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "c13abf39abf5c0fda468cb0e37cef8e9",
     "grade": false,
     "grade_id": "cell-eeb98658f3a9e923",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "## 3. Splitting the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "49e754ea8bcf2bb606c3a6add3e3601a",
     "grade": false,
     "grade_id": "cell-8e7319af6b9403ea",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "**Question 3.0**\n",
    "<br> {points: 1}\n",
    "\n",
    "Currently, the image data and labels are split. The `tidymodels` package needs the image data and labels to be combined together in one data frame. Given that the image data and labels are in the same order, we can use the `bind_cols` function to combine them. Name the training image data with its respective labels `training_set` and name the testing image data with its respective labels `testing_set`. \n",
    "\n",
    "> Note: even though the entire data set has been split for you already into a training and a test set, don't forget to do this in the future for other data sets where this is not the case. Remember, you need to have a training and testing data set when designing a useful k-nn classification model. \n",
    "\n",
    "Also, remember in Section 2 that we told you to keep something in mind? To remind you, there is an extra \"X\" column on the far left which represents the row numbers (1, 2, 3, etc.) in the `training_set`. **This column should not be used for training.** Therefore, let's remove this column from the data set. \n",
    "\n",
    "*Hint: You can remove columns in a dataset using the `select` function and by putting a negative sign infront of the column you want to exclude (e.g. `-X`)*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "75583e32f93c1fceb227f41c5e419fdb",
     "grade": false,
     "grade_id": "cell-7ed04d8612d530f4",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Set the seed. Don't remove this!\n",
    "set.seed(9999) \n",
    "\n",
    "#... <- bind_cols(..., ...) |> # for the training data\n",
    "#        select(...)\n",
    "\n",
    "#... <- bind_cols(..., ...) # for the testing data\n",
    "\n",
    "\n",
    "# your code here\n",
    "fail() # No Answer - remove if you provide an answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "5ad61fdbc44140df89de1337120382c1",
     "grade": true,
     "grade_id": "cell-930d3ef15a5b523d",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "library(digest)\n",
    "stopifnot(\"training_set should be a data frame\"= setequal(digest(paste(toString('data.frame' %in% class(training_set)), \"77352\")), \"30b40780d79e09d070d47c85c06f4ae3\"))\n",
    "stopifnot(\"dimensions of training_set are not correct\"= setequal(digest(paste(toString(dim(training_set)), \"77352\")), \"9b28bb00adebd170dc4fe9ff2eccc75f\"))\n",
    "stopifnot(\"column names of training_set are not correct\"= setequal(digest(paste(toString(sort(colnames(training_set))), \"77352\")), \"31fc57c51beafde22f14bb2113a41587\"))\n",
    "stopifnot(\"types of columns in training_set are not correct\"= setequal(digest(paste(toString(sort(unlist(sapply(training_set, class)))), \"77352\")), \"6b244da539faa3772b7b3bbcdca06e8a\"))\n",
    "stopifnot(\"values in one or more numerical columns in training_set are not correct\"= setequal(digest(paste(toString(if (any(sapply(training_set, is.numeric))) sort(round(sapply(training_set[, sapply(training_set, is.numeric)], sum, na.rm = TRUE), 2)) else 0), \"77352\")), \"47ef444f9815f67421ac9f07e64e09bc\"))\n",
    "stopifnot(\"values in one or more character columns in training_set are not correct\"= setequal(digest(paste(toString(if (any(sapply(training_set, is.character))) sum(sapply(training_set[sapply(training_set, is.character)], function(x) length(unique(x)))) else 0), \"77352\")), \"a7cbc433e52889504facf08516462951\"))\n",
    "stopifnot(\"values in one or more factor columns in training_set are not correct\"= setequal(digest(paste(toString(if (any(sapply(training_set, is.factor))) sum(sapply(training_set[, sapply(training_set, is.factor)], function(col) length(unique(col)))) else 0), \"77352\")), \"651384436c2713f10472a0b33ea752b1\"))\n",
    "\n",
    "stopifnot(\"testing_set should be a data frame\"= setequal(digest(paste(toString('data.frame' %in% class(testing_set)), \"77353\")), \"b587f781074400970da0a1b9a9e4133c\"))\n",
    "stopifnot(\"dimensions of testing_set are not correct\"= setequal(digest(paste(toString(dim(testing_set)), \"77353\")), \"f14a7428e410f254212646117dbe5a80\"))\n",
    "stopifnot(\"column names of testing_set are not correct\"= setequal(digest(paste(toString(sort(colnames(testing_set))), \"77353\")), \"aba660b72056bb8654db4a3b29275841\"))\n",
    "stopifnot(\"types of columns in testing_set are not correct\"= setequal(digest(paste(toString(sort(unlist(sapply(testing_set, class)))), \"77353\")), \"5b3b64785ba7250ea65961a8c6564343\"))\n",
    "stopifnot(\"values in one or more numerical columns in testing_set are not correct\"= setequal(digest(paste(toString(if (any(sapply(testing_set, is.numeric))) sort(round(sapply(testing_set[, sapply(testing_set, is.numeric)], sum, na.rm = TRUE), 2)) else 0), \"77353\")), \"8d262003560342ca2a105fbffd558a15\"))\n",
    "stopifnot(\"values in one or more character columns in testing_set are not correct\"= setequal(digest(paste(toString(if (any(sapply(testing_set, is.character))) sum(sapply(testing_set[sapply(testing_set, is.character)], function(x) length(unique(x)))) else 0), \"77353\")), \"55f79afcd10741cfa7a63d81d6b662eb\"))\n",
    "stopifnot(\"values in one or more factor columns in testing_set are not correct\"= setequal(digest(paste(toString(if (any(sapply(testing_set, is.factor))) sum(sapply(testing_set[, sapply(testing_set, is.factor)], function(col) length(unique(col)))) else 0), \"77353\")), \"3e3d9627ed585640d864d74ceb586574\"))\n",
    "\n",
    "print('Success!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "7041023873d68390a18d9d919011503b",
     "grade": false,
     "grade_id": "cell-df4772461e83d1c9",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "**Question 3.1**\n",
    "<br> {points: 3}\n",
    "\n",
    "We have already split the data into two datasets, one for training purposes and one for testing purposes. **Is it important to split the data into a training and testing dataset when designing a knn classification model?** If yes, why do we do this? If no, explain why this is not a good idea."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "bb5f87ba5750a590bf5c6231ec8215aa",
     "grade": true,
     "grade_id": "cell-887389384414f1c1",
     "locked": false,
     "points": 3,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "DOUBLE CLICK TO EDIT **THIS CELL** AND REPLACE THIS TEXT WITH YOUR ANSWER."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "6dda57b8a79aeb3d3302a057a6487756",
     "grade": false,
     "grade_id": "cell-22cc98b4c3ed05b5",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "## Which $k$ should we use?\n",
    "\n",
    "As you learned from the worksheet, we can use cross-validation on the training data set to select which $k$ is the most optimal for our data set for k-nn classification. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "9a6d003896424e4f397798b5cb446f67",
     "grade": false,
     "grade_id": "cell-a19c883460a4f6f7",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "**Question 3.2**\n",
    "<br> {points: 1}\n",
    "\n",
    "To get all the marks in this question, you will have to:\n",
    "- Create a recipe that uses all predictors and a model specification with tuning on the number of neighbours (**Note: You don't need to scale or center this data**)\n",
    "- Perform a 5-fold cross-validation on the training set\n",
    "- Create a workflow analysis with your recipe and model specification. Try **k = 2, 3, 4, 5, and 6**.\n",
    "    - (we would normally try more values of $k$ across a wider range; but this process puts a lot of load on our course server, so we keep it limited here.)\n",
    "- Collect the metrics from the workflow analysis \n",
    "- Plot the accuracy vs $k$\n",
    "    - Assign this plot to an object called `cross_val_plot`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "7d1450aae96004115130e830887a3d60",
     "grade": false,
     "grade_id": "cell-b202e81559613b62",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Set the seed. Don't remove this!\n",
    "set.seed(1234) \n",
    "\n",
    "options(repr.plot.height = 5, repr.plot.width = 6)\n",
    "\n",
    "# your code here\n",
    "fail() # No Answer - remove if you provide an answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "99585b74cb6b89d5d915c21d1b9fb896",
     "grade": true,
     "grade_id": "cell-a555ad05c7d7fdcb",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "library(digest)\n",
    "stopifnot(\"type of plot is not correct (if you are using two types of geoms, try flipping the order of the geom objects!)\"= setequal(digest(paste(toString(sapply(seq_len(length(cross_val_plot$layers)), function(i) {c(class(cross_val_plot$layers[[i]]$geom))[1]})), \"9b32a\")), \"d22ff5676ca324395ce650f5620ab149\"))\n",
    "stopifnot(\"variable x is not correct\"= setequal(digest(paste(toString(unlist(lapply(sapply(seq_len(length(cross_val_plot$layers)), function(i) {rlang::get_expr(c(cross_val_plot$layers[[i]]$mapping, cross_val_plot$mapping)$x)}), as.character))), \"9b32a\")), \"4cf56bde0cd6ea12f8fd41ac6b9c8b3f\"))\n",
    "stopifnot(\"variable y is not correct\"= setequal(digest(paste(toString(unlist(lapply(sapply(seq_len(length(cross_val_plot$layers)), function(i) {rlang::get_expr(c(cross_val_plot$layers[[i]]$mapping, cross_val_plot$mapping)$y)}), as.character))), \"9b32a\")), \"13e4dc62f4af142f3f55968b58b2a3b2\"))\n",
    "stopifnot(\"x-axis label is not descriptive, nicely formatted, or human readable\"= setequal(digest(paste(toString(rlang::get_expr(c(cross_val_plot$layers[[1]]$mapping, cross_val_plot$mapping)$x)!= cross_val_plot$labels$x), \"9b32a\")), \"23da1c642256d5ed7db32bb1bf170ad6\"))\n",
    "stopifnot(\"y-axis label is not descriptive, nicely formatted, or human readable\"= setequal(digest(paste(toString(rlang::get_expr(c(cross_val_plot$layers[[1]]$mapping, cross_val_plot$mapping)$y)!= cross_val_plot$labels$y), \"9b32a\")), \"23da1c642256d5ed7db32bb1bf170ad6\"))\n",
    "stopifnot(\"incorrect colour variable in cross_val_plot, specify a correct one if required\"= setequal(digest(paste(toString(rlang::get_expr(c(cross_val_plot$layers[[1]]$mapping, cross_val_plot$mapping)$colour)), \"9b32a\")), \"f70d134338fb3cdf2c3347b810481e28\"))\n",
    "stopifnot(\"incorrect shape variable in cross_val_plot, specify a correct one if required\"= setequal(digest(paste(toString(rlang::get_expr(c(cross_val_plot$layers[[1]]$mapping, cross_val_plot$mapping)$shape)), \"9b32a\")), \"f70d134338fb3cdf2c3347b810481e28\"))\n",
    "stopifnot(\"the colour label in cross_val_plot is not descriptive, nicely formatted, or human readable\"= setequal(digest(paste(toString(rlang::get_expr(c(cross_val_plot$layers[[1]]$mapping, cross_val_plot$mapping)$colour) != cross_val_plot$labels$colour), \"9b32a\")), \"f70d134338fb3cdf2c3347b810481e28\"))\n",
    "stopifnot(\"the shape label in cross_val_plot is not descriptive, nicely formatted, or human readable\"= setequal(digest(paste(toString(rlang::get_expr(c(cross_val_plot$layers[[1]]$mapping, cross_val_plot$mapping)$colour) != cross_val_plot$labels$shape), \"9b32a\")), \"f70d134338fb3cdf2c3347b810481e28\"))\n",
    "stopifnot(\"fill variable in cross_val_plot is not correct\"= setequal(digest(paste(toString(quo_name(cross_val_plot$mapping$fill)), \"9b32a\")), \"94924d09c0cbff53dab6a696d5c26dae\"))\n",
    "stopifnot(\"fill label in cross_val_plot is not informative\"= setequal(digest(paste(toString((quo_name(cross_val_plot$mapping$fill) != cross_val_plot$labels$fill)), \"9b32a\")), \"f70d134338fb3cdf2c3347b810481e28\"))\n",
    "stopifnot(\"position argument in cross_val_plot is not correct\"= setequal(digest(paste(toString(class(cross_val_plot$layers[[1]]$position)[1]), \"9b32a\")), \"8ec700b9c9dec7bef2f9e03606e8743d\"))\n",
    "\n",
    "stopifnot(\"cross_val_plot$data should be a data frame\"= setequal(digest(paste(toString('data.frame' %in% class(cross_val_plot$data)), \"9b32b\")), \"a09632b2ab435c7952310194ccbae915\"))\n",
    "stopifnot(\"dimensions of cross_val_plot$data are not correct\"= setequal(digest(paste(toString(dim(cross_val_plot$data)), \"9b32b\")), \"6e6da220566f92527219af96f4d8e906\"))\n",
    "stopifnot(\"column names of cross_val_plot$data are not correct\"= setequal(digest(paste(toString(sort(colnames(cross_val_plot$data))), \"9b32b\")), \"61f65a150e0a5287821ba043238f219d\"))\n",
    "stopifnot(\"types of columns in cross_val_plot$data are not correct\"= setequal(digest(paste(toString(sort(unlist(sapply(cross_val_plot$data, class)))), \"9b32b\")), \"bdc2234b2063fb403ff39757d90f40e1\"))\n",
    "stopifnot(\"values in one or more numerical columns in cross_val_plot$data are not correct\"= setequal(digest(paste(toString(if (any(sapply(cross_val_plot$data, is.numeric))) sort(round(sapply(cross_val_plot$data[, sapply(cross_val_plot$data, is.numeric)], sum, na.rm = TRUE), 2)) else 0), \"9b32b\")), \"a770e4ac42c923c7929b8b805241d453\"))\n",
    "stopifnot(\"values in one or more character columns in cross_val_plot$data are not correct\"= setequal(digest(paste(toString(if (any(sapply(cross_val_plot$data, is.character))) sum(sapply(cross_val_plot$data[sapply(cross_val_plot$data, is.character)], function(x) length(unique(x)))) else 0), \"9b32b\")), \"ea8a23b492232e9dde6fcb85a7f7e07e\"))\n",
    "stopifnot(\"values in one or more factor columns in cross_val_plot$data are not correct\"= setequal(digest(paste(toString(if (any(sapply(cross_val_plot$data, is.factor))) sum(sapply(cross_val_plot$data[, sapply(cross_val_plot$data, is.factor)], function(col) length(unique(col)))) else 0), \"9b32b\")), \"bb5a3af09212cd278b1f2cee9eb519d3\"))\n",
    "\n",
    "print('Success!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "db7779499465ec50f3c16d31951ab919",
     "grade": false,
     "grade_id": "cell-fc3c04fd7f0d5d5f",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**Question 3.3**\n",
    "<br> {points: 3}\n",
    "\n",
    "Based on the plot from **Question 3.2**, which $k$ would you choose and how can you be sure about your decision? In your answer you should reference why we do cross-validation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "84ee2229d39d8c31738e259e055bfe63",
     "grade": true,
     "grade_id": "cell-60e47e1dc46c55d0",
     "locked": false,
     "points": 3,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "DOUBLE CLICK TO EDIT **THIS CELL** AND REPLACE THIS TEXT WITH YOUR ANSWER."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "6188b12dbff09bb85e3bdbe947107f46",
     "grade": false,
     "grade_id": "cell-d8a437411c4d4e44",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "## 4. Let's build our model\n",
    "\n",
    "**Question 4.0**\n",
    "<br> {points: 3}\n",
    "\n",
    "Now that we have explored our data, separated the data into training and testing sets (was technically done for you), and applied cross-validation to choose the best $k$, we can build our final model.\n",
    "\n",
    "First, build your model specification with the best value for $K$. Assign your answer to an object called `mnist_spec`.\n",
    "\n",
    "Then, pass the model specification and the training data set to the `fit()` function. Assign your answer to an object called `mnist_fit`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "02c5e485d875e69cd415798968daaa8b",
     "grade": false,
     "grade_id": "cell-ef0258111eeb88ed",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Set the seed. Don't remove this!\n",
    "set.seed(9999) \n",
    "\n",
    "# your code here\n",
    "fail() # No Answer - remove if you provide an answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "b1c58391d032d9a544747b12db8332f1",
     "grade": true,
     "grade_id": "cell-e599a16a81e3003a",
     "locked": true,
     "points": 3,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "library(digest)\n",
    "stopifnot(\"type of exists('mnist_spec') is not logical\"= setequal(digest(paste(toString(class(exists('mnist_spec'))), \"97bc5\")), \"0aedca3df678c2c21765cd93a2649fd8\"))\n",
    "stopifnot(\"logical value of exists('mnist_spec') is not correct\"= setequal(digest(paste(toString(exists('mnist_spec')), \"97bc5\")), \"25e913218b337968eff03c38ab3e81e2\"))\n",
    "\n",
    "stopifnot(\"type of exists('mnist_fit') is not logical\"= setequal(digest(paste(toString(class(exists('mnist_fit'))), \"97bc6\")), \"ada858e60261df100a2b7dd2c3edf20b\"))\n",
    "stopifnot(\"logical value of exists('mnist_fit') is not correct\"= setequal(digest(paste(toString(exists('mnist_fit')), \"97bc6\")), \"61a634ce64ed512d1b17eb5d129d6c91\"))\n",
    "\n",
    "# The rest of the tests are intentionally hidden so that you can practice deciding \n",
    "# when you have found the correct answer. \n",
    "print('Success!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "f69a9071bb3517c94338a9d83cf78e0e",
     "grade": false,
     "grade_id": "cell-097f339e6f489355",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "**Question 4.1**\n",
    "<br> {points: 1}\n",
    "\n",
    "Use your final model to predict on the test dataset and assign this to an object called `mnist_predictions`. Report the accuracy of this prediction, and store this in an object named `mnist_metrics`. Also report the confusion matrix and and store this in an object named `mnist_conf_mat`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "cd14739d62e584293db324bb00599de9",
     "grade": false,
     "grade_id": "cell-0e192eaef00a5d98",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Set the seed. Don't remove this!\n",
    "set.seed(9999) \n",
    "\n",
    "# your code here\n",
    "fail() # No Answer - remove if you provide an answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "1ffeaaa75ddd99bda5e51ed236cd7342",
     "grade": true,
     "grade_id": "cell-5690538e24ee5653",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "library(digest)\n",
    "stopifnot(\"mnist_predictions should be a data frame\"= setequal(digest(paste(toString('data.frame' %in% class(mnist_predictions)), \"a9977\")), \"6c19676b2d3df220d30738ac49381cec\"))\n",
    "stopifnot(\"dimensions of mnist_predictions are not correct\"= setequal(digest(paste(toString(dim(mnist_predictions)), \"a9977\")), \"7bf8bf186516e28f0b225b359c4f4c7c\"))\n",
    "stopifnot(\"column names of mnist_predictions are not correct\"= setequal(digest(paste(toString(sort(colnames(mnist_predictions))), \"a9977\")), \"d847b82f88aa0094627cc662fe08b9ac\"))\n",
    "stopifnot(\"types of columns in mnist_predictions are not correct\"= setequal(digest(paste(toString(sort(unlist(sapply(mnist_predictions, class)))), \"a9977\")), \"62c195694d4eb2893544157cb1729854\"))\n",
    "stopifnot(\"values in one or more numerical columns in mnist_predictions are not correct\"= setequal(digest(paste(toString(if (any(sapply(mnist_predictions, is.numeric))) sort(round(sapply(mnist_predictions[, sapply(mnist_predictions, is.numeric)], sum, na.rm = TRUE), 2)) else 0), \"a9977\")), \"c5dda8aa3db9570f5e5f81db2f6dfd2f\"))\n",
    "stopifnot(\"values in one or more character columns in mnist_predictions are not correct\"= setequal(digest(paste(toString(if (any(sapply(mnist_predictions, is.character))) sum(sapply(mnist_predictions[sapply(mnist_predictions, is.character)], function(x) length(unique(x)))) else 0), \"a9977\")), \"0055527ef7bdee9e13ee0b1c5986623d\"))\n",
    "stopifnot(\"values in one or more factor columns in mnist_predictions are not correct\"= setequal(digest(paste(toString(if (any(sapply(mnist_predictions, is.factor))) sum(sapply(mnist_predictions[, sapply(mnist_predictions, is.factor)], function(col) length(unique(col)))) else 0), \"a9977\")), \"24304d3256d0c0fca305625d7415f55b\"))\n",
    "\n",
    "stopifnot(\"type of class(mnist_conf_mat) is not character\"= setequal(digest(paste(toString(class(class(mnist_conf_mat))), \"a9978\")), \"7f3aca9784c29b3a63a3271bf0803598\"))\n",
    "stopifnot(\"length of class(mnist_conf_mat) is not correct\"= setequal(digest(paste(toString(length(class(mnist_conf_mat))), \"a9978\")), \"9d4bca7570d784357a8b383a363dfe30\"))\n",
    "stopifnot(\"value of class(mnist_conf_mat) is not correct\"= setequal(digest(paste(toString(tolower(class(mnist_conf_mat))), \"a9978\")), \"b1209ad3b28f8c99c0a7a36807ac2484\"))\n",
    "stopifnot(\"letters in string value of class(mnist_conf_mat) are correct but case is not correct\"= setequal(digest(paste(toString(class(mnist_conf_mat)), \"a9978\")), \"b1209ad3b28f8c99c0a7a36807ac2484\"))\n",
    "\n",
    "stopifnot(\"as.data.frame.matrix(mnist_conf_mat$table) should be a data frame\"= setequal(digest(paste(toString('data.frame' %in% class(as.data.frame.matrix(mnist_conf_mat$table))), \"a9979\")), \"75b8b30e2dc1eaeae9a58c7ae894f24f\"))\n",
    "stopifnot(\"dimensions of as.data.frame.matrix(mnist_conf_mat$table) are not correct\"= setequal(digest(paste(toString(dim(as.data.frame.matrix(mnist_conf_mat$table))), \"a9979\")), \"d9c657dc4ca0e62e93f7b9e152617051\"))\n",
    "stopifnot(\"column names of as.data.frame.matrix(mnist_conf_mat$table) are not correct\"= setequal(digest(paste(toString(sort(colnames(as.data.frame.matrix(mnist_conf_mat$table)))), \"a9979\")), \"514346f8b4c48cbc7c4715265653a299\"))\n",
    "stopifnot(\"types of columns in as.data.frame.matrix(mnist_conf_mat$table) are not correct\"= setequal(digest(paste(toString(sort(unlist(sapply(as.data.frame.matrix(mnist_conf_mat$table), class)))), \"a9979\")), \"fc01c63a8d0af56621ab14fc191f5b35\"))\n",
    "stopifnot(\"values in one or more numerical columns in as.data.frame.matrix(mnist_conf_mat$table) are not correct\"= setequal(digest(paste(toString(if (any(sapply(as.data.frame.matrix(mnist_conf_mat$table), is.numeric))) sort(round(sapply(as.data.frame.matrix(mnist_conf_mat$table)[, sapply(as.data.frame.matrix(mnist_conf_mat$table), is.numeric)], sum, na.rm = TRUE), 2)) else 0), \"a9979\")), \"7a3c042eaa6bc7c00dab93273c8c6fa8\"))\n",
    "stopifnot(\"values in one or more character columns in as.data.frame.matrix(mnist_conf_mat$table) are not correct\"= setequal(digest(paste(toString(if (any(sapply(as.data.frame.matrix(mnist_conf_mat$table), is.character))) sum(sapply(as.data.frame.matrix(mnist_conf_mat$table)[sapply(as.data.frame.matrix(mnist_conf_mat$table), is.character)], function(x) length(unique(x)))) else 0), \"a9979\")), \"31a33fb137ebae74ab0ece216e468928\"))\n",
    "stopifnot(\"values in one or more factor columns in as.data.frame.matrix(mnist_conf_mat$table) are not correct\"= setequal(digest(paste(toString(if (any(sapply(as.data.frame.matrix(mnist_conf_mat$table), is.factor))) sum(sapply(as.data.frame.matrix(mnist_conf_mat$table)[, sapply(as.data.frame.matrix(mnist_conf_mat$table), is.factor)], function(col) length(unique(col)))) else 0), \"a9979\")), \"31a33fb137ebae74ab0ece216e468928\"))\n",
    "\n",
    "stopifnot(\"type of 'data.frame' %in% class(mnist_metrics) is not logical\"= setequal(digest(paste(toString(class('data.frame' %in% class(mnist_metrics))), \"a997a\")), \"f10a792cc5d364bbd2cb82d1881ab97f\"))\n",
    "stopifnot(\"logical value of 'data.frame' %in% class(mnist_metrics) is not correct\"= setequal(digest(paste(toString('data.frame' %in% class(mnist_metrics)), \"a997a\")), \"b15a095232e23ab5b78e4d78d1c4c47b\"))\n",
    "\n",
    "stopifnot(\"type of sort(colnames(mnist_metrics)) is not character\"= setequal(digest(paste(toString(class(sort(colnames(mnist_metrics)))), \"a997b\")), \"2dadebab0aa38cc8e2438599c51d5a06\"))\n",
    "stopifnot(\"length of sort(colnames(mnist_metrics)) is not correct\"= setequal(digest(paste(toString(length(sort(colnames(mnist_metrics)))), \"a997b\")), \"917cde4182c4f7ad1b1fc130b6f8eccf\"))\n",
    "stopifnot(\"value of sort(colnames(mnist_metrics)) is not correct\"= setequal(digest(paste(toString(tolower(sort(colnames(mnist_metrics)))), \"a997b\")), \"1883f630963d366d06858f591449f704\"))\n",
    "stopifnot(\"letters in string value of sort(colnames(mnist_metrics)) are correct but case is not correct\"= setequal(digest(paste(toString(sort(colnames(mnist_metrics))), \"a997b\")), \"1883f630963d366d06858f591449f704\"))\n",
    "\n",
    "stopifnot(\"type of round(mnist_metrics |> filter(.metric == \\\"accuracy\\\") |> pull(.estimate), 2) is not numeric\"= setequal(digest(paste(toString(class(round(mnist_metrics |> filter(.metric == \"accuracy\") |> pull(.estimate), 2))), \"a997c\")), \"ee6de8229c3c6eeace47974a93e22cd5\"))\n",
    "stopifnot(\"value of round(mnist_metrics |> filter(.metric == \\\"accuracy\\\") |> pull(.estimate), 2) is not correct (rounded to 2 decimal places)\"= setequal(digest(paste(toString(round(round(mnist_metrics |> filter(.metric == \"accuracy\") |> pull(.estimate), 2), 2)), \"a997c\")), \"cecac775121c28641b783d4867dfe634\"))\n",
    "stopifnot(\"length of round(mnist_metrics |> filter(.metric == \\\"accuracy\\\") |> pull(.estimate), 2) is not correct\"= setequal(digest(paste(toString(length(round(mnist_metrics |> filter(.metric == \"accuracy\") |> pull(.estimate), 2))), \"a997c\")), \"7dd2597a1723e5020bfd5afd73317f41\"))\n",
    "stopifnot(\"values of round(mnist_metrics |> filter(.metric == \\\"accuracy\\\") |> pull(.estimate), 2) are not correct\"= setequal(digest(paste(toString(sort(round(round(mnist_metrics |> filter(.metric == \"accuracy\") |> pull(.estimate), 2), 2))), \"a997c\")), \"cecac775121c28641b783d4867dfe634\"))\n",
    "\n",
    "print('Success!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "82b006b35e4e44264896c95aec66d7a6",
     "grade": false,
     "grade_id": "cell-6909f8d2f907b5ab",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "**Question 4.2**\n",
    "<br> {points: 3}\n",
    "\n",
    "For this exercise, print out 3 images and the true labels from the test set that were predicted correctly. \n",
    "\n",
    "To approach this exercise, we will first create a data frame that contains the predictions, and the labels from the testing set. We will want to use this data to find cases where the hand written digits were predicted correctly (i.e., any rows where the values in the predicted class label column, `.pred_class`, match the test set labels, `y`). We will then want to use this information to go back to the original data and extract images that correspond to these correct predictions. \n",
    "\n",
    "To keep track of which rows correspond to which images, we will use `mutate` to add a column called `seq`. This will order the rows, from 1 to $n$ (where $n$ is the number of images in the test set), and be useful to keep track of which rows correspond to which images when we do something to the data frame, for example, filter it to find correctly predicted labels. Scaffolding has been provided below for you. Assign your answer to an object called `mnist_predictions_with_labels`. Make sure this object has only three columns `.pred_class`, `y`, and `seq` \n",
    "\n",
    "From this data frame, filter for cases of equality between the predictions, `.pred_class`, and testing set labels, `y`. Essentially, you want to find cases where the predictions match the testing set labels. Sample 3 rows of data using `slice_sample`. Assign your answer to an object called `matching`. \n",
    "\n",
    "Next, we want to extract the row numbers (`seq`) from the `matching` data frame to input them into the `show_digit` function. The scaffolding to extract the data from the first row and the associated row number is provided below. Assign your answers respectively to `matching_1`, `matching_2`, and `matching_3`. \n",
    "\n",
    "*Use `show_digit` to visualize the digits indexed by `matching_1`, `matching_2`, and `matching_3` to see what they look like!*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "8253907b96a7ed984078784f68427f2e",
     "grade": false,
     "grade_id": "cell-0e9c5f1971016180",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Set the seed. Don't remove this!\n",
    "set.seed(1000) \n",
    "\n",
    "#... <- mnist_predictions |>\n",
    "#       select(...) |>\n",
    "#       bind_cols(testing_set |> select(...)) |>\n",
    "#       mutate(... = 1:nrow(...)) |>\n",
    "#       as.data.frame()\n",
    "\n",
    "#... <- mnist_predictions_with_labels |>\n",
    "#          filter(... == ...) |>\n",
    "#          slice_sample(...) |>\n",
    "\n",
    "#... <- matching |>\n",
    "#          slice(1) |>\n",
    "#          select(...) |>\n",
    "#          pull()\n",
    "\n",
    "# show_digit(slice(..., ...))\n",
    "# show_digit(slice(..., ...))\n",
    "# show_digit(slice(..., ...))\n",
    "\n",
    "options(repr.plot.height = 5, repr.plot.width = 5)\n",
    "\n",
    "# your code here\n",
    "fail() # No Answer - remove if you provide an answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "1555831707942b5433f2f50cb6e735cf",
     "grade": true,
     "grade_id": "cell-86bd96b4dc6eab40",
     "locked": true,
     "points": 3,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "library(digest)\n",
    "stopifnot(\"type of exists('mnist_predictions_with_labels') is not logical\"= setequal(digest(paste(toString(class(exists('mnist_predictions_with_labels'))), \"25db0\")), \"1f8b0640454e444eae8a65a4e9b67410\"))\n",
    "stopifnot(\"logical value of exists('mnist_predictions_with_labels') is not correct\"= setequal(digest(paste(toString(exists('mnist_predictions_with_labels')), \"25db0\")), \"9434d00d5a10e43cf27dee9f94f37eaa\"))\n",
    "\n",
    "stopifnot(\"type of dim(mnist_predictions_with_labels) is not integer\"= setequal(digest(paste(toString(class(dim(mnist_predictions_with_labels))), \"25db1\")), \"cb3db593b2d80dc74d643a0d108293e8\"))\n",
    "stopifnot(\"length of dim(mnist_predictions_with_labels) is not correct\"= setequal(digest(paste(toString(length(dim(mnist_predictions_with_labels))), \"25db1\")), \"544ad314d3dc995432ba2b3a212e3965\"))\n",
    "stopifnot(\"values of dim(mnist_predictions_with_labels) are not correct\"= setequal(digest(paste(toString(sort(dim(mnist_predictions_with_labels))), \"25db1\")), \"849f92579e49a1963878271f1c70066f\"))\n",
    "\n",
    "stopifnot(\"type of exists('matching') is not logical\"= setequal(digest(paste(toString(class(exists('matching'))), \"25db2\")), \"55342b100b06c89c9e25a6ddae729238\"))\n",
    "stopifnot(\"logical value of exists('matching') is not correct\"= setequal(digest(paste(toString(exists('matching')), \"25db2\")), \"a31503cad1837db222ca844360eb8bee\"))\n",
    "\n",
    "stopifnot(\"type of exists('matching_1') is not logical\"= setequal(digest(paste(toString(class(exists('matching_1'))), \"25db3\")), \"244c0977d8449837896863e0e7c712f6\"))\n",
    "stopifnot(\"logical value of exists('matching_1') is not correct\"= setequal(digest(paste(toString(exists('matching_1')), \"25db3\")), \"894c9bb93168708d90ea5e23999a8548\"))\n",
    "\n",
    "stopifnot(\"type of exists('matching_2') is not logical\"= setequal(digest(paste(toString(class(exists('matching_2'))), \"25db4\")), \"56ff839900e82be42fcbba68b788f470\"))\n",
    "stopifnot(\"logical value of exists('matching_2') is not correct\"= setequal(digest(paste(toString(exists('matching_2')), \"25db4\")), \"ddf42317c886d5fbac94c2aff778a9d0\"))\n",
    "\n",
    "stopifnot(\"type of exists('matching_3') is not logical\"= setequal(digest(paste(toString(class(exists('matching_3'))), \"25db5\")), \"41621dd98031c2929420727c0a996d78\"))\n",
    "stopifnot(\"logical value of exists('matching_3') is not correct\"= setequal(digest(paste(toString(exists('matching_3')), \"25db5\")), \"cb4b471dda4f7679ce24754f3cbb8261\"))\n",
    "\n",
    "# The rest of the tests are intentionally hidden so that you can practice deciding \n",
    "# when you have found the correct answer. \n",
    "print('Success!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "47c21ebb4f1d3f0b703cb7851cdaf628",
     "grade": false,
     "grade_id": "cell-9c5f324193a29613",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "**Question 4.3**\n",
    "<br> {points: 3}\n",
    "\n",
    "Print out 3 images and true labels from the test set that were **NOT** predicted correctly. You can reuse the `mnist_predictions_with_labels` data frame from **Question 4.2**. \n",
    "\n",
    "Filter for inequality between the predictions and the labels for the testing set in a data frame called `not_matching`. Afterwards, extract the row number and assign them to `not_matching_1`, `not_matching_2`, and `not_matching_3` respectively. If you need help, refer to the instructions in **Question 4.2**. \n",
    "\n",
    "Similar to the previous question, use the `show_digit` function we gave you above to print out the images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "a671fda500eb758bb84feee7b9c400cc",
     "grade": false,
     "grade_id": "cell-bc7fc6b54d89ef3b",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Set the seed. Don't remove this!\n",
    "set.seed(3500) \n",
    "\n",
    "options(repr.plot.height = 5, repr.plot.width = 5)\n",
    "\n",
    "# your code here\n",
    "fail() # No Answer - remove if you provide an answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "4d0e2094cc309f72853bb02ffb0d0c90",
     "grade": true,
     "grade_id": "cell-b925b109b4ec7f4d",
     "locked": true,
     "points": 3,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "library(digest)\n",
    "stopifnot(\"type of exists('not_matching') is not logical\"= setequal(digest(paste(toString(class(exists('not_matching'))), \"b96fb\")), \"c3cd95f2cf3f342907862e4b8ac3beab\"))\n",
    "stopifnot(\"logical value of exists('not_matching') is not correct\"= setequal(digest(paste(toString(exists('not_matching')), \"b96fb\")), \"e70714b405b9c70778c60d50263f9336\"))\n",
    "\n",
    "stopifnot(\"type of dim(not_matching) is not integer\"= setequal(digest(paste(toString(class(dim(not_matching))), \"b96fc\")), \"eb1b8734df695ca803c6cc9012e414a8\"))\n",
    "stopifnot(\"length of dim(not_matching) is not correct\"= setequal(digest(paste(toString(length(dim(not_matching))), \"b96fc\")), \"83a7f76c43c4c7a0309ed43c41e3629c\"))\n",
    "stopifnot(\"values of dim(not_matching) are not correct\"= setequal(digest(paste(toString(sort(dim(not_matching))), \"b96fc\")), \"9e1b9493d6068a4fce8003b8ad816c95\"))\n",
    "\n",
    "stopifnot(\"type of exists('not_matching_1') is not logical\"= setequal(digest(paste(toString(class(exists('not_matching_1'))), \"b96fd\")), \"1af954b42ed7b7d48c76bc3972ad5ffb\"))\n",
    "stopifnot(\"logical value of exists('not_matching_1') is not correct\"= setequal(digest(paste(toString(exists('not_matching_1')), \"b96fd\")), \"8a8637f09f41fba525e52b660b3bfa99\"))\n",
    "\n",
    "stopifnot(\"type of exists('not_matching_2') is not logical\"= setequal(digest(paste(toString(class(exists('not_matching_2'))), \"b96fe\")), \"729590111ccc899171db372e32542ad1\"))\n",
    "stopifnot(\"logical value of exists('not_matching_2') is not correct\"= setequal(digest(paste(toString(exists('not_matching_2')), \"b96fe\")), \"b5e20bb9c86e30cb9edbfc0413e2b8b1\"))\n",
    "\n",
    "stopifnot(\"type of exists('not_matching_3') is not logical\"= setequal(digest(paste(toString(class(exists('not_matching_3'))), \"b96ff\")), \"78aa47e7b73b825aa3f7718194b95ea0\"))\n",
    "stopifnot(\"logical value of exists('not_matching_3') is not correct\"= setequal(digest(paste(toString(exists('not_matching_3')), \"b96ff\")), \"d4e807a49f8aba97a9d869697e813a77\"))\n",
    "\n",
    "# The rest of the tests are intentionally hidden so that you can practice deciding \n",
    "# when you have found the correct answer. \n",
    "print('Success!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "46ae2aa71bbb88b61c0fcac72737c02e",
     "grade": false,
     "grade_id": "cell-c5a6da2601c50147",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "**Question 4.4** True or False:\n",
    "<br> {points: 1}\n",
    "\n",
    "The above images were predicted incorrectly due to messy handwriting. For example, the second image is illegible and actually looks like the letter \"U\".\n",
    "\n",
    "*Assign your answer to an object called `answer4.4`. Make sure your answer is in lowercase and is surrounded by quotation marks (e.g. `\"true\"` or `\"false\"`).*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "7100fdeb7e56e074febdbb019e5a9540",
     "grade": false,
     "grade_id": "cell-e104bb1ba6a2272b",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Replace the fail() with your answer. \n",
    "\n",
    "# your code here\n",
    "fail() # No Answer - remove if you provide an answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "389d507130cfec9b146f252eab823222",
     "grade": true,
     "grade_id": "cell-d1152d82e07b60e2",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "library(digest)\n",
    "stopifnot(\"type of answer4.4 is not character\"= setequal(digest(paste(toString(class(answer4.4)), \"aa60a\")), \"57fdc1331bad23b01452fb17368e89d8\"))\n",
    "stopifnot(\"length of answer4.4 is not correct\"= setequal(digest(paste(toString(length(answer4.4)), \"aa60a\")), \"30267a18b7c8d0da4e9247beb23ebb52\"))\n",
    "stopifnot(\"value of answer4.4 is not correct\"= setequal(digest(paste(toString(tolower(answer4.4)), \"aa60a\")), \"58acdda436fb993793da167fd57346fe\"))\n",
    "stopifnot(\"letters in string value of answer4.4 are correct but case is not correct\"= setequal(digest(paste(toString(answer4.4), \"aa60a\")), \"58acdda436fb993793da167fd57346fe\"))\n",
    "\n",
    "print('Success!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "a363866e8aaad48fc5fcbd9fc66192ba",
     "grade": false,
     "grade_id": "cell-36f596caca403aaf",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "**Question 4.5**\n",
    "<br> {points: 3}\n",
    "\n",
    "Looking again at the result from **Question 4.1**, what does this accuracy mean? Imagine that your classifier was to be used by the Canada Post to read handwritten digits in zip codes. Is it good enough that you would use this model for the Canada Post? Can you imagine a way we might improve our classifier's accuracy?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "79096e04d74f84b6644e6e8bdce8e212",
     "grade": true,
     "grade_id": "cell-86ae152b9a99ea34",
     "locked": false,
     "points": 3,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "DOUBLE CLICK TO EDIT **THIS CELL** AND REPLACE THIS TEXT WITH YOUR ANSWER."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "f7b7e84e0c941e34bcb17d5826a16de1",
     "grade": false,
     "grade_id": "cell-5bd3eadd6344002c",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**Question 4.6**\n",
    "<br> {points: 3}\n",
    "\n",
    "Looking again at the result from **Question 4.1**, and let's think about the other two metrics introduced in class for evaluating classifier performance. Do you think it is a good idea to tune/build our classifier based on precision and/or recall?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "ee45b2be3c5c4da51c54739d5f5a3d7d",
     "grade": true,
     "grade_id": "cell-348b48ee7040d721",
     "locked": false,
     "points": 3,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "DOUBLE CLICK TO EDIT **THIS CELL** AND REPLACE THIS TEXT WITH YOUR ANSWER."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "a67efe270f10735708d0232758bad40a",
     "grade": false,
     "grade_id": "cell-097f2cdb5ac59a83",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "source(\"cleanup.R\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.3.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
